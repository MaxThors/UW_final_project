{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "## Natural Language Processing (NLP)\n",
    "\n",
    "\n",
    "\n",
    "### Scope of this notebook:\n",
    "\n",
    "\n",
    "### 1.  Tokenization, Normalization & Custom Stopword Filtering with NLTK\n",
    "### 2.  Extract the most common words\n",
    "### 3.  Create \"Bag of Words\" data set\n",
    "### 4.  Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "### 5.  Split the Data into Training and Testing\n",
    "### 6.  Balanced Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Tokenization, Normalization & Custom Stopword Filtering with NLTK\n",
    "\n",
    "Here is where all the magic of splitting the reviews into individual words, putting each word into lower case, lemmatizing each to its base form, removing punctuations and excluding stop words occurs.\n",
    "\n",
    "We perform this step with the NLTK library as it is the most popular in education and research for NLP.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I tried the new flavor with layers and it was ...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>love this ice cream, taste fantastic!! will ne...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite cream. Where can I find th...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3417</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The best tasting ice cream out there! It is ve...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite, period. If I cant find it...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3419 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "0     0_breyers      1           11           0   \n",
       "1     0_breyers      1            7           0   \n",
       "2     0_breyers      1            8           0   \n",
       "3     0_breyers      1            4           0   \n",
       "4     0_breyers      5           21           2   \n",
       "...         ...    ...          ...         ...   \n",
       "3414       9_hd      5            1           0   \n",
       "3415       9_hd      5            1           0   \n",
       "3416       9_hd      5            1           0   \n",
       "3417       9_hd      5            1           0   \n",
       "3418       9_hd      5            1           0   \n",
       "\n",
       "                                                   text  rating  sentiment  \n",
       "0     I am interested in the flavoring components us...     4.1          0  \n",
       "1     Boy, was I surprised when I got my Bryers home...     4.1          0  \n",
       "2     I havent purchased this product in awhile and ...     4.1          0  \n",
       "3     The Natural Vanilla recipe change to include T...     4.1          0  \n",
       "4     I had the same issue with breyers. I finally f...     4.1          1  \n",
       "...                                                 ...     ...        ...  \n",
       "3414  I tried the new flavor with layers and it was ...     4.9          1  \n",
       "3415  love this ice cream, taste fantastic!! will ne...     4.9          1  \n",
       "3416  This is my favorite cream. Where can I find th...     4.9          1  \n",
       "3417  The best tasting ice cream out there! It is ve...     4.9          1  \n",
       "3418  This is my favorite, period. If I cant find it...     4.9          1  \n",
       "\n",
       "[3419 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tokenizer dataframe\n",
    "df_tokenize = pd.read_csv(\"../Resources/product_sentiment_reviews.csv\")\n",
    "df_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Tokenizer library\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "\n",
    "# RegexpTokenizer will tokenize according to any regular expression assigned. \n",
    "# The regular expression r'\\w+' matches any pattern consisting of one or more consecutive letters.\n",
    "reTokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "# Create Custom Stopwords \n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(list(set(['10','100','15', '20', '2in1', '30', '50', 'able', 'absolute', 'actual', 'actually', 'add', \n",
    "                            'added', 'adding', 'addition', 'ago', 'allergic', 'allergy', 'alternative', 'area', 'ask', \n",
    "                            'ate', 'available', 'away', 'awesome', 'balance', 'bar', 'barely', 'bark', 'base', 'based', \n",
    "                            'basically', 'batch', 'beat', 'belgian', 'ben', 'birthday', 'bit', 'bite', 'black', 'bought', \n",
    "                            'bowl', 'box', 'boy', 'boyfriend', 'brand', 'break', 'breyers', 'bring', 'brought', 'brown', \n",
    "                            'bryers', 'bud', 'buy', 'buying', 'called', 'calorie', 'came', 'carb', 'carbs', 'care', 'carry',\n",
    "                            'carrying', 'carton', 'case', 'cause', 'ccc', 'center', 'certainly', 'chance', 'change', \n",
    "                            'changed', 'cheap', 'check', 'child', 'chocoholic', 'choice', 'choose', 'christmas', 'chubby',\n",
    "                            'chuck', 'close', 'cold', 'color', 'com', 'combo', 'come', 'coming', 'company', 'completely', \n",
    "                            'consider', 'consumer', 'contact', 'contained', 'container', 'contains', 'continue', 'cool', \n",
    "                            'cost', 'couple', 'coupon', 'cow', 'craving', 'cream', 'create', 'created', 'creation', 'cup', \n",
    "                            'customer', 'cut', 'daily', 'daughter', 'day', 'daz', 'dazs', 'deal', 'decade', 'decided', \n",
    "                            'deep', 'definitely', 'desert', 'dessert', 'diabetic', 'didnt', 'die', 'diet', 'dig', 'dinner',\n",
    "                            'directly', 'discontinue', 'discontinued', 'dont', 'double', 'drive', 'earth', 'easily', 'easy',\n",
    "                            'eat', 'eaten', 'eating', 'edition', 'email', 'end', 'ended', 'entire', 'expect', 'eye', 'fact',\n",
    "                            'fall', 'family', 'fan', 'far', 'fat', 'filled', 'finally', 'finding', 'fine', 'fish', 'fix', 'flavor',\n",
    "                            'food', 'forever', 'formula', 'forward', 'free', 'freezer', 'fresh', 'friend', 'frozen', \n",
    "                            'future', 'gallon', 'garcia', 'gave', 'gelato', 'gelatos', 'getting', 'gimme', 'giving', 'glad',\n",
    "                            'gluten', 'god', 'going', 'gone', 'gonna', 'good', 'got', 'gotten', 'grab', 'gram', 'green', \n",
    "                            'grocer', 'grocery', 'guess', 'guilty', 'guy', 'haagen', 'half', 'halo', 'hand', 'happen', \n",
    "                            'happened', 'happy', 'hard', 'hardly', 'hate', 'havent', 'hd', 'healthy', 'hear', 'heard', \n",
    "                            'heart', 'help', 'high', 'highly', 'hill', 'hint', 'hit', 'holiday','home','homemade','honest',\n",
    "                            'honestly', 'hot', 'house', 'hubby', 'huge', 'husband', 'hÃ¤agen', 'ice', 'icecream', 'id', \n",
    "                            'idea', 'ill', 'im', 'imagine', 'influenster', 'inside', 'instead', 'irish', 'isnt', 'issue', \n",
    "                            'italy', 'item', 'ive', 'jar', 'jerry', 'job', 'kept', 'keto', 'kid', 'kind', 'kinda', 'knew', \n",
    "                            'know', 'label', 'large', 'larger', 'late', 'lately', 'later', 'layer', 'le', 'leave', 'left', \n",
    "                            'let', 'level', 'lid', 'life', 'light', 'like', 'liked', 'limited', 'line', 'list', 'literally',\n",
    "                            'little', 'live', 'local', 'lol', 'long', 'longer', 'look', 'looked', 'looking', 'lost', 'lot',\n",
    "                            'love', 'loved', 'lover', 'low', 'lower', 'luck', 'major', 'make', 'making', 'man', 'market', \n",
    "                            'maybe', 'mean', 'mediterranean', 'mess', 'middle', 'mild', 'mile', 'mind', 'mini', 'minute', \n",
    "                            'miss', 'mom', 'money', 'monkey', 'month', 'mouth', 'multiple', 'near', 'need', 'needed', \n",
    "                            'needle', 'net', 'new', 'nice', 'night', 'non', 'normal', 'normally', 'note', 'notice', \n",
    "                            'noticed', 'number', 'offer', 'oh', 'oil', 'ok', 'okay', 'old', 'omg', 'one', 'open', 'opened', 'option', \n",
    "                            'order', 'original', 'outside', 'overall', 'overly', 'pack', 'package', 'packaging', 'pair', \n",
    "                            'paired', 'particular', 'party', 'past', 'pay', 'people', 'period', 'permanent', 'person', 'phish',\n",
    "                            'pick', 'picked', 'picture', 'pint', 'place', 'plain', 'planet', 'plus', 'point', 'portion', \n",
    "                            'possible', 'prefer', 'pregnant', 'premium', 'pretty', 'previous', 'probably', 'problem', 'product',\n",
    "                            'protein', 'publix', 'purchase', 'purchased', 'purchasing', 'pure', 'purpose', 'quart', 'quickly', \n",
    "                            'quite', 'rating', 'ratio', 'reach', 'read', 'reading', 'real', 'really', 'reason', 'received', \n",
    "                            'recent', 'recently', 'recipe', 'regular', 'remember', 'reminds', 'remove', 'replaced', 'rest', \n",
    "                            'return', 'review', 'reviewer', 'ribbon', 'rid', 'right', 'road', 'rock', 'round', 'ruby', 'run',\n",
    "                            'said', 'sale', 'save', 'saw', 'say', 'saying', 'scoop', 'season', 'seasonal', 'second', \n",
    "                            'section', 'seeing', 'seen', 'sell', 'selling', 'sent', 'seriously', 'service', 'serving', 'share',\n",
    "                            'sharing', 'shelf', 'shop', 'shopping', 'short', 'sick', 'similar', 'simple', 'simply', 'single',\n",
    "                            'sit', 'sitting', 'size', 'slightly', 'small', 'smaller', 'smart', 'snack', 'sold', 'son', 'soon',\n",
    "                            'sooo', 'soooo', 'sorbet', 'sorbetto', 'sorry', 'sort', 'sound', 'spirit', 'spoon', 'spoonful', \n",
    "                            'spot', 'stand', 'star', 'start', 'started', 'state', 'stay', 'stick', 'stock', 'stop', 'stopped',\n",
    "                            'store', 'straight', 'stuff', 'substitute', 'summer', 'super', 'supermarket', 'sure', 'taken', \n",
    "                            'taking', 'talenti', 'target', 'team', 'tell', 'thats', 'therapy', 'theyre', 'thing', 'think', \n",
    "                            'thinking', 'thought', 'time', 'tiny', 'today', 'told', 'ton', 'tongue', 'tonight', 'took', 'tooth',\n",
    "                            'total', 'totally', 'touch', 'treat', 'trio', 'trip', 'true', 'truly', 'try', 'trying', 'tub', \n",
    "                            'turn', 'turned', 'twice', 'type', 'typically', 'understand', 'unilever', 'unless', 'unlike', 'use',\n",
    "                            'used', 'using', 'usual', 'usually', 'variety', 'version', 'wait', 'waiting', 'walmart', 'warm', \n",
    "                            'wasnt', 'water', 'way', 'website', 'week', 'weight', 'went', 'weve', 'whats', 'whim', 'white', \n",
    "                            'wife', 'word', 'work', 'world', 'worth', 'wouldnt', 'write', 'year', 'yes', 'yesterday', 'york', \n",
    "                            'youll', 'youre', 'youve'\n",
    "])))\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature\n",
    "custom_words =  set(['bigger', 'almond', 'apple', 'banana', 'bean', 'berry', 'bitter', 'blackberry', 'bourbon',\n",
    "                          'brownie', 'bun', 'butter', 'buttery', 'cacao', 'cake', 'candy', 'caramel', 'carmel', 'cheesecake', \n",
    "                           'cherry', 'chip', 'choc', 'chocolate', 'chocolatey', 'chocolaty', 'cinnamon', 'cocoa', \n",
    "                          'coconut', 'coffee', 'cone', 'cookie', 'cooky', 'cracker', 'crust', 'dairy', 'dough', \n",
    "                          'dulce', 'espresso', 'flake', 'fruit', 'fudge', 'graham', \n",
    "                          'hazelnut', 'honey', 'lemon', 'mango', 'marshmallow', 'matcha',  'mint', 'minty', 'nut', 'oat', \n",
    "                          'oatmeal', 'oreo', 'pb', 'peanut', 'pecan', 'peppermint', \n",
    "                          'pie', 'pistachio', 'potato', 'pretzel', 'pumpkin', 'raisin', 'raspberry', 'rum', 'salt', 'salted',\n",
    "                          'salty', 'smore', 'smores', 'snicker', 'sour', 'spice', 'strawberry',  \n",
    "                          'sweet', 'sweetener', 'sweeter', 'sweetness', 'swirl', 'swirled', 'syrup', 'tart', 'tea', \n",
    "                          'toasted', 'toffee', 'truffle', 'turkey', 'vanilla', 'waffle', 'walnut',\n",
    "                          'natural', 'sauce', 'sea', 'sicilian', 'ahoy', 'blend', 'blended', 'covered', 'dark', 'baked', \n",
    "                          'course', 'layered', 'piece', 'rocky', 'silky', 'speck', 'topping', 'chewy', 'chunk', 'chunky', 'consistency',\n",
    "                          'creaminess', 'creamy', 'crispy', 'crumb', 'crunch', 'crunchy', 'dense', 'gooey', 'gritty', 'gum', 'icy', \n",
    "                          'rich', 'smooth', 'soft', 'texture'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenize['text_custom'] =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_tokenize['text'])):\n",
    "       \n",
    "    \n",
    "    df_tokenize['text_custom'][i] = []\n",
    "    \n",
    "    # iterate through tokens\n",
    "    for word in custom_words:\n",
    "        if word in df_tokenize['text'][i]:\n",
    "            \n",
    "            if word not in stop_words:\n",
    "            \n",
    "        \n",
    "                # append to text column of dataframe for appropriate row\n",
    "                df_tokenize['text_custom'][i].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text list to string and create string column\n",
    "\n",
    "df_tokenize['text_custom_str'] = df_tokenize['text_custom'].apply(lambda x: ','.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_custom</th>\n",
       "      <th>text_custom_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[choc, chocolate, bean, pie, mint, vanilla, gu...</td>\n",
       "      <td>choc,chocolate,bean,pie,mint,vanilla,gum,natur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[syrup, dairy]</td>\n",
       "      <td>syrup,dairy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[gum, natural]</td>\n",
       "      <td>gum,natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[rich, bean, creamy, vanilla, gum, texture]</td>\n",
       "      <td>rich,bean,creamy,vanilla,gum,texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[turkey, natural]</td>\n",
       "      <td>turkey,natural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \\\n",
       "0  I am interested in the flavoring components us...     4.1          0   \n",
       "1  Boy, was I surprised when I got my Bryers home...     4.1          0   \n",
       "2  I havent purchased this product in awhile and ...     4.1          0   \n",
       "3  The Natural Vanilla recipe change to include T...     4.1          0   \n",
       "4  I had the same issue with breyers. I finally f...     4.1          1   \n",
       "\n",
       "                                         text_custom  \\\n",
       "0  [choc, chocolate, bean, pie, mint, vanilla, gu...   \n",
       "1                                     [syrup, dairy]   \n",
       "2                                     [gum, natural]   \n",
       "3        [rich, bean, creamy, vanilla, gum, texture]   \n",
       "4                                  [turkey, natural]   \n",
       "\n",
       "                                     text_custom_str  \n",
       "0  choc,chocolate,bean,pie,mint,vanilla,gum,natur...  \n",
       "1                                        syrup,dairy  \n",
       "2                                        gum,natural  \n",
       "3               rich,bean,creamy,vanilla,gum,texture  \n",
       "4                                     turkey,natural  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all the words from all the reviews into one list\n",
    "\n",
    "# initialize list to hold words\n",
    "all_words = []\n",
    "\n",
    "\n",
    "for i in range(len(df_tokenize['text'])):\n",
    "    # separate review text into a list of words\n",
    "    tokens = reTokenizer.tokenize(df_tokenize['text'][i])\n",
    "    \n",
    "    \n",
    "    df_tokenize['text'][i] = []\n",
    "    \n",
    "    # iterate through tokens\n",
    "    for word in tokens:\n",
    "        # lower the case of each word\n",
    "        word = word.lower()\n",
    "        # exclude stop words\n",
    "        if word not in stop_words:\n",
    "            \n",
    "            # Lemmatize words into a standard form and avoid counting the same word more than once\n",
    "            word = lemmatizer.lemmatize(word)\n",
    "            # add to list of words\n",
    "            all_words.append(word)\n",
    "            # append to text column of dataframe for appropriate row\n",
    "            df_tokenize['text'][i].append(word)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Extract the most common words\n",
    "\n",
    "\"bag of words\" and \"most common words\" is used interchangeably throughout the rest of this notebook. We will fix it to be consistent after everyone has mastered comfort with the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chocolate', 1416),\n",
       " ('taste', 855),\n",
       " ('favorite', 725),\n",
       " ('best', 645),\n",
       " ('vanilla', 566),\n",
       " ('would', 547),\n",
       " ('ever', 518),\n",
       " ('flavor', 502),\n",
       " ('get', 469),\n",
       " ('creamy', 457),\n",
       " ('cookie', 456),\n",
       " ('find', 431),\n",
       " ('delicious', 431),\n",
       " ('please', 430),\n",
       " ('great', 398),\n",
       " ('butter', 382),\n",
       " ('tried', 378),\n",
       " ('sweet', 378),\n",
       " ('perfect', 370),\n",
       " ('chip', 351),\n",
       " ('texture', 344),\n",
       " ('amazing', 344),\n",
       " ('caramel', 341),\n",
       " ('peanut', 336),\n",
       " ('first', 331),\n",
       " ('much', 314),\n",
       " ('go', 308),\n",
       " ('dairy', 308),\n",
       " ('never', 304),\n",
       " ('every', 264),\n",
       " ('chunk', 261),\n",
       " ('back', 254),\n",
       " ('always', 252),\n",
       " ('better', 244),\n",
       " ('could', 240),\n",
       " ('even', 240),\n",
       " ('coffee', 240),\n",
       " ('cooky', 224),\n",
       " ('year', 218),\n",
       " ('dough', 218),\n",
       " ('cant', 211),\n",
       " ('swirl', 208),\n",
       " ('rich', 204),\n",
       " ('also', 203),\n",
       " ('since', 202),\n",
       " ('fudge', 200),\n",
       " ('mint', 193),\n",
       " ('disappointed', 193),\n",
       " ('found', 191),\n",
       " ('well', 188),\n",
       " ('smooth', 187),\n",
       " ('tasted', 184),\n",
       " ('ingredient', 182),\n",
       " ('made', 182),\n",
       " ('piece', 182),\n",
       " ('thank', 179),\n",
       " ('store', 170),\n",
       " ('see', 169),\n",
       " ('still', 169),\n",
       " ('almond', 167),\n",
       " ('last', 166),\n",
       " ('wish', 166),\n",
       " ('keep', 163),\n",
       " ('something', 156),\n",
       " ('absolutely', 152),\n",
       " ('two', 150),\n",
       " ('milk', 148),\n",
       " ('sugar', 147),\n",
       " ('enough', 147),\n",
       " ('jerry', 141),\n",
       " ('many', 141),\n",
       " ('whole', 140),\n",
       " ('cream', 137),\n",
       " ('3', 137),\n",
       " ('combination', 135),\n",
       " ('hope', 132),\n",
       " ('pint', 132),\n",
       " ('brownie', 129),\n",
       " ('feel', 128),\n",
       " ('2', 128),\n",
       " ('another', 128),\n",
       " ('pistachio', 126),\n",
       " ('raspberry', 125),\n",
       " ('want', 124),\n",
       " ('almost', 124),\n",
       " ('amount', 123),\n",
       " ('cherry', 122),\n",
       " ('u', 119),\n",
       " ('core', 119),\n",
       " ('natural', 118),\n",
       " ('however', 118),\n",
       " ('crunch', 116),\n",
       " ('strawberry', 113),\n",
       " ('cheesecake', 113),\n",
       " ('different', 112),\n",
       " ('though', 112),\n",
       " ('bad', 110),\n",
       " ('enjoy', 110),\n",
       " ('quality', 109),\n",
       " ('layer', 109),\n",
       " ('recommend', 108),\n",
       " ('big', 107),\n",
       " ('mango', 105),\n",
       " ('marshmallow', 103),\n",
       " ('give', 100),\n",
       " ('5', 99),\n",
       " ('dark', 99),\n",
       " ('make', 98),\n",
       " ('nothing', 98),\n",
       " ('pie', 97),\n",
       " ('oreo', 96),\n",
       " ('coconut', 95),\n",
       " ('put', 93),\n",
       " ('b', 93),\n",
       " ('thanks', 93),\n",
       " ('top', 92),\n",
       " ('everything', 92),\n",
       " ('take', 91),\n",
       " ('around', 90),\n",
       " ('doesnt', 90),\n",
       " ('j', 90),\n",
       " ('without', 89),\n",
       " ('tasting', 89),\n",
       " ('cinnamon', 88),\n",
       " ('part', 87),\n",
       " ('bean', 86),\n",
       " ('1', 84),\n",
       " ('excited', 83),\n",
       " ('sad', 82),\n",
       " ('graham', 82),\n",
       " ('anything', 81),\n",
       " ('wonderful', 81),\n",
       " ('full', 80),\n",
       " ('le', 79),\n",
       " ('4', 77),\n",
       " ('pecan', 75),\n",
       " ('crunchy', 75),\n",
       " ('bit', 73),\n",
       " ('bar', 73),\n",
       " ('salty', 73),\n",
       " ('bourbon', 73),\n",
       " ('truffle', 71),\n",
       " ('together', 71),\n",
       " ('cracker', 71),\n",
       " ('anymore', 70),\n",
       " ('pretzel', 70),\n",
       " ('yummy', 69),\n",
       " ('brand', 68),\n",
       " ('mix', 67),\n",
       " ('couldnt', 66),\n",
       " ('time', 66),\n",
       " ('must', 65),\n",
       " ('next', 65),\n",
       " ('calorie', 65),\n",
       " ('disappointing', 64),\n",
       " ('perfectly', 63),\n",
       " ('ahoy', 63),\n",
       " ('unfortunately', 62),\n",
       " ('experience', 62),\n",
       " ('month', 62),\n",
       " ('others', 62),\n",
       " ('price', 61),\n",
       " ('wanted', 61),\n",
       " ('heaven', 61),\n",
       " ('hand', 61),\n",
       " ('bottom', 61),\n",
       " ('several', 60),\n",
       " ('review', 60),\n",
       " ('tasty', 60),\n",
       " ('soft', 59),\n",
       " ('product', 59),\n",
       " ('cannot', 59),\n",
       " ('hooked', 59),\n",
       " ('day', 58),\n",
       " ('believe', 58),\n",
       " ('flavour', 58),\n",
       " ('least', 57),\n",
       " ('seems', 57),\n",
       " ('everyone', 57),\n",
       " ('nut', 57),\n",
       " ('melt', 56),\n",
       " ('star', 56),\n",
       " ('vegan', 56),\n",
       " ('wrong', 55),\n",
       " ('strong', 55),\n",
       " ('addicted', 55),\n",
       " ('may', 54),\n",
       " ('especially', 54),\n",
       " ('might', 54),\n",
       " ('come', 53),\n",
       " ('cone', 53),\n",
       " ('banana', 53),\n",
       " ('cake', 53),\n",
       " ('flavored', 51),\n",
       " ('peppermint', 51),\n",
       " ('thing', 50),\n",
       " ('wow', 50),\n",
       " ('lactose', 50),\n",
       " ('decadent', 49),\n",
       " ('kid', 49),\n",
       " ('else', 49),\n",
       " ('gum', 48),\n",
       " ('artificial', 48),\n",
       " ('either', 48),\n",
       " ('love', 48),\n",
       " ('apple', 47),\n",
       " ('blend', 46),\n",
       " ('three', 45),\n",
       " ('need', 45),\n",
       " ('throughout', 45),\n",
       " ('exactly', 45),\n",
       " ('covered', 45),\n",
       " ('pumpkin', 45),\n",
       " ('yet', 44),\n",
       " ('sometimes', 44),\n",
       " ('service', 44),\n",
       " ('special', 44),\n",
       " ('yum', 43),\n",
       " ('enjoyed', 43),\n",
       " ('wont', 42),\n",
       " ('side', 42),\n",
       " ('pb', 42),\n",
       " ('baked', 42),\n",
       " ('salted', 42),\n",
       " ('delight', 42),\n",
       " ('smores', 42),\n",
       " ('anyone', 41),\n",
       " ('container', 41),\n",
       " ('expecting', 41),\n",
       " ('anywhere', 41),\n",
       " ('salt', 41),\n",
       " ('guy', 41),\n",
       " ('surprised', 40),\n",
       " ('obsessed', 40),\n",
       " ('refreshing', 39),\n",
       " ('done', 39),\n",
       " ('become', 39),\n",
       " ('missing', 39),\n",
       " ('extremely', 39),\n",
       " ('sweetness', 39),\n",
       " ('someone', 39),\n",
       " ('bite', 39),\n",
       " ('mixed', 38),\n",
       " ('excellent', 38),\n",
       " ('cup', 38),\n",
       " ('lemon', 37),\n",
       " ('per', 37),\n",
       " ('perfection', 37),\n",
       " ('fantastic', 37),\n",
       " ('bigger', 37),\n",
       " ('mine', 37),\n",
       " ('oatmeal', 37),\n",
       " ('disappointment', 36),\n",
       " ('finished', 36),\n",
       " ('consistency', 36),\n",
       " ('friend', 36),\n",
       " ('satisfying', 36),\n",
       " ('extra', 35),\n",
       " ('name', 35),\n",
       " ('opinion', 35),\n",
       " ('testing', 35),\n",
       " ('goodness', 35),\n",
       " ('dream', 35),\n",
       " ('fell', 35),\n",
       " ('already', 35),\n",
       " ('syrup', 34),\n",
       " ('often', 34),\n",
       " ('overpowering', 34),\n",
       " ('crust', 34),\n",
       " ('weird', 33),\n",
       " ('7', 33),\n",
       " ('there', 33),\n",
       " ('one', 33),\n",
       " ('felt', 33),\n",
       " ('hoping', 33),\n",
       " ('compare', 32),\n",
       " ('more', 32),\n",
       " ('6', 32),\n",
       " ('difficult', 32),\n",
       " ('difference', 31),\n",
       " ('bun', 31),\n",
       " ('carmel', 31),\n",
       " ('although', 31),\n",
       " ('agree', 30),\n",
       " ('except', 30),\n",
       " ('none', 30),\n",
       " ('thick', 30),\n",
       " ('rum', 30),\n",
       " ('tea', 30),\n",
       " ('across', 29),\n",
       " ('corn', 28),\n",
       " ('due', 28),\n",
       " ('aftertaste', 28),\n",
       " ('hazelnut', 28),\n",
       " ('creaminess', 27),\n",
       " ('week', 27),\n",
       " ('option', 27),\n",
       " ('course', 27),\n",
       " ('flake', 27),\n",
       " ('discovered', 27),\n",
       " ('intolerant', 27),\n",
       " ('feeling', 26),\n",
       " ('subtle', 26),\n",
       " ('incredible', 26),\n",
       " ('flavorful', 26),\n",
       " ('surprise', 26),\n",
       " ('complaint', 26),\n",
       " ('de', 26),\n",
       " ('upon', 26),\n",
       " ('bud', 26),\n",
       " ('classic', 25),\n",
       " ('along', 25),\n",
       " ('impressed', 25),\n",
       " ('lover', 25),\n",
       " ('chewy', 25),\n",
       " ('tart', 25),\n",
       " ('fruit', 25),\n",
       " ('dessert', 25),\n",
       " ('intense', 25),\n",
       " ('disappoint', 25),\n",
       " ('heavenly', 25),\n",
       " ('smore', 25),\n",
       " ('rather', 24),\n",
       " ('melted', 24),\n",
       " ('seem', 24),\n",
       " ('sadly', 24),\n",
       " ('compared', 24),\n",
       " ('minute', 24),\n",
       " ('toasted', 24),\n",
       " ('balanced', 24),\n",
       " ('buttery', 24),\n",
       " ('ruined', 23),\n",
       " ('lack', 23),\n",
       " ('candy', 23),\n",
       " ('anyway', 23),\n",
       " ('nearly', 23),\n",
       " ('shelf', 23),\n",
       " ('dulce', 23),\n",
       " ('chunky', 23),\n",
       " ('five', 23),\n",
       " ('matcha', 23),\n",
       " ('flavoring', 22),\n",
       " ('say', 22),\n",
       " ('expensive', 22),\n",
       " ('topping', 22),\n",
       " ('look', 22),\n",
       " ('everywhere', 22),\n",
       " ('potato', 22),\n",
       " ('gooey', 22),\n",
       " ('spicy', 22),\n",
       " ('expected', 21),\n",
       " ('became', 21),\n",
       " ('icy', 21),\n",
       " ('stronger', 21),\n",
       " ('leche', 21),\n",
       " ('n', 21),\n",
       " ('sicilian', 21),\n",
       " ('content', 20),\n",
       " ('finish', 20),\n",
       " ('perhaps', 20),\n",
       " ('appreciate', 20),\n",
       " ('toffee', 20),\n",
       " ('whenever', 20),\n",
       " ('vegetable', 19),\n",
       " ('immediately', 19),\n",
       " ('upset', 19),\n",
       " ('personally', 19),\n",
       " ('shame', 19),\n",
       " ('sauce', 19),\n",
       " ('swirled', 19),\n",
       " ('alcohol', 19),\n",
       " ('gram', 19),\n",
       " ('waste', 19),\n",
       " ('describe', 19),\n",
       " ('mostly', 19),\n",
       " ('thin', 19),\n",
       " ('chocolatey', 19),\n",
       " ('searching', 19),\n",
       " ('ribbon', 19),\n",
       " ('blackberry', 19),\n",
       " ('chemical', 18),\n",
       " ('alone', 18),\n",
       " ('delightful', 18),\n",
       " ('crispy', 18),\n",
       " ('waffle', 18),\n",
       " ('sea', 18),\n",
       " ('lot', 18),\n",
       " ('word', 18),\n",
       " ('treat', 18),\n",
       " ('honey', 18),\n",
       " ('addictive', 18),\n",
       " ('berry', 18),\n",
       " ('etc', 17),\n",
       " ('favourite', 17),\n",
       " ('recommended', 17),\n",
       " ('bland', 17),\n",
       " ('8', 17),\n",
       " ('fabulous', 17),\n",
       " ('craving', 17),\n",
       " ('add', 17),\n",
       " ('seemed', 17),\n",
       " ('fun', 17),\n",
       " ('silky', 17),\n",
       " ('deliciousness', 17),\n",
       " ('espresso', 17),\n",
       " ('pleasure', 17),\n",
       " ('dry', 17),\n",
       " ('skeptical', 17),\n",
       " ('pleasantly', 16),\n",
       " ('g', 16),\n",
       " ('blended', 16),\n",
       " ('loaded', 16),\n",
       " ('place', 16),\n",
       " ('layered', 16),\n",
       " ('crumb', 16),\n",
       " ('soy', 16),\n",
       " ('incredibly', 16),\n",
       " ('minty', 16),\n",
       " ('spice', 16),\n",
       " ('component', 15),\n",
       " ('leaf', 15),\n",
       " ('unique', 15),\n",
       " ('strange', 15),\n",
       " ('note', 15),\n",
       " ('gritty', 15),\n",
       " ('snicker', 15),\n",
       " ('egg', 15),\n",
       " ('dense', 15),\n",
       " ('choc', 15),\n",
       " ('crazy', 15),\n",
       " ('pleased', 15),\n",
       " ('oat', 15),\n",
       " ('generous', 15),\n",
       " ('greatest', 15),\n",
       " ('reviewer', 15),\n",
       " ('brew', 15),\n",
       " ('winner', 15),\n",
       " ('spirit', 15),\n",
       " ('decade', 14),\n",
       " ('rocky', 14),\n",
       " ('terrible', 14),\n",
       " ('fake', 14),\n",
       " ('wanting', 14),\n",
       " ('bitter', 14),\n",
       " ('choice', 14),\n",
       " ('within', 14),\n",
       " ('otherwise', 14),\n",
       " ('gross', 14),\n",
       " ('issue', 14),\n",
       " ('worst', 14),\n",
       " ('impossible', 14),\n",
       " ('doubt', 14),\n",
       " ('expectation', 14),\n",
       " ('richness', 14),\n",
       " ('like', 14),\n",
       " ('sour', 14),\n",
       " ('admit', 14),\n",
       " ('chocolaty', 14),\n",
       " ('bummed', 14),\n",
       " ('bailey', 14),\n",
       " ('besides', 13),\n",
       " ('rarely', 13),\n",
       " ('mistake', 13),\n",
       " ('clean', 13),\n",
       " ('cocoa', 13),\n",
       " ('joy', 13),\n",
       " ('sweeter', 13),\n",
       " ('in', 13),\n",
       " ('whatever', 13),\n",
       " ('walnut', 13),\n",
       " ('considering', 13),\n",
       " ('satisfy', 13),\n",
       " ('sweetener', 13),\n",
       " ('spoonful', 13),\n",
       " ('complimentary', 13),\n",
       " ('exclusive', 13),\n",
       " ('cacao', 13),\n",
       " ('carton', 13),\n",
       " ('boring', 13),\n",
       " ('addiction', 13),\n",
       " ('raisin', 13),\n",
       " ('speck', 12),\n",
       " ('turkey', 12),\n",
       " ('indulgence', 12),\n",
       " ('horrible', 12),\n",
       " ('enjoying', 12),\n",
       " ('customer', 12),\n",
       " ('mean', 12),\n",
       " ('fan', 12),\n",
       " ('satisfied', 12),\n",
       " ('despite', 12),\n",
       " ('show', 12),\n",
       " ('four', 12),\n",
       " ('blown', 12),\n",
       " ('talentis', 12),\n",
       " ('ton', 12),\n",
       " ('hide', 12),\n",
       " ('divine', 12),\n",
       " ('head', 12),\n",
       " ('bold', 12)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the most common words from the list of all_words.\n",
    "\n",
    "from nltk import FreqDist\n",
    "\n",
    "# sort all of the words in the all_words list by frequency count\n",
    "all_words = FreqDist(all_words)\n",
    "# Extract the most common words from the all_words list\n",
    "most_common_words = all_words.most_common(500)\n",
    "\n",
    "# create a list of most common words without the frequency count\n",
    "word_features = []\n",
    "for w in most_common_words:\n",
    "    word_features.append(w[0])\n",
    "\n",
    "#print \n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  5801 unique words total in our text dataset.\n",
      "There are  500 unique words in the most common words list.\n"
     ]
    }
   ],
   "source": [
    "print ('There are ', len(all_words), 'unique words total in our text dataset.')\n",
    "print ('There are ', len(most_common_words), 'unique words in the most common words list.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.  Create \"Bag of Words\" data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Bag of Words DataFrame\n",
    "df_bagofwords = pd.DataFrame(df_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_custom</th>\n",
       "      <th>text_custom_str</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[interested, flavoring, component, ingredient,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[choc, chocolate, bean, pie, mint, vanilla, gu...</td>\n",
       "      <td>choc,chocolate,bean,pie,mint,vanilla,gum,natur...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[surprised, discover, dairy, even, ingredient,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[syrup, dairy]</td>\n",
       "      <td>syrup,dairy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[awhile, surprised, find, cheapened, ingredien...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[gum, natural]</td>\n",
       "      <td>gum,natural</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, include, tara, gum, change,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[rich, bean, creamy, vanilla, gum, texture]</td>\n",
       "      <td>rich,bean,creamy,vanilla,gum,texture</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>[found, turkey, natural, settle, filler, natural]</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[turkey, natural]</td>\n",
       "      <td>turkey,natural</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \\\n",
       "0  [interested, flavoring, component, ingredient,...     4.1          0   \n",
       "1  [surprised, discover, dairy, even, ingredient,...     4.1          0   \n",
       "2  [awhile, surprised, find, cheapened, ingredien...     4.1          0   \n",
       "3  [natural, vanilla, include, tara, gum, change,...     4.1          0   \n",
       "4  [found, turkey, natural, settle, filler, natural]     4.1          1   \n",
       "\n",
       "                                         text_custom  \\\n",
       "0  [choc, chocolate, bean, pie, mint, vanilla, gu...   \n",
       "1                                     [syrup, dairy]   \n",
       "2                                     [gum, natural]   \n",
       "3        [rich, bean, creamy, vanilla, gum, texture]   \n",
       "4                                  [turkey, natural]   \n",
       "\n",
       "                                     text_custom_str bag_of_words  \n",
       "0  choc,chocolate,bean,pie,mint,vanilla,gum,natur...               \n",
       "1                                        syrup,dairy               \n",
       "2                                        gum,natural               \n",
       "3               rich,bean,creamy,vanilla,gum,texture               \n",
       "4                                     turkey,natural               "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create column for bag of words\n",
    "df_bagofwords['bag_of_words'] = \"\"\n",
    "df_bagofwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate dataframe to populate bag of words column\n",
    "for i in range(len(df_bagofwords['text_custom'])):\n",
    "    # initialize empty column    \n",
    "    df_bagofwords['bag_of_words'][i] = []\n",
    "    \n",
    "    # iterate through df row by row\n",
    "    for word in df_bagofwords['text_custom'][i]:\n",
    "        # if a word in 'text' is in the most common words\n",
    "        # note: this is simply the \"most_common_words\" without the count column\n",
    "        if word in word_features:\n",
    "            # if it is, add it to the bag of words cell\n",
    "            df_bagofwords['bag_of_words'][i].append(word)\n",
    "            \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_custom</th>\n",
       "      <th>text_custom_str</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[interested, flavoring, component, ingredient,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[choc, chocolate, bean, pie, mint, vanilla, gu...</td>\n",
       "      <td>choc,chocolate,bean,pie,mint,vanilla,gum,natur...</td>\n",
       "      <td>[choc, chocolate, bean, pie, mint, vanilla, gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[surprised, discover, dairy, even, ingredient,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[syrup, dairy]</td>\n",
       "      <td>syrup,dairy</td>\n",
       "      <td>[syrup, dairy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[awhile, surprised, find, cheapened, ingredien...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[gum, natural]</td>\n",
       "      <td>gum,natural</td>\n",
       "      <td>[gum, natural]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, include, tara, gum, change,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[rich, bean, creamy, vanilla, gum, texture]</td>\n",
       "      <td>rich,bean,creamy,vanilla,gum,texture</td>\n",
       "      <td>[rich, bean, creamy, vanilla, gum, texture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>[found, turkey, natural, settle, filler, natural]</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[turkey, natural]</td>\n",
       "      <td>turkey,natural</td>\n",
       "      <td>[turkey, natural]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \\\n",
       "0  [interested, flavoring, component, ingredient,...     4.1          0   \n",
       "1  [surprised, discover, dairy, even, ingredient,...     4.1          0   \n",
       "2  [awhile, surprised, find, cheapened, ingredien...     4.1          0   \n",
       "3  [natural, vanilla, include, tara, gum, change,...     4.1          0   \n",
       "4  [found, turkey, natural, settle, filler, natural]     4.1          1   \n",
       "\n",
       "                                         text_custom  \\\n",
       "0  [choc, chocolate, bean, pie, mint, vanilla, gu...   \n",
       "1                                     [syrup, dairy]   \n",
       "2                                     [gum, natural]   \n",
       "3        [rich, bean, creamy, vanilla, gum, texture]   \n",
       "4                                  [turkey, natural]   \n",
       "\n",
       "                                     text_custom_str  \\\n",
       "0  choc,chocolate,bean,pie,mint,vanilla,gum,natur...   \n",
       "1                                        syrup,dairy   \n",
       "2                                        gum,natural   \n",
       "3               rich,bean,creamy,vanilla,gum,texture   \n",
       "4                                     turkey,natural   \n",
       "\n",
       "                                        bag_of_words  \n",
       "0  [choc, chocolate, bean, pie, mint, vanilla, gu...  \n",
       "1                                     [syrup, dairy]  \n",
       "2                                     [gum, natural]  \n",
       "3        [rich, bean, creamy, vanilla, gum, texture]  \n",
       "4                                  [turkey, natural]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bagofwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['syrup', 'dairy']\n",
      "\n",
      "bag_of_words:  ['syrup', 'dairy']\n"
     ]
    }
   ],
   "source": [
    "# Example to compare text vs bag of words\n",
    "# set example variable equal to the review row you'd like to see\n",
    "example = 1\n",
    "\n",
    "print('text: ', df_bagofwords['text_custom'][example])\n",
    "print('\\nbag_of_words: ',df_bagofwords['bag_of_words'][example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Term Frequency-Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_custom</th>\n",
       "      <th>text_custom_str</th>\n",
       "      <th>bag_of_words</th>\n",
       "      <th>bag_of_words_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[interested, flavoring, component, ingredient,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[choc, chocolate, bean, pie, mint, vanilla, gu...</td>\n",
       "      <td>choc,chocolate,bean,pie,mint,vanilla,gum,natur...</td>\n",
       "      <td>[choc, chocolate, bean, pie, mint, vanilla, gu...</td>\n",
       "      <td>choc,chocolate,bean,pie,mint,vanilla,gum,natur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[surprised, discover, dairy, even, ingredient,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[syrup, dairy]</td>\n",
       "      <td>syrup,dairy</td>\n",
       "      <td>[syrup, dairy]</td>\n",
       "      <td>syrup,dairy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[awhile, surprised, find, cheapened, ingredien...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[gum, natural]</td>\n",
       "      <td>gum,natural</td>\n",
       "      <td>[gum, natural]</td>\n",
       "      <td>gum,natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, include, tara, gum, change,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[rich, bean, creamy, vanilla, gum, texture]</td>\n",
       "      <td>rich,bean,creamy,vanilla,gum,texture</td>\n",
       "      <td>[rich, bean, creamy, vanilla, gum, texture]</td>\n",
       "      <td>rich,bean,creamy,vanilla,gum,texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>[found, turkey, natural, settle, filler, natural]</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[turkey, natural]</td>\n",
       "      <td>turkey,natural</td>\n",
       "      <td>[turkey, natural]</td>\n",
       "      <td>turkey,natural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \\\n",
       "0  [interested, flavoring, component, ingredient,...     4.1          0   \n",
       "1  [surprised, discover, dairy, even, ingredient,...     4.1          0   \n",
       "2  [awhile, surprised, find, cheapened, ingredien...     4.1          0   \n",
       "3  [natural, vanilla, include, tara, gum, change,...     4.1          0   \n",
       "4  [found, turkey, natural, settle, filler, natural]     4.1          1   \n",
       "\n",
       "                                         text_custom  \\\n",
       "0  [choc, chocolate, bean, pie, mint, vanilla, gu...   \n",
       "1                                     [syrup, dairy]   \n",
       "2                                     [gum, natural]   \n",
       "3        [rich, bean, creamy, vanilla, gum, texture]   \n",
       "4                                  [turkey, natural]   \n",
       "\n",
       "                                     text_custom_str  \\\n",
       "0  choc,chocolate,bean,pie,mint,vanilla,gum,natur...   \n",
       "1                                        syrup,dairy   \n",
       "2                                        gum,natural   \n",
       "3               rich,bean,creamy,vanilla,gum,texture   \n",
       "4                                     turkey,natural   \n",
       "\n",
       "                                        bag_of_words  \\\n",
       "0  [choc, chocolate, bean, pie, mint, vanilla, gu...   \n",
       "1                                     [syrup, dairy]   \n",
       "2                                     [gum, natural]   \n",
       "3        [rich, bean, creamy, vanilla, gum, texture]   \n",
       "4                                  [turkey, natural]   \n",
       "\n",
       "                                    bag_of_words_str  \n",
       "0  choc,chocolate,bean,pie,mint,vanilla,gum,natur...  \n",
       "1                                        syrup,dairy  \n",
       "2                                        gum,natural  \n",
       "3               rich,bean,creamy,vanilla,gum,texture  \n",
       "4                                     turkey,natural  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dependencies\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# create new DataFrame to hold encoded values \n",
    "df_tfidf_text = pd.DataFrame(df_bagofwords)\n",
    "\n",
    "# convert text list to string and create string column\n",
    "# Required for vectorizer. Running on a list will yield an error.\n",
    "# https://stackoverflow.com/questions/45306988/column-of-lists-convert-list-to-string-as-a-new-column\n",
    "df_tfidf_text['bag_of_words_str'] = df_tfidf_text['bag_of_words'].apply(lambda x: ','.join(map(str, x)))\n",
    "\n",
    "df_tfidf_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create engineered_feature_tokens table\n",
    "#df_tfidf_text.to_csv(\"../Resources/engineered_feature_tokens.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ahoy</th>\n",
       "      <th>almond</th>\n",
       "      <th>apple</th>\n",
       "      <th>baked</th>\n",
       "      <th>banana</th>\n",
       "      <th>bean</th>\n",
       "      <th>berry</th>\n",
       "      <th>bigger</th>\n",
       "      <th>bitter</th>\n",
       "      <th>blackberry</th>\n",
       "      <th>...</th>\n",
       "      <th>tea</th>\n",
       "      <th>texture</th>\n",
       "      <th>toasted</th>\n",
       "      <th>toffee</th>\n",
       "      <th>topping</th>\n",
       "      <th>truffle</th>\n",
       "      <th>turkey</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>waffle</th>\n",
       "      <th>walnut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.221726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.338588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ahoy  almond  apple  baked  banana      bean  berry  bigger  bitter  \\\n",
       "0   0.0     0.0    0.0    0.0     0.0  0.335561    0.0     0.0     0.0   \n",
       "1   0.0     0.0    0.0    0.0     0.0  0.000000    0.0     0.0     0.0   \n",
       "2   0.0     0.0    0.0    0.0     0.0  0.000000    0.0     0.0     0.0   \n",
       "3   0.0     0.0    0.0    0.0     0.0  0.503040    0.0     0.0     0.0   \n",
       "4   0.0     0.0    0.0    0.0     0.0  0.000000    0.0     0.0     0.0   \n",
       "\n",
       "   blackberry  ...  tea   texture  toasted  toffee  topping  truffle  \\\n",
       "0         0.0  ...  0.0  0.000000      0.0     0.0      0.0      0.0   \n",
       "1         0.0  ...  0.0  0.000000      0.0     0.0      0.0      0.0   \n",
       "2         0.0  ...  0.0  0.000000      0.0     0.0      0.0      0.0   \n",
       "3         0.0  ...  0.0  0.338588      0.0     0.0      0.0      0.0   \n",
       "4         0.0  ...  0.0  0.000000      0.0     0.0      0.0      0.0   \n",
       "\n",
       "     turkey   vanilla  waffle  walnut  \n",
       "0  0.000000  0.221726     0.0     0.0  \n",
       "1  0.000000  0.000000     0.0     0.0  \n",
       "2  0.000000  0.000000     0.0     0.0  \n",
       "3  0.000000  0.332390     0.0     0.0  \n",
       "4  0.860684  0.000000     0.0     0.0  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 'text' term frequencies weighted by their relative importance (IDF)\n",
    "tfidf = TfidfVectorizer(analyzer='word', stop_words = 'english')\n",
    "\n",
    "# create variable to hold independent features and TFIDF\n",
    "x = df_tfidf_text['bag_of_words_str']\n",
    "\n",
    "\n",
    "# Fit and transform independent features\n",
    "xtfidf = tfidf.fit_transform(x)\n",
    "\n",
    "# Create encoded TFIDF vector for bag of words\n",
    "tfdif_bagOfWords_df = pd.DataFrame(data = xtfidf.toarray(),\n",
    "                        # set column header as feature names           \n",
    "                        columns = tfidf.get_feature_names())\n",
    "\n",
    "tfdif_bagOfWords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features :  ['ahoy', 'almond', 'apple', 'baked', 'banana', 'bean', 'berry', 'bigger', 'bitter', 'blackberry', 'blend', 'blended', 'bourbon', 'brownie', 'bun', 'butter', 'buttery', 'cacao', 'cake', 'candy', 'caramel', 'carmel', 'cheesecake', 'cherry', 'chewy', 'chip', 'choc', 'chocolate', 'chocolatey', 'chocolaty', 'chunk', 'chunky', 'cinnamon', 'cocoa', 'coconut', 'coffee', 'cone', 'consistency', 'cookie', 'course', 'covered', 'cracker', 'creaminess', 'creamy', 'crispy', 'crumb', 'crunch', 'crunchy', 'crust', 'dairy', 'dark', 'dense', 'dough', 'dulce', 'espresso', 'flake', 'fruit', 'fudge', 'gooey', 'graham', 'gritty', 'gum', 'hazelnut', 'honey', 'icy', 'layered', 'lemon', 'mango', 'marshmallow', 'matcha', 'mint', 'minty', 'natural', 'nut', 'oat', 'oatmeal', 'oreo', 'pb', 'peanut', 'pecan', 'peppermint', 'pie', 'piece', 'pistachio', 'potato', 'pretzel', 'pumpkin', 'raisin', 'raspberry', 'rich', 'rocky', 'rum', 'salt', 'salted', 'salty', 'sauce', 'sea', 'sicilian', 'silky', 'smooth', 'smore', 'smores', 'snicker', 'soft', 'sour', 'speck', 'spice', 'strawberry', 'sweet', 'sweetener', 'sweeter', 'sweetness', 'swirl', 'swirled', 'syrup', 'tart', 'tea', 'texture', 'toasted', 'toffee', 'topping', 'truffle', 'turkey', 'vanilla', 'waffle', 'walnut']\n"
     ]
    }
   ],
   "source": [
    "print ('\\nFeatures : ', tfdif_bagOfWords_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>choc</td>\n",
       "      <td>272.824030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chocolate</td>\n",
       "      <td>267.656502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>creamy</td>\n",
       "      <td>172.664509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>cookie</td>\n",
       "      <td>171.803154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>nut</td>\n",
       "      <td>151.073538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>144.544081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>sweet</td>\n",
       "      <td>142.268061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>texture</td>\n",
       "      <td>135.969438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>caramel</td>\n",
       "      <td>99.267534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>butter</td>\n",
       "      <td>96.072715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>dairy</td>\n",
       "      <td>94.360390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chip</td>\n",
       "      <td>93.220764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>chunk</td>\n",
       "      <td>90.828385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>rich</td>\n",
       "      <td>88.368004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>smooth</td>\n",
       "      <td>85.278909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>pie</td>\n",
       "      <td>83.201207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>peanut</td>\n",
       "      <td>81.588772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>coffee</td>\n",
       "      <td>76.026742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>berry</td>\n",
       "      <td>72.591191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>swirl</td>\n",
       "      <td>70.279791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term  significance\n",
       "26        choc    272.824030\n",
       "27   chocolate    267.656502\n",
       "43      creamy    172.664509\n",
       "38      cookie    171.803154\n",
       "73         nut    151.073538\n",
       "123    vanilla    144.544081\n",
       "108      sweet    142.268061\n",
       "117    texture    135.969438\n",
       "20     caramel     99.267534\n",
       "15      butter     96.072715\n",
       "49       dairy     94.360390\n",
       "25        chip     93.220764\n",
       "30       chunk     90.828385\n",
       "89        rich     88.368004\n",
       "99      smooth     85.278909\n",
       "81         pie     83.201207\n",
       "78      peanut     81.588772\n",
       "35      coffee     76.026742\n",
       "6        berry     72.591191\n",
       "112      swirl     70.279791"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank top 20 terms from TFID in order of signifigance score\n",
    "# https://stackoverflow.com/questions/45805493/sorting-tfidfvectorizer-output-by-tf-idf-lowest-to-highest-and-vice-versa\n",
    "\n",
    "terms = tfidf.get_feature_names()\n",
    "\n",
    "# sum tfidf frequency of each term through documents\n",
    "sums = xtfidf.sum(axis=0)\n",
    "\n",
    "# connecting term to its sums frequency\n",
    "data = []\n",
    "for col, term in enumerate(terms):\n",
    "    data.append( (term, sums[0,col] ))\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term','significance'])\n",
    "term_rank = ranking.sort_values('significance', ascending=False)\n",
    "\n",
    "term_rank[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ahoy</th>\n",
       "      <th>almond</th>\n",
       "      <th>apple</th>\n",
       "      <th>baked</th>\n",
       "      <th>...</th>\n",
       "      <th>tea</th>\n",
       "      <th>texture</th>\n",
       "      <th>toasted</th>\n",
       "      <th>toffee</th>\n",
       "      <th>topping</th>\n",
       "      <th>truffle</th>\n",
       "      <th>turkey</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>waffle</th>\n",
       "      <th>walnut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.221726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.338588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  rating  sentiment  ahoy  almond  \\\n",
       "0  0_breyers      1           11           0     4.1          0   0.0     0.0   \n",
       "1  0_breyers      1            7           0     4.1          0   0.0     0.0   \n",
       "2  0_breyers      1            8           0     4.1          0   0.0     0.0   \n",
       "3  0_breyers      1            4           0     4.1          0   0.0     0.0   \n",
       "4  0_breyers      5           21           2     4.1          1   0.0     0.0   \n",
       "\n",
       "   apple  baked  ...  tea   texture  toasted  toffee  topping  truffle  \\\n",
       "0    0.0    0.0  ...  0.0  0.000000      0.0     0.0      0.0      0.0   \n",
       "1    0.0    0.0  ...  0.0  0.000000      0.0     0.0      0.0      0.0   \n",
       "2    0.0    0.0  ...  0.0  0.000000      0.0     0.0      0.0      0.0   \n",
       "3    0.0    0.0  ...  0.0  0.338588      0.0     0.0      0.0      0.0   \n",
       "4    0.0    0.0  ...  0.0  0.000000      0.0     0.0      0.0      0.0   \n",
       "\n",
       "     turkey   vanilla  waffle  walnut  \n",
       "0  0.000000  0.221726     0.0     0.0  \n",
       "1  0.000000  0.000000     0.0     0.0  \n",
       "2  0.000000  0.000000     0.0     0.0  \n",
       "3  0.000000  0.332390     0.0     0.0  \n",
       "4  0.860684  0.000000     0.0     0.0  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge tfidf features and drop the originals\n",
    "\n",
    "df_tfidf_text = df_tfidf_text.merge(tfdif_bagOfWords_df,left_index=True, right_index=True)\n",
    "df_tfidf_text = df_tfidf_text.drop([\"text\",\"text_custom\",\"text_custom_str\",\"bag_of_words\",\"bag_of_words_str\"], axis=1)\n",
    "df_tfidf_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Split the Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the features from the target\n",
    "y = df_tfidf_text[\"sentiment\"]\n",
    "X = df_tfidf_text.drop([\"key\",\"stars\",\"helpful_yes\",\"helpful_no\",\"rating\",\"sentiment\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ahoy</th>\n",
       "      <th>almond</th>\n",
       "      <th>apple</th>\n",
       "      <th>baked</th>\n",
       "      <th>banana</th>\n",
       "      <th>bean</th>\n",
       "      <th>berry</th>\n",
       "      <th>bigger</th>\n",
       "      <th>bitter</th>\n",
       "      <th>blackberry</th>\n",
       "      <th>...</th>\n",
       "      <th>tea</th>\n",
       "      <th>texture</th>\n",
       "      <th>toasted</th>\n",
       "      <th>toffee</th>\n",
       "      <th>topping</th>\n",
       "      <th>truffle</th>\n",
       "      <th>turkey</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>waffle</th>\n",
       "      <th>walnut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3419.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>0.010329</td>\n",
       "      <td>0.021232</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019108</td>\n",
       "      <td>0.039769</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.042277</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.001550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.059228</td>\n",
       "      <td>0.088283</td>\n",
       "      <td>0.062821</td>\n",
       "      <td>0.046585</td>\n",
       "      <td>0.057069</td>\n",
       "      <td>0.081466</td>\n",
       "      <td>0.098355</td>\n",
       "      <td>0.070906</td>\n",
       "      <td>0.045611</td>\n",
       "      <td>0.037671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112775</td>\n",
       "      <td>0.140670</td>\n",
       "      <td>0.039044</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>0.047092</td>\n",
       "      <td>0.065181</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.141353</td>\n",
       "      <td>0.035717</td>\n",
       "      <td>0.031186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.835487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855563</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.786024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.767140</td>\n",
       "      <td>0.906459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ahoy       almond        apple        baked       banana  \\\n",
       "count  3419.000000  3419.000000  3419.000000  3419.000000  3419.000000   \n",
       "mean      0.005298     0.015278     0.006196     0.003150     0.004962   \n",
       "std       0.059228     0.088283     0.062821     0.046585     0.057069   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.835487     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              bean        berry       bigger       bitter   blackberry  ...  \\\n",
       "count  3419.000000  3419.000000  3419.000000  3419.000000  3419.000000  ...   \n",
       "mean      0.010329     0.021232     0.006484     0.003491     0.002118  ...   \n",
       "std       0.081466     0.098355     0.070906     0.045611     0.037671  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     0.855563  ...   \n",
       "\n",
       "               tea      texture      toasted       toffee      topping  \\\n",
       "count  3419.000000  3419.000000  3419.000000  3419.000000  3419.000000   \n",
       "mean      0.019108     0.039769     0.002983     0.002642     0.003373   \n",
       "std       0.112775     0.140670     0.039044     0.042865     0.047092   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     0.786024     1.000000     1.000000   \n",
       "\n",
       "           truffle       turkey      vanilla       waffle       walnut  \n",
       "count  3419.000000  3419.000000  3419.000000  3419.000000  3419.000000  \n",
       "mean      0.007310     0.000447     0.042277     0.002242     0.001550  \n",
       "std       0.065181     0.018632     0.141353     0.035717     0.031186  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     0.860684     1.000000     0.767140     0.906459  \n",
       "\n",
       "[8 rows x 126 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2735\n",
       "0     684\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2070, 0: 494})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normal train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# 75% split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1,\n",
    "                                                   test_size=0.25)\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2564, 126)\n",
      "(855, 126)\n",
      "(2564,)\n",
      "(855,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Balanced Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "rf_model = BalancedRandomForestClassifier(n_estimators=128, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data.\n",
    "predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Random Forest\n",
      "Accuracy Score\n",
      "0.6783625730994152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Calculating the accuracy score.\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(str('Balanced Random Forest'))\n",
    "print(str('Accuracy Score'))\n",
    "print((acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Random Forest\n",
      "Confusion Matrix\n",
      "                      Predicted Neg Sentiment  Predicted Pos Sentiment\n",
      "Actual Neg Sentiment                      106                       84\n",
      "Actual Pos Sentiment                      191                      474\n"
     ]
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Neg Sentiment\", \"Actual Pos Sentiment\"], columns=[\"Predicted Neg Sentiment\", \"Predicted Pos Sentiment\"])\n",
    "\n",
    "cm_df\n",
    "\n",
    "print(str('Balanced Random Forest'))\n",
    "print(str('Confusion Matrix'))\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Random Forest\n",
      "Imbalanced Classification Report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.36      0.56      0.71      0.44      0.63      0.39       190\n",
      "          1       0.85      0.71      0.56      0.78      0.63      0.40       665\n",
      "\n",
      "avg / total       0.74      0.68      0.59      0.70      0.63      0.40       855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(str('Balanced Random Forest'))\n",
    "print(str('Imbalanced Classification Report'))\n",
    "print(classification_report_imbalanced(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.056748293926680744, 'vanilla'),\n",
       " (0.03430188764725658, 'choc'),\n",
       " (0.03274515072809185, 'chocolate'),\n",
       " (0.031648581423790324, 'caramel'),\n",
       " (0.02887063144796896, 'sweet'),\n",
       " (0.0284848443026955, 'creamy'),\n",
       " (0.0279989876836284, 'cookie'),\n",
       " (0.027022288364314365, 'nut'),\n",
       " (0.026699772484031457, 'gum'),\n",
       " (0.023699442465230713, 'butter'),\n",
       " (0.02195156899392367, 'chunk'),\n",
       " (0.020881619638601856, 'texture'),\n",
       " (0.019458960742531083, 'tea'),\n",
       " (0.019204846709509817, 'piece'),\n",
       " (0.019132665840595923, 'swirl'),\n",
       " (0.01876370655129205, 'dairy'),\n",
       " (0.01811324112649644, 'chip'),\n",
       " (0.017391301675143377, 'dough'),\n",
       " (0.016656280889716792, 'pistachio'),\n",
       " (0.01638624416485298, 'bean'),\n",
       " (0.016320112958190424, 'smooth'),\n",
       " (0.015002950413744914, 'peanut'),\n",
       " (0.01404543809723437, 'almond'),\n",
       " (0.013996145751314698, 'rich'),\n",
       " (0.013907518177421863, 'coffee'),\n",
       " (0.013885194321089773, 'natural'),\n",
       " (0.013188165417063037, 'syrup'),\n",
       " (0.012639718891352923, 'berry'),\n",
       " (0.012212493280883368, 'consistency'),\n",
       " (0.011756920948672539, 'tart'),\n",
       " (0.011744156419504536, 'pie'),\n",
       " (0.011487406805640848, 'crunch'),\n",
       " (0.011483017255980279, 'truffle'),\n",
       " (0.011106005347966786, 'sea'),\n",
       " (0.0109406956712641, 'fudge'),\n",
       " (0.010898770458752195, 'cake'),\n",
       " (0.009335454011216701, 'pb'),\n",
       " (0.009036721225691356, 'mint'),\n",
       " (0.00848057915955139, 'marshmallow'),\n",
       " (0.007643261263200274, 'brownie'),\n",
       " (0.007221120536799767, 'flake'),\n",
       " (0.0071323268600229596, 'pecan'),\n",
       " (0.006805357413505933, 'cheesecake'),\n",
       " (0.006632938859366454, 'salt'),\n",
       " (0.006328350829667904, 'graham'),\n",
       " (0.006113808402637004, 'swirled'),\n",
       " (0.006088392508392002, 'dark'),\n",
       " (0.005692876374245875, 'raspberry'),\n",
       " (0.005687881756888887, 'rum'),\n",
       " (0.005555261665915024, 'crumb'),\n",
       " (0.00548807542531647, 'blend'),\n",
       " (0.005473200312101186, 'bourbon'),\n",
       " (0.005045298974980506, 'pretzel'),\n",
       " (0.0050320048617313266, 'snicker'),\n",
       " (0.004981791088423425, 'oat'),\n",
       " (0.004900452280087017, 'mango'),\n",
       " (0.004861684948234464, 'cacao'),\n",
       " (0.004850674645303225, 'cherry'),\n",
       " (0.004810461982303819, 'salty'),\n",
       " (0.004542846249299609, 'sour'),\n",
       " (0.004426580763478328, 'cracker'),\n",
       " (0.004269519625294241, 'cocoa'),\n",
       " (0.0042132054310118116, 'bun'),\n",
       " (0.004194658329254473, 'candy'),\n",
       " (0.004126216650390292, 'cinnamon'),\n",
       " (0.004054105693832449, 'smore'),\n",
       " (0.003904051754441466, 'covered'),\n",
       " (0.003831398869151373, 'icy'),\n",
       " (0.003677239995777844, 'smores'),\n",
       " (0.0036746868754733457, 'coconut'),\n",
       " (0.0036445805453143043, 'dense'),\n",
       " (0.0036345173898895983, 'soft'),\n",
       " (0.0033889353873101566, 'cone'),\n",
       " (0.0033545828344847843, 'speck'),\n",
       " (0.0031330626768789785, 'bigger'),\n",
       " (0.0031252590404451273, 'crunchy'),\n",
       " (0.0031057831199467834, 'bitter'),\n",
       " (0.002887598613087785, 'apple'),\n",
       " (0.0028739006499103625, 'strawberry'),\n",
       " (0.0028478583990508297, 'sweetness'),\n",
       " (0.0027766648978780834, 'course'),\n",
       " (0.0027461421876140905, 'dulce'),\n",
       " (0.002743998425997146, 'carmel'),\n",
       " (0.002720840073190961, 'lemon'),\n",
       " (0.0026344810584257054, 'layered'),\n",
       " (0.0025799929306029186, 'potato'),\n",
       " (0.0025684975977733238, 'fruit'),\n",
       " (0.0024750568818813884, 'buttery'),\n",
       " (0.00245710944703867, 'chewy'),\n",
       " (0.0023803680665180986, 'baked'),\n",
       " (0.0023748068033573166, 'hazelnut'),\n",
       " (0.0022573955992333354, 'sweeter'),\n",
       " (0.0021816838692007316, 'banana'),\n",
       " (0.002175365321075413, 'sweetener'),\n",
       " (0.002090959609116215, 'sauce'),\n",
       " (0.002089262088750026, 'blackberry'),\n",
       " (0.0020466479193066026, 'ahoy'),\n",
       " (0.0020348906303919536, 'oreo'),\n",
       " (0.0017901800547345662, 'pumpkin'),\n",
       " (0.0017704339808323436, 'matcha'),\n",
       " (0.0016755230912473707, 'toffee'),\n",
       " (0.0014678381096092285, 'peppermint'),\n",
       " (0.0013809936932420732, 'rocky'),\n",
       " (0.0013759025865133002, 'creaminess'),\n",
       " (0.0013488603770401835, 'gooey'),\n",
       " (0.0013280889353808265, 'crust'),\n",
       " (0.0012763564849803397, 'chunky'),\n",
       " (0.001263951861336642, 'topping'),\n",
       " (0.0011707969648527942, 'toasted'),\n",
       " (0.0011359913157910654, 'gritty'),\n",
       " (0.001043869497922239, 'oatmeal'),\n",
       " (0.0009878324588627216, 'spice'),\n",
       " (0.000982930951122172, 'salted'),\n",
       " (0.0008912980928188733, 'blended'),\n",
       " (0.0008746013918117889, 'chocolaty'),\n",
       " (0.0007096959219522219, 'silky'),\n",
       " (0.0005676236225073994, 'chocolatey'),\n",
       " (0.0004874502859685317, 'walnut'),\n",
       " (0.0004126558360108694, 'espresso'),\n",
       " (0.0004103139827159663, 'raisin'),\n",
       " (0.00034640395196778684, 'waffle'),\n",
       " (0.0002944173934219026, 'minty'),\n",
       " (0.0002673662777424803, 'turkey'),\n",
       " (0.00025705522190038507, 'crispy'),\n",
       " (0.00018224080551769765, 'sicilian'),\n",
       " (8.157214310759122e-05, 'honey')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importance = sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features\n",
      "Ranked by Importance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.056748293926680744, 'vanilla'),\n",
       " (0.03430188764725658, 'choc'),\n",
       " (0.03274515072809185, 'chocolate'),\n",
       " (0.031648581423790324, 'caramel'),\n",
       " (0.02887063144796896, 'sweet'),\n",
       " (0.0284848443026955, 'creamy'),\n",
       " (0.0279989876836284, 'cookie'),\n",
       " (0.027022288364314365, 'nut'),\n",
       " (0.026699772484031457, 'gum'),\n",
       " (0.023699442465230713, 'butter')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(str('Top 10 Features'))\n",
    "print(str('Ranked by Importance'))\n",
    "display(feature_importance[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 10 Features\n",
      "Ranked by Importance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.0005676236225073994, 'chocolatey'),\n",
       " (0.0004874502859685317, 'walnut'),\n",
       " (0.0004126558360108694, 'espresso'),\n",
       " (0.0004103139827159663, 'raisin'),\n",
       " (0.00034640395196778684, 'waffle'),\n",
       " (0.0002944173934219026, 'minty'),\n",
       " (0.0002673662777424803, 'turkey'),\n",
       " (0.00025705522190038507, 'crispy'),\n",
       " (0.00018224080551769765, 'sicilian'),\n",
       " (8.157214310759122e-05, 'honey')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(str('Bottom 10 Features'))\n",
    "print(str('Ranked by Importance'))\n",
    "display(feature_importance[-10:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
