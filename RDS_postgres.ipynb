{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RDS_postgres.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyLPBPo3Scrt",
        "outputId": "a380e629-80ed-465b-dec7-8642ba131343"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 2.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.0'\n",
        "spark_version = 'spark-3.0.2'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connected to cloud\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connecting to ppa.\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (105 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGuOkRb5S188",
        "outputId": "94073de7-34a8-4de6-d19b-963bf0855c76"
      },
      "source": [
        "# Download the Postgres driver that will allow Spark to interact with Postgres.\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-27 23:41:38--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar.1’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  4.78MB/s    in 0.2s    \n",
            "\n",
            "2021-05-27 23:41:39 (4.78 MB/s) - ‘postgresql-42.2.16.jar.1’ saved [1002883/1002883]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEqHo0UnS_0H"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Final-Challenge\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87X47tW5Tj0l"
      },
      "source": [
        "**Load Data into Spark DataFrame and Create DataFrames to match tables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSQjxkcHTG8h",
        "outputId": "6cc84293-16ff-4544-9a5a-b0aa417095fb"
      },
      "source": [
        "# Create product dataframe\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://wrennk-ice-cream.s3.amazonaws.com/products.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "products_df = spark.read.option(\"encoding\", \"UTF-8\").csv(SparkFiles.get(\"products.csv\"), sep=\",\", header=True, inferSchema=True)\n",
        "products_df.show(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----+-------------------+--------------------+--------------------+------+------------+--------------------+\n",
            "|brand| key|               name|             subhead|         description|rating|rating_count|         ingredients|\n",
            "+-----+----+-------------------+--------------------+--------------------+------+------------+--------------------+\n",
            "|   bj|0_bj|Salted Caramel Core|Sweet Cream Ice C...|Find your way to ...|   3.7|         208|CREAM, SKIM MILK,...|\n",
            "|   bj|1_bj|Netflix & Chilll'd™|Peanut Butter Ice...|There’s something...|   4.0|         127|CREAM, SKIM MILK,...|\n",
            "|   bj|2_bj|       Chip Happens|A Cold Mess of Ch...|Sometimes “chip” ...|   4.7|         130|CREAM, LIQUID SUG...|\n",
            "|   bj|3_bj|            Cannoli|Mascarpone Ice Cr...|As a Limited Batc...|   3.6|          70|CREAM, SKIM MILK,...|\n",
            "|   bj|4_bj|     Gimme S’more!™|Toasted Marshmall...|It’s a gimme: the...|   4.5|         281|CREAM, SKIM MILK,...|\n",
            "+-----+----+-------------------+--------------------+--------------------+------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRoDi4RjaKU9",
        "outputId": "2af145c5-04d9-428b-e142-47774222ae39"
      },
      "source": [
        "# Create review dataframe\n",
        "url = \"https://wrennk-ice-cream.s3.amazonaws.com/reviews.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "reviews_df = spark.read.option(\"encoding\", \"UTF-8\").csv(SparkFiles.get(\"reviews.csv\"), sep=\",\", header=True, inferSchema=True)\n",
        "reviews_df.show(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------+--------------+----------+--------------------+--------------------+-----------+----------+--------------------+-----+-----------+-------+-----+\n",
            "|  brand|         key|        author|      date|               stars|               title|helpful_yes|helpful_no|                text|taste|ingredients|texture|likes|\n",
            "+-------+------------+--------------+----------+--------------------+--------------------+-----------+----------+--------------------+-----+-----------+-------+-----+\n",
            "|     bj|        0_bj|Ilovebennjerry|2017-04-15|                   3|Not enough brownies!|       10.0|       3.0|Super good, don't...| null|       null|   null| null|\n",
            "|Overall| good flavor|       texture|      idea| and brownies. No...|                null|       null|      null|                null| null|       null|   null| null|\n",
            "|     bj|        0_bj| Sweettooth909|2020-01-05|                   5|I’m OBSESSED with...|        3.0|       0.0|I decided to try ...| null|       null|   null| null|\n",
            "|     bj|        0_bj|     LaTanga71|2018-04-26|                   3|My favorite...Mor...|        5.0|       2.0|My caramel core b...| null|       null|   null| null|\n",
            "|     bj|        0_bj|    chicago220|2018-01-14|                   5|         Obsessed!!!|       24.0|       1.0|Why are people co...| null|       null|   null| null|\n",
            "+-------+------------+--------------+----------+--------------------+--------------------+-----------+----------+--------------------+-----+-----------+-------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePb2LcN0aNpo",
        "outputId": "9c53588a-76f9-4eaa-8697-47d72eb9af62"
      },
      "source": [
        "# Create clean_review dataframe\n",
        "url = \"https://wrennk-ice-cream.s3.amazonaws.com/clean_reviews.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "clean_reviews_df = spark.read.option(\"encoding\", \"UTF-8\").csv(SparkFiles.get(\"clean_reviews.csv\"), sep=\",\", header=True, inferSchema=True)\n",
        "clean_reviews_df.show(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-----+-----------+----------+--------------------+\n",
            "| key|stars|helpful_yes|helpful_no|                text|\n",
            "+----+-----+-----------+----------+--------------------+\n",
            "|0_bj|    3|       10.0|       3.0|Super good, dont ...|\n",
            "|0_bj|    5|        3.0|       0.0|I decided to try ...|\n",
            "|0_bj|    3|        5.0|       2.0|My caramel core b...|\n",
            "|0_bj|    5|       24.0|       1.0|Why are people co...|\n",
            "|0_bj|    2|        3.0|       1.0|I bought this las...|\n",
            "+----+-----+-----------+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyyneIrcaRFu",
        "outputId": "b4c75c81-d2d6-4345-efee-f3a1775332df"
      },
      "source": [
        "# Create helpful_clean_review dataframe\n",
        "url = \"https://wrennk-ice-cream.s3.amazonaws.com/helpful_clean_reviews.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "helpful_clean_reviews_df = spark.read.option(\"encoding\", \"UTF-8\").csv(SparkFiles.get(\"helpful_clean_reviews.csv\"), sep=\",\", header=True, inferSchema=True)\n",
        "helpful_clean_reviews_df.show(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-----+-----------+----------+--------------------+\n",
            "| key|stars|helpful_yes|helpful_no|                text|\n",
            "+----+-----+-----------+----------+--------------------+\n",
            "|0_bj|    3|       10.0|       3.0|Super good, dont ...|\n",
            "|0_bj|    5|        3.0|       0.0|I decided to try ...|\n",
            "|0_bj|    3|        5.0|       2.0|My caramel core b...|\n",
            "|0_bj|    5|       24.0|       1.0|Why are people co...|\n",
            "|0_bj|    2|        3.0|       1.0|I bought this las...|\n",
            "+----+-----+-----------+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0f78TOOaVIW",
        "outputId": "61e9615b-c22d-4acb-9416-297f96b843e0"
      },
      "source": [
        "# Create high_rating dataframe\n",
        "url = \"https://wrennk-ice-cream.s3.amazonaws.com/high_rating.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "high_rating_df = spark.read.option(\"encoding\", \"UTF-8\").csv(SparkFiles.get(\"high_rating.csv\"), sep=\",\", header=True, inferSchema=True)\n",
        "high_rating_df.show(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+--------------------+--------------------+------+------------+\n",
            "| key|                name|         description|rating|rating_count|\n",
            "+----+--------------------+--------------------+------+------------+\n",
            "|1_bj| Netflix & Chilll'd™|There’s something...|   4.0|         127|\n",
            "|2_bj|        Chip Happens|Sometimes “chip” ...|   4.7|         130|\n",
            "|4_bj|      Gimme S’more!™|It’s a gimme: the...|   4.5|         281|\n",
            "|5_bj|Peanut Butter Hal...|If you were more ...|   4.9|          14|\n",
            "|6_bj|Berry Sweet Masca...|From the sweet bl...|   4.6|          10|\n",
            "+----+--------------------+--------------------+------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DbTEo3haij8",
        "outputId": "52a5e3bb-1e43-4aa8-dd25-d91aafcab485"
      },
      "source": [
        "# Create combined dataframe\n",
        "url = \"https://wrennk-ice-cream.s3.amazonaws.com/combined.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "combined_df = spark.read.option(\"encoding\", \"UTF-8\").csv(SparkFiles.get(\"combined.csv\"), sep=\",\", header=True, inferSchema=True)\n",
        "combined_df.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+----------+----+\n",
            "|                 key|                name|         description|              rating|        rating_count|stars|         helpful_yes|helpful_no|text|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+----------+----+\n",
            "|           0_breyers|     Natural Vanilla|Our Original Vani...|                null|                null| null|                null|      null|null|\n",
            "|When William Brey...| he based his rec...|               sugar| and milk? To mak...| the milk and cre...| null|                null|      null|null|\n",
            "|Do you see those ...| so you can enjoy...| knowing that you...|                null|                null| null|                null|      null|null|\n",
            "|Try Breyers® Natu...|                null|                null|                null|                null| null|                null|      null|null|\n",
            "|*The FDA states t...|                 4.1|                 467|                   1|                  35|    0|I have literally ...|      null|null|\n",
            "|           0_breyers|     Natural Vanilla|Our Original Vani...|                null|                null| null|                null|      null|null|\n",
            "|When William Brey...| he based his rec...|               sugar| and milk? To mak...| the milk and cre...| null|                null|      null|null|\n",
            "|Do you see those ...| so you can enjoy...| knowing that you...|                null|                null| null|                null|      null|null|\n",
            "|Try Breyers® Natu...|                null|                null|                null|                null| null|                null|      null|null|\n",
            "|*The FDA states t...|                 4.1|                 467|                   1|                   5|    0|Our family has be...|      null|null|\n",
            "|           0_breyers|     Natural Vanilla|Our Original Vani...|                null|                null| null|                null|      null|null|\n",
            "|When William Brey...| he based his rec...|               sugar| and milk? To mak...| the milk and cre...| null|                null|      null|null|\n",
            "|Do you see those ...| so you can enjoy...| knowing that you...|                null|                null| null|                null|      null|null|\n",
            "|Try Breyers® Natu...|                null|                null|                null|                null| null|                null|      null|null|\n",
            "|*The FDA states t...|                 4.1|                 467|                   3|                  73|    4|used to be my ver...|      null|null|\n",
            "|           0_breyers|     Natural Vanilla|Our Original Vani...|                null|                null| null|                null|      null|null|\n",
            "|When William Brey...| he based his rec...|               sugar| and milk? To mak...| the milk and cre...| null|                null|      null|null|\n",
            "|Do you see those ...| so you can enjoy...| knowing that you...|                null|                null| null|                null|      null|null|\n",
            "|Try Breyers® Natu...|                null|                null|                null|                null| null|                null|      null|null|\n",
            "|*The FDA states t...|                 4.1|                 467|                   1|                  27|    0|I used to swear b...|      null|null|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+----------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uofv8ydla6Wk"
      },
      "source": [
        "**Connect to the AWS RDS instance and write each DataFrame to its Table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFdl2LbmbFUQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}