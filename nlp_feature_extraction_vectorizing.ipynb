{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)\n",
    "## Feature Extraction & Vectorizing\n",
    "\n",
    "The primary goal of this notebook is to get the data compatible with supervised machine learning algorithms. \n",
    "\n",
    "At this stage in the project, it is beneficial to decision making to see as much of the output as possible to ensure the code\n",
    "is working as intended and adjust/improve where possible.  The markdowns here are meant to be a guide to walk through what the\n",
    "code is doing and why.\n",
    "\n",
    "This is a shell state of the pre-processing model. Need to limit the \"tokenized reviews\" dataset to the 3000 most common words for step 7 vectorizing of \"text\" to reflect accurately.\n",
    "\n",
    "## Scope of this notebook:\n",
    "\n",
    "### 1.  Data Inspection\n",
    "### 2.  Add Sentiment Feature to data set\n",
    "### 3.  Create Product Sentiment Reviews Dataset\n",
    "### 4.  Tokenize \"text\" words\n",
    "### 5.  Bag of Words - Extract the 3000 most common words\n",
    "### 6.  Create Tokenized Reviews data set\n",
    "### 7.  TFID Vectorizing for Supervised  ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are starting with a review dataset that has been filtered down to ice cream products that have achieved an amazon rating of 4 stars or higher joined on the key feature with consumer reviews that have been filtered down those that received more helpful_yes votes than helpful_no votes.\n",
    "\n",
    "(insert why we chose to filter and clean the dataset this way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  \n",
       "0  I am interested in the flavoring components us...     4.1  \n",
       "1  Boy, was I surprised when I got my Bryers home...     4.1  \n",
       "2  I havent purchased this product in awhile and ...     4.1  \n",
       "3  The Natural Vanilla recipe change to include T...     4.1  \n",
       "4  I had the same issue with breyers. I finally f...     4.1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data source\n",
    "df = pd.read_csv(\"Resources/helpful_clean_reviews_combined.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the data is key to ensuring its compatible with any functions or methods required for the code to perform.\n",
    "We know, off the cusp, that unsupervised ML doesn't like strings or null values so lets identify any of those. Also, we will remove any duplicate data as it doesn't tell us anything new and may skew results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows     :  3424\n",
      "Columns  :  6\n",
      "\n",
      "Features :  ['key', 'stars', 'helpful_yes', 'helpful_no', 'text', 'rating']\n",
      "\n",
      "Missing values :   0\n",
      "\n",
      "Unique values :  \n",
      " key             184\n",
      "stars             5\n",
      "helpful_yes      66\n",
      "helpful_no       20\n",
      "text           3419\n",
      "rating           11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data overview\n",
    "print ('Rows     : ', df.shape[0])\n",
    "print ('Columns  : ', df.shape[1])\n",
    "print ('\\nFeatures : ', df.columns.tolist())\n",
    "print ('\\nMissing values :  ', df.isnull().sum().values.sum())\n",
    "print ('\\nUnique values :  \\n', df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3424 entries, 0 to 3423\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   key          3424 non-null   object \n",
      " 1   stars        3424 non-null   int64  \n",
      " 2   helpful_yes  3424 non-null   int64  \n",
      " 3   helpful_no   3424 non-null   int64  \n",
      " 4   text         3424 non-null   object \n",
      " 5   rating       3424 non-null   float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 160.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# find missing values and view data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column key has 0 null values\n",
      "Column stars has 0 null values\n",
      "Column helpful_yes has 0 null values\n",
      "Column helpful_no has 0 null values\n",
      "Column text has 0 null values\n",
      "Column rating has 0 null values\n"
     ]
    }
   ],
   "source": [
    "# Find null values\n",
    "for column in df.columns:\n",
    "    print(f\"Column {column} has {df[column].isnull().sum()} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries: 4\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate entries\n",
    "# duplicate entries are not telling us anything new  and can skew results\n",
    "print(f\"Duplicate entries: {(df.duplicated().sum()) * 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I tried the new flavor with layers and it was ...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>love this ice cream, taste fantastic!! will ne...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite cream. Where can I find th...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The best tasting ice cream out there! It is ve...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite, period. If I cant find it...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3419 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "0     0_breyers      1           11           0   \n",
       "1     0_breyers      1            7           0   \n",
       "2     0_breyers      1            8           0   \n",
       "3     0_breyers      1            4           0   \n",
       "4     0_breyers      5           21           2   \n",
       "...         ...    ...          ...         ...   \n",
       "3419       9_hd      5            1           0   \n",
       "3420       9_hd      5            1           0   \n",
       "3421       9_hd      5            1           0   \n",
       "3422       9_hd      5            1           0   \n",
       "3423       9_hd      5            1           0   \n",
       "\n",
       "                                                   text  rating  \n",
       "0     I am interested in the flavoring components us...     4.1  \n",
       "1     Boy, was I surprised when I got my Bryers home...     4.1  \n",
       "2     I havent purchased this product in awhile and ...     4.1  \n",
       "3     The Natural Vanilla recipe change to include T...     4.1  \n",
       "4     I had the same issue with breyers. I finally f...     4.1  \n",
       "...                                                 ...     ...  \n",
       "3419  I tried the new flavor with layers and it was ...     4.9  \n",
       "3420  love this ice cream, taste fantastic!! will ne...     4.9  \n",
       "3421  This is my favorite cream. Where can I find th...     4.9  \n",
       "3422  The best tasting ice cream out there! It is ve...     4.9  \n",
       "3423  This is my favorite, period. If I cant find it...     4.9  \n",
       "\n",
       "[3419 rows x 6 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate entries\n",
    "df.drop_duplicates(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I tried the new flavor with layers and it was ...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>love this ice cream, taste fantastic!! will ne...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite cream. Where can I find th...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The best tasting ice cream out there! It is ve...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite, period. If I cant find it...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3424 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "0     0_breyers      1           11           0   \n",
       "1     0_breyers      1            7           0   \n",
       "2     0_breyers      1            8           0   \n",
       "3     0_breyers      1            4           0   \n",
       "4     0_breyers      5           21           2   \n",
       "...         ...    ...          ...         ...   \n",
       "3419       9_hd      5            1           0   \n",
       "3420       9_hd      5            1           0   \n",
       "3421       9_hd      5            1           0   \n",
       "3422       9_hd      5            1           0   \n",
       "3423       9_hd      5            1           0   \n",
       "\n",
       "                                                   text  rating  \n",
       "0     I am interested in the flavoring components us...     4.1  \n",
       "1     Boy, was I surprised when I got my Bryers home...     4.1  \n",
       "2     I havent purchased this product in awhile and ...     4.1  \n",
       "3     The Natural Vanilla recipe change to include T...     4.1  \n",
       "4     I had the same issue with breyers. I finally f...     4.1  \n",
       "...                                                 ...     ...  \n",
       "3419  I tried the new flavor with layers and it was ...     4.9  \n",
       "3420  love this ice cream, taste fantastic!! will ne...     4.9  \n",
       "3421  This is my favorite cream. Where can I find th...     4.9  \n",
       "3422  The best tasting ice cream out there! It is ve...     4.9  \n",
       "3423  This is my favorite, period. If I cant find it...     4.9  \n",
       "\n",
       "[3424 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create data_df to hold new dataset without duplicates\n",
    "df_data = pd.DataFrame(df)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Add Sentiment Feature to data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include a sentiment in case we run a sentiment analysis, which is very popular with NLP modeling. \n",
    "Here we will assign a value of 1 to reflect positive sentiment. This consists of star rating greater than or equal to 5. \n",
    "Any review with a star rating less than 5 gets a value of 0 to reflect negative sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \n",
       "0  I am interested in the flavoring components us...     4.1        NaN  \n",
       "1  Boy, was I surprised when I got my Bryers home...     4.1        NaN  \n",
       "2  I havent purchased this product in awhile and ...     4.1        NaN  \n",
       "3  The Natural Vanilla recipe change to include T...     4.1        NaN  \n",
       "4  I had the same issue with breyers. I finally f...     4.1        NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add sentiment column to df_data\n",
    "df_data['sentiment'] = pd.Series(dtype='int64')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \n",
       "0  I am interested in the flavoring components us...     4.1          0  \n",
       "1  Boy, was I surprised when I got my Bryers home...     4.1          0  \n",
       "2  I havent purchased this product in awhile and ...     4.1          0  \n",
       "3  The Natural Vanilla recipe change to include T...     4.1          0  \n",
       "4  I had the same issue with breyers. I finally f...     4.1          1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign 1 for positive sentiment, 0 for negative\n",
    "# I'm bad with functions, this link helped me get it right. \n",
    "# https://stackoverflow.com/questions/30953299/pandas-if-row-in-column-a-contains-x-write-y-to-row-in-column-b\n",
    "def applyFunc(s):\n",
    "    if s >= 5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# populate column        \n",
    "df_data['sentiment'] = df_data['stars'].apply(applyFunc)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>After trying Bryers Natural Vanilla Ice Cream ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>if this flavor is ever retired, i swear -- my ...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>I am an ice cream addict and this flavour has ...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>This flavor is sloop good, I eat about 2 a day...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I tried the new flavor with layers and it was ...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>love this ice cream, taste fantastic!! will ne...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite cream. Where can I find th...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The best tasting ice cream out there! It is ve...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite, period. If I cant find it...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2530 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "4     0_breyers      5           21           2   \n",
       "56    0_breyers      5           53          32   \n",
       "74         0_hd      5           27           0   \n",
       "75         0_hd      5           10           0   \n",
       "76         0_hd      5            4           0   \n",
       "...         ...    ...          ...         ...   \n",
       "3419       9_hd      5            1           0   \n",
       "3420       9_hd      5            1           0   \n",
       "3421       9_hd      5            1           0   \n",
       "3422       9_hd      5            1           0   \n",
       "3423       9_hd      5            1           0   \n",
       "\n",
       "                                                   text  rating  sentiment  \n",
       "4     I had the same issue with breyers. I finally f...     4.1          1  \n",
       "56    After trying Bryers Natural Vanilla Ice Cream ...     4.1          1  \n",
       "74    if this flavor is ever retired, i swear -- my ...     4.9          1  \n",
       "75    I am an ice cream addict and this flavour has ...     4.9          1  \n",
       "76    This flavor is sloop good, I eat about 2 a day...     4.9          1  \n",
       "...                                                 ...     ...        ...  \n",
       "3419  I tried the new flavor with layers and it was ...     4.9          1  \n",
       "3420  love this ice cream, taste fantastic!! will ne...     4.9          1  \n",
       "3421  This is my favorite cream. Where can I find th...     4.9          1  \n",
       "3422  The best tasting ice cream out there! It is ve...     4.9          1  \n",
       "3423  This is my favorite, period. If I cant find it...     4.9          1  \n",
       "\n",
       "[2530 rows x 7 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create positive sentiment dataframe\n",
    "# delete if not used in rest of notebook\n",
    "# again, seeing output may drive inspiration for new ideas or provide clarity on the direction. \n",
    "\n",
    "df_positive_sentiment = df_data[df_data['sentiment'] ==1]\n",
    "df_positive_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I rarely eat ice cream these days but bought t...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>I dont buy a lot of ice cream, gelato, or swee...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>The top layers are great. Tastes like cheeseca...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I was really excited to try this flavor but wa...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>All of your flavors are such high quality and ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tastes great except there was absolutely no ch...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>894 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "0     0_breyers      1           11           0   \n",
       "1     0_breyers      1            7           0   \n",
       "2     0_breyers      1            8           0   \n",
       "3     0_breyers      1            4           0   \n",
       "5     0_breyers      1            4           0   \n",
       "...         ...    ...          ...         ...   \n",
       "3349  8_talenti      2            3           1   \n",
       "3352  8_talenti      3            3           0   \n",
       "3358  8_talenti      3            2           1   \n",
       "3361  8_talenti      3            1           0   \n",
       "3372  8_talenti      2            1           0   \n",
       "\n",
       "                                                   text  rating  sentiment  \n",
       "0     I am interested in the flavoring components us...     4.1          0  \n",
       "1     Boy, was I surprised when I got my Bryers home...     4.1          0  \n",
       "2     I havent purchased this product in awhile and ...     4.1          0  \n",
       "3     The Natural Vanilla recipe change to include T...     4.1          0  \n",
       "5     I rarely eat ice cream these days but bought t...     4.1          0  \n",
       "...                                                 ...     ...        ...  \n",
       "3349  I dont buy a lot of ice cream, gelato, or swee...     4.3          0  \n",
       "3352  The top layers are great. Tastes like cheeseca...     4.3          0  \n",
       "3358  I was really excited to try this flavor but wa...     4.3          0  \n",
       "3361  All of your flavors are such high quality and ...     4.3          0  \n",
       "3372  Tastes great except there was absolutely no ch...     4.3          0  \n",
       "\n",
       "[894 rows x 7 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create negative sentiment dataframe\n",
    "# delete if not used in rest of notebook\n",
    "\n",
    "df_negative_sentiment = df_data[df_data['sentiment'] ==0]\n",
    "df_negative_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Create Product Sentiment Reviews Dataset\n",
    "\n",
    "This is the helpful_cleaned_reviews_combined.csv with duplicates removed and sentiment column added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create product_sentiment_reviews.csv\n",
    "df_data.to_csv(\"Resources/product_sentiment_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Tokenize \"text\" words\n",
    "\n",
    "We are working with text data we have to count the number of words in the text, as well as, identify the number of times a particular word is present. We Tokenize the text data to do just that.\n",
    "\n",
    "Here is where all the magic of splitting the reviews into single words, putting each word into lower case, lemmatizing each to its base form, removing punctuations and excluding stop words occurs. We still have more work to do to clean this up, but hey, the code is there. \n",
    "\n",
    "While there are plenty of library and program options, we've tokenized with NLTK as this is the best way to see whats happening step by step.  \n",
    "\n",
    "As we do more research, we may change our minds and adopt libraries and programs that offer \"cleaner\" coding opportunities and better performance now that we have a clearer vision of what the code is doing function by function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer dataframe\n",
    "df_tokenize = pd.DataFrame(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Tokenizer library\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "\n",
    "# RegexpTokenizer will tokenize according to any regular expression assigned. \n",
    "# The regular expression r'\\w+' matches any pattern consisting of one or more consecutive letters.\n",
    "reTokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all the words from all the reviews into one list\n",
    "\n",
    "# initialize list to hold words\n",
    "all_words = []\n",
    "\n",
    "\n",
    "for i in range(len(df_tokenize['text'])):\n",
    "    # separate review text into a list of words\n",
    "    tokens = reTokenizer.tokenize(df_tokenize['text'][i])\n",
    "    \n",
    "    \n",
    "    df_tokenize['text'][i] = []\n",
    "    \n",
    "    # iterate through tokens\n",
    "    for word in tokens:\n",
    "        # exclude stop words\n",
    "        if word not in stop_words:\n",
    "            # lower the case of each word\n",
    "            word = word.lower()\n",
    "            # Lemmatize words into a standard form and avoid counting the same word more than once\n",
    "            word = lemmatizer.lemmatize(word)\n",
    "            # add to list of words\n",
    "            all_words.append(word)\n",
    "            df_tokenize['text'][i].append(word)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Bag of Words? Extract the 3000 most common words\n",
    "\n",
    "Of the 3000 most common words, frequency ranges from 13-3175, with one word \"i\" as an outlier at 7281.\n",
    "To Do: make a print statement that tells us this automatically since we will be changing this to find the perfect data for our modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 7281),\n",
       " ('cream', 3175),\n",
       " ('ice', 3018),\n",
       " ('flavor', 2681),\n",
       " ('chocolate', 1419),\n",
       " ('it', 1212),\n",
       " ('the', 1202),\n",
       " ('love', 1123),\n",
       " ('this', 1039),\n",
       " ('like', 987),\n",
       " ('one', 909),\n",
       " ('taste', 857),\n",
       " ('favorite', 725),\n",
       " ('good', 676),\n",
       " ('best', 645),\n",
       " ('vanilla', 566),\n",
       " ('would', 547),\n",
       " ('pint', 534),\n",
       " ('ever', 518),\n",
       " ('time', 504),\n",
       " ('get', 470),\n",
       " ('creamy', 459),\n",
       " ('cookie', 456),\n",
       " ('store', 453),\n",
       " ('find', 432),\n",
       " ('delicious', 432),\n",
       " ('please', 431),\n",
       " ('great', 398),\n",
       " ('try', 390),\n",
       " ('really', 389),\n",
       " ('im', 383),\n",
       " ('butter', 383),\n",
       " ('tried', 379),\n",
       " ('sweet', 379),\n",
       " ('gelato', 373),\n",
       " ('perfect', 370),\n",
       " ('make', 368),\n",
       " ('chip', 352),\n",
       " ('product', 351),\n",
       " ('buy', 348),\n",
       " ('texture', 346),\n",
       " ('amazing', 344),\n",
       " ('my', 341),\n",
       " ('caramel', 341),\n",
       " ('breyers', 339),\n",
       " ('new', 339),\n",
       " ('eat', 338),\n",
       " ('peanut', 337),\n",
       " ('ive', 334),\n",
       " ('first', 331),\n",
       " ('year', 327),\n",
       " ('much', 314),\n",
       " ('go', 308),\n",
       " ('dairy', 308),\n",
       " ('never', 305),\n",
       " ('bought', 285),\n",
       " ('dont', 266),\n",
       " ('every', 266),\n",
       " ('chunk', 264),\n",
       " ('back', 254),\n",
       " ('always', 252),\n",
       " ('so', 249),\n",
       " ('better', 246),\n",
       " ('could', 240),\n",
       " ('even', 240),\n",
       " ('coffee', 240),\n",
       " ('talenti', 231),\n",
       " ('free', 230),\n",
       " ('jerry', 229),\n",
       " ('ben', 226),\n",
       " ('cooky', 224),\n",
       " ('eating', 223),\n",
       " ('little', 218),\n",
       " ('dough', 218),\n",
       " ('cant', 211),\n",
       " ('thing', 209),\n",
       " ('swirl', 208),\n",
       " ('brand', 206),\n",
       " ('day', 204),\n",
       " ('rich', 204),\n",
       " ('also', 203),\n",
       " ('container', 203),\n",
       " ('since', 202),\n",
       " ('way', 202),\n",
       " ('fudge', 200),\n",
       " ('disappointed', 194),\n",
       " ('bit', 194),\n",
       " ('definitely', 194),\n",
       " ('mint', 193),\n",
       " ('found', 191),\n",
       " ('well', 189),\n",
       " ('smooth', 187),\n",
       " ('tasted', 185),\n",
       " ('made', 183),\n",
       " ('ingredient', 182),\n",
       " ('if', 182),\n",
       " ('piece', 182),\n",
       " ('haagen', 180),\n",
       " ('thank', 179),\n",
       " ('know', 178),\n",
       " ('we', 178),\n",
       " ('used', 177),\n",
       " ('but', 177),\n",
       " ('say', 177),\n",
       " ('hard', 177),\n",
       " ('treat', 176),\n",
       " ('layer', 175),\n",
       " ('a', 173),\n",
       " ('bite', 170),\n",
       " ('see', 169),\n",
       " ('still', 169),\n",
       " ('dazs', 168),\n",
       " ('last', 167),\n",
       " ('almond', 167),\n",
       " ('right', 166),\n",
       " ('think', 166),\n",
       " ('wish', 166),\n",
       " ('got', 164),\n",
       " ('and', 163),\n",
       " ('keep', 163),\n",
       " ('need', 161),\n",
       " ('fan', 158),\n",
       " ('review', 156),\n",
       " ('come', 156),\n",
       " ('something', 156),\n",
       " ('absolutely', 152),\n",
       " ('two', 150),\n",
       " ('far', 150),\n",
       " ('milk', 148),\n",
       " ('sugar', 147),\n",
       " ('enough', 147),\n",
       " ('buying', 145),\n",
       " ('many', 141),\n",
       " ('whole', 140),\n",
       " ('non', 139),\n",
       " ('not', 139),\n",
       " ('you', 138),\n",
       " ('there', 137),\n",
       " ('3', 137),\n",
       " ('loved', 136),\n",
       " ('stop', 136),\n",
       " ('combination', 135),\n",
       " ('thought', 134),\n",
       " ('hope', 133),\n",
       " ('real', 131),\n",
       " ('2', 129),\n",
       " ('another', 129),\n",
       " ('brownie', 129),\n",
       " ('grocery', 128),\n",
       " ('feel', 128),\n",
       " ('trying', 128),\n",
       " ('didnt', 127),\n",
       " ('lot', 127),\n",
       " ('pistachio', 126),\n",
       " ('raspberry', 125),\n",
       " ('want', 124),\n",
       " ('almost', 124),\n",
       " ('bar', 124),\n",
       " ('dessert', 123),\n",
       " ('cherry', 123),\n",
       " ('amount', 123),\n",
       " ('ago', 122),\n",
       " ('change', 120),\n",
       " ('making', 120),\n",
       " ('core', 120),\n",
       " ('sure', 119),\n",
       " ('u', 119),\n",
       " ('natural', 118),\n",
       " ('however', 118),\n",
       " ('half', 116),\n",
       " ('crunch', 116),\n",
       " ('strawberry', 114),\n",
       " ('going', 113),\n",
       " ('cheesecake', 113),\n",
       " ('frozen', 112),\n",
       " ('different', 112),\n",
       " ('though', 112),\n",
       " ('local', 112),\n",
       " ('week', 111),\n",
       " ('bad', 110),\n",
       " ('enjoy', 110),\n",
       " ('quality', 109),\n",
       " ('nice', 109),\n",
       " ('recommend', 108),\n",
       " ('freezer', 108),\n",
       " ('saw', 108),\n",
       " ('mango', 108),\n",
       " ('add', 107),\n",
       " ('big', 107),\n",
       " ('super', 106),\n",
       " ('regular', 106),\n",
       " ('actually', 105),\n",
       " ('went', 105),\n",
       " ('family', 104),\n",
       " ('marshmallow', 103),\n",
       " ('icecream', 102),\n",
       " ('away', 101),\n",
       " ('look', 101),\n",
       " ('people', 100),\n",
       " ('give', 100),\n",
       " ('5', 100),\n",
       " ('life', 99),\n",
       " ('dark', 99),\n",
       " ('nothing', 98),\n",
       " ('pie', 97),\n",
       " ('long', 97),\n",
       " ('month', 97),\n",
       " ('food', 96),\n",
       " ('available', 96),\n",
       " ('oreo', 96),\n",
       " ('mouth', 95),\n",
       " ('coconut', 95),\n",
       " ('recipe', 94),\n",
       " ('put', 93),\n",
       " ('b', 93),\n",
       " ('everything', 93),\n",
       " ('thanks', 93),\n",
       " ('top', 92),\n",
       " ('stuff', 92),\n",
       " ('happy', 92),\n",
       " ('changed', 91),\n",
       " ('take', 91),\n",
       " ('without', 91),\n",
       " ('calorie', 91),\n",
       " ('around', 90),\n",
       " ('husband', 90),\n",
       " ('doesnt', 90),\n",
       " ('j', 90),\n",
       " ('when', 89),\n",
       " ('tasting', 89),\n",
       " ('just', 89),\n",
       " ('looking', 88),\n",
       " ('size', 88),\n",
       " ('usually', 88),\n",
       " ('cinnamon', 88),\n",
       " ('they', 87),\n",
       " ('part', 87),\n",
       " ('bean', 86),\n",
       " ('1', 86),\n",
       " ('old', 86),\n",
       " ('no', 86),\n",
       " ('now', 85),\n",
       " ('world', 84),\n",
       " ('came', 83),\n",
       " ('excited', 83),\n",
       " ('sad', 82),\n",
       " ('graham', 82),\n",
       " ('anything', 81),\n",
       " ('full', 81),\n",
       " ('entire', 81),\n",
       " ('wonderful', 81),\n",
       " ('huge', 80),\n",
       " ('le', 79),\n",
       " ('purchased', 79),\n",
       " ('stock', 79),\n",
       " ('home', 78),\n",
       " ('purchase', 78),\n",
       " ('maybe', 78),\n",
       " ('sitting', 78),\n",
       " ('glad', 78),\n",
       " ('4', 78),\n",
       " ('in', 77),\n",
       " ('very', 76),\n",
       " ('longer', 76),\n",
       " ('base', 76),\n",
       " ('balance', 76),\n",
       " ('awesome', 76),\n",
       " ('recently', 75),\n",
       " ('pecan', 75),\n",
       " ('night', 75),\n",
       " ('crunchy', 75),\n",
       " ('kind', 75),\n",
       " ('hand', 74),\n",
       " ('low', 73),\n",
       " ('literally', 73),\n",
       " ('kid', 73),\n",
       " ('salty', 73),\n",
       " ('bourbon', 73),\n",
       " ('carb', 73),\n",
       " ('star', 72),\n",
       " ('all', 72),\n",
       " ('lover', 72),\n",
       " ('able', 72),\n",
       " ('truffle', 71),\n",
       " ('together', 71),\n",
       " ('cracker', 71),\n",
       " ('anymore', 70),\n",
       " ('instead', 70),\n",
       " ('10', 70),\n",
       " ('pretzel', 70),\n",
       " ('yummy', 69),\n",
       " ('friend', 68),\n",
       " ('pretty', 67),\n",
       " ('light', 67),\n",
       " ('mix', 67),\n",
       " ('oh', 67),\n",
       " ('added', 66),\n",
       " ('bring', 66),\n",
       " ('couldnt', 66),\n",
       " ('problem', 66),\n",
       " ('batch', 66),\n",
       " ('must', 65),\n",
       " ('thats', 65),\n",
       " ('cup', 65),\n",
       " ('wasnt', 65),\n",
       " ('next', 65),\n",
       " ('disappointing', 64),\n",
       " ('tell', 64),\n",
       " ('highly', 64),\n",
       " ('honestly', 64),\n",
       " ('decided', 63),\n",
       " ('ill', 63),\n",
       " ('perfectly', 63),\n",
       " ('carbs', 63),\n",
       " ('ahoy', 63),\n",
       " ('unfortunately', 62),\n",
       " ('scoop', 62),\n",
       " ('experience', 62),\n",
       " ('others', 62),\n",
       " ('target', 62),\n",
       " ('price', 61),\n",
       " ('what', 61),\n",
       " ('wanted', 61),\n",
       " ('heaven', 61),\n",
       " ('bottom', 61),\n",
       " ('several', 60),\n",
       " ('let', 60),\n",
       " ('ate', 60),\n",
       " ('absolute', 60),\n",
       " ('tasty', 60),\n",
       " ('craving', 60),\n",
       " ('left', 59),\n",
       " ('gone', 59),\n",
       " ('soft', 59),\n",
       " ('reason', 59),\n",
       " ('cannot', 59),\n",
       " ('said', 59),\n",
       " ('small', 59),\n",
       " ('hit', 59),\n",
       " ('hooked', 59),\n",
       " ('received', 59),\n",
       " ('spoonful', 58),\n",
       " ('seems', 58),\n",
       " ('past', 58),\n",
       " ('believe', 58),\n",
       " ('getting', 58),\n",
       " ('flavour', 58),\n",
       " ('spoon', 58),\n",
       " ('sorbet', 58),\n",
       " ('that', 57),\n",
       " ('least', 57),\n",
       " ('everyone', 57),\n",
       " ('work', 57),\n",
       " ('nut', 57),\n",
       " ('wait', 57),\n",
       " ('melt', 56),\n",
       " ('vegan', 56),\n",
       " ('sorbetto', 56),\n",
       " ('probably', 56),\n",
       " ('addicted', 56),\n",
       " ('today', 55),\n",
       " ('isnt', 55),\n",
       " ('use', 55),\n",
       " ('service', 55),\n",
       " ('worth', 55),\n",
       " ('eaten', 55),\n",
       " ('consumer', 55),\n",
       " ('omg', 55),\n",
       " ('wrong', 55),\n",
       " ('strong', 55),\n",
       " ('why', 54),\n",
       " ('took', 54),\n",
       " ('may', 54),\n",
       " ('especially', 54),\n",
       " ('might', 54),\n",
       " ('banana', 54),\n",
       " ('area', 53),\n",
       " ('cone', 53),\n",
       " ('more', 53),\n",
       " ('cake', 53),\n",
       " ('finally', 52),\n",
       " ('sold', 52),\n",
       " ('couple', 52),\n",
       " ('carton', 52),\n",
       " ('option', 51),\n",
       " ('flavored', 51),\n",
       " ('overall', 51),\n",
       " ('peppermint', 51),\n",
       " ('havent', 50),\n",
       " ('decadent', 50),\n",
       " ('wow', 50),\n",
       " ('lactose', 50),\n",
       " ('else', 49),\n",
       " ('shelf', 49),\n",
       " ('for', 49),\n",
       " ('forward', 49),\n",
       " ('then', 48),\n",
       " ('gum', 48),\n",
       " ('version', 48),\n",
       " ('noticed', 48),\n",
       " ('artificial', 48),\n",
       " ('either', 48),\n",
       " ('lol', 48),\n",
       " ('list', 47),\n",
       " ('looked', 47),\n",
       " ('original', 47),\n",
       " ('apple', 47),\n",
       " ('is', 46),\n",
       " ('com', 46),\n",
       " ('to', 46),\n",
       " ('totally', 46),\n",
       " ('guy', 46),\n",
       " ('id', 46),\n",
       " ('help', 46),\n",
       " ('combo', 46),\n",
       " ('limited', 46),\n",
       " ('blend', 46),\n",
       " ('issue', 45),\n",
       " ('high', 45),\n",
       " ('quite', 45),\n",
       " ('three', 45),\n",
       " ('fact', 45),\n",
       " ('throughout', 45),\n",
       " ('exactly', 45),\n",
       " ('covered', 45),\n",
       " ('pumpkin', 45),\n",
       " ('market', 44),\n",
       " ('yet', 44),\n",
       " ('sometimes', 44),\n",
       " ('seriously', 44),\n",
       " ('end', 44),\n",
       " ('special', 44),\n",
       " ('unilever', 43),\n",
       " ('plain', 43),\n",
       " ('line', 43),\n",
       " ('fresh', 43),\n",
       " ('pb', 43),\n",
       " ('yum', 43),\n",
       " ('diet', 43),\n",
       " ('enjoyed', 43),\n",
       " ('second', 42),\n",
       " ('will', 42),\n",
       " ('wont', 42),\n",
       " ('cold', 42),\n",
       " ('side', 42),\n",
       " ('stopped', 42),\n",
       " ('simply', 42),\n",
       " ('tonight', 42),\n",
       " ('youre', 42),\n",
       " ('tub', 42),\n",
       " ('baked', 42),\n",
       " ('liked', 42),\n",
       " ('barely', 42),\n",
       " ('salted', 42),\n",
       " ('delight', 42),\n",
       " ('phish', 42),\n",
       " ('smores', 42),\n",
       " ('anyone', 41),\n",
       " ('choice', 41),\n",
       " ('place', 41),\n",
       " ('happened', 41),\n",
       " ('expecting', 41),\n",
       " ('rest', 41),\n",
       " ('anywhere', 41),\n",
       " ('salt', 41),\n",
       " ('finding', 41),\n",
       " ('green', 41),\n",
       " ('surprised', 40),\n",
       " ('sell', 40),\n",
       " ('truly', 40),\n",
       " ('single', 40),\n",
       " ('permanent', 40),\n",
       " ('missing', 40),\n",
       " ('obsessed', 40),\n",
       " ('these', 40),\n",
       " ('discontinued', 40),\n",
       " ('box', 39),\n",
       " ('hint', 39),\n",
       " ('refreshing', 39),\n",
       " ('simple', 39),\n",
       " ('done', 39),\n",
       " ('become', 39),\n",
       " ('extremely', 39),\n",
       " ('sweetness', 39),\n",
       " ('someone', 39),\n",
       " ('easy', 39),\n",
       " ('carry', 39),\n",
       " ('completely', 38),\n",
       " ('true', 38),\n",
       " ('opened', 38),\n",
       " ('white', 38),\n",
       " ('mean', 38),\n",
       " ('walmart', 38),\n",
       " ('mixed', 38),\n",
       " ('excellent', 38),\n",
       " ('summer', 38),\n",
       " ('live', 37),\n",
       " ('gave', 37),\n",
       " ('discontinue', 37),\n",
       " ('yes', 37),\n",
       " ('lemon', 37),\n",
       " ('per', 37),\n",
       " ('perfection', 37),\n",
       " ('soon', 37),\n",
       " ('fantastic', 37),\n",
       " ('serving', 37),\n",
       " ('bigger', 37),\n",
       " ('mine', 37),\n",
       " ('oatmeal', 37),\n",
       " ('disappointment', 36),\n",
       " ('finished', 36),\n",
       " ('company', 36),\n",
       " ('consistency', 36),\n",
       " ('satisfying', 36),\n",
       " ('influenster', 36),\n",
       " ('write', 36),\n",
       " ('point', 35),\n",
       " ('thinking', 35),\n",
       " ('extra', 35),\n",
       " ('name', 35),\n",
       " ('opinion', 35),\n",
       " ('testing', 35),\n",
       " ('after', 35),\n",
       " ('goodness', 35),\n",
       " ('son', 35),\n",
       " ('dream', 35),\n",
       " ('fell', 35),\n",
       " ('item', 35),\n",
       " ('already', 35),\n",
       " ('forever', 35),\n",
       " ('syrup', 34),\n",
       " ('customer', 34),\n",
       " ('read', 34),\n",
       " ('often', 34),\n",
       " ('ok', 34),\n",
       " ('sorry', 34),\n",
       " ('only', 34),\n",
       " ('word', 34),\n",
       " ('jar', 34),\n",
       " ('close', 34),\n",
       " ('overpowering', 34),\n",
       " ('crust', 34),\n",
       " ('outside', 34),\n",
       " ('pure', 33),\n",
       " ('weird', 33),\n",
       " ('person', 33),\n",
       " ('similar', 33),\n",
       " ('7', 33),\n",
       " ('hear', 33),\n",
       " ('type', 33),\n",
       " ('snack', 33),\n",
       " ('felt', 33),\n",
       " ('spot', 33),\n",
       " ('hoping', 33),\n",
       " ('start', 32),\n",
       " ('brought', 32),\n",
       " ('compare', 32),\n",
       " ('reach', 32),\n",
       " ('hubby', 32),\n",
       " ('mind', 32),\n",
       " ('sale', 32),\n",
       " ('idea', 32),\n",
       " ('net', 32),\n",
       " ('6', 32),\n",
       " ('difficult', 32),\n",
       " ('round', 32),\n",
       " ('bowl', 31),\n",
       " ('picked', 31),\n",
       " ('difference', 31),\n",
       " ('overly', 31),\n",
       " ('actual', 31),\n",
       " ('label', 31),\n",
       " ('bun', 31),\n",
       " ('carmel', 31),\n",
       " ('although', 31),\n",
       " ('coupon', 31),\n",
       " ('agree', 30),\n",
       " ('daz', 30),\n",
       " ('except', 30),\n",
       " ('knew', 30),\n",
       " ('with', 30),\n",
       " ('none', 30),\n",
       " ('thick', 30),\n",
       " ('gluten', 30),\n",
       " ('rum', 30),\n",
       " ('tea', 30),\n",
       " ('money', 29),\n",
       " ('wa', 29),\n",
       " ('prefer', 29),\n",
       " ('across', 29),\n",
       " ('mom', 29),\n",
       " ('directly', 29),\n",
       " ('hot', 29),\n",
       " ('corn', 28),\n",
       " ('started', 28),\n",
       " ('run', 28),\n",
       " ('formula', 28),\n",
       " ('due', 28),\n",
       " ('aftertaste', 28),\n",
       " ('daughter', 28),\n",
       " ('minute', 28),\n",
       " ('hazelnut', 28),\n",
       " ('smart', 28),\n",
       " ('chance', 28),\n",
       " ('die', 28),\n",
       " ('reviewer', 27),\n",
       " ('stick', 27),\n",
       " ('website', 27),\n",
       " ('using', 27),\n",
       " ('creaminess', 27),\n",
       " ('cost', 27),\n",
       " ('told', 27),\n",
       " ('gimme', 27),\n",
       " ('course', 27),\n",
       " ('flake', 27),\n",
       " ('bark', 27),\n",
       " ('discovered', 27),\n",
       " ('intolerant', 27),\n",
       " ('deep', 27),\n",
       " ('remember', 26),\n",
       " ('rid', 26),\n",
       " ('stay', 26),\n",
       " ('feeling', 26),\n",
       " ('shop', 26),\n",
       " ('subtle', 26),\n",
       " ('incredible', 26),\n",
       " ('flavorful', 26),\n",
       " ('surprise', 26),\n",
       " ('complaint', 26),\n",
       " ('de', 26),\n",
       " ('job', 26),\n",
       " ('filled', 26),\n",
       " ('upon', 26),\n",
       " ('tiny', 26),\n",
       " ('bud', 26),\n",
       " ('seen', 26),\n",
       " ('state', 25),\n",
       " ('classic', 25),\n",
       " ('purchasing', 25),\n",
       " ('miss', 25),\n",
       " ('care', 25),\n",
       " ('along', 25),\n",
       " ('addition', 25),\n",
       " ('have', 25),\n",
       " ('based', 25),\n",
       " ('impressed', 25),\n",
       " ('fat', 25),\n",
       " ('while', 25),\n",
       " ('chewy', 25),\n",
       " ('easily', 25),\n",
       " ('tart', 25),\n",
       " ('fruit', 25),\n",
       " ('intense', 25),\n",
       " ('smaller', 25),\n",
       " ('hd', 25),\n",
       " ('disappoint', 25),\n",
       " ('20', 25),\n",
       " ('heavenly', 25),\n",
       " ('sooo', 25),\n",
       " ('plus', 25),\n",
       " ('double', 25),\n",
       " ('häagen', 25),\n",
       " ('garcia', 25),\n",
       " ('smore', 25),\n",
       " ('expect', 24),\n",
       " ('rather', 24),\n",
       " ('melted', 24),\n",
       " ('seem', 24),\n",
       " ('sadly', 24),\n",
       " ('gallon', 24),\n",
       " ('check', 24),\n",
       " ('compared', 24),\n",
       " ('ribbon', 24),\n",
       " ('giving', 24),\n",
       " ('hardly', 24),\n",
       " ('note', 24),\n",
       " ('toasted', 24),\n",
       " ('inside', 24),\n",
       " ('open', 24),\n",
       " ('whim', 24),\n",
       " ('balanced', 24),\n",
       " ('buttery', 24),\n",
       " ('coming', 23),\n",
       " ('ruined', 23),\n",
       " ('lack', 23),\n",
       " ('called', 23),\n",
       " ('at', 23),\n",
       " ('fix', 23),\n",
       " ('candy', 23),\n",
       " ('leave', 23),\n",
       " ('anyway', 23),\n",
       " ('waiting', 23),\n",
       " ('had', 23),\n",
       " ('nearly', 23),\n",
       " ('case', 23),\n",
       " ('share', 23),\n",
       " ('normally', 23),\n",
       " ('slightly', 23),\n",
       " ('level', 23),\n",
       " ('consider', 23),\n",
       " ('dulce', 23),\n",
       " ('hate', 23),\n",
       " ('chunky', 23),\n",
       " ('s', 23),\n",
       " ('five', 23),\n",
       " ('potato', 23),\n",
       " ('matcha', 23),\n",
       " ('irish', 23),\n",
       " ('flavoring', 22),\n",
       " ('boy', 22),\n",
       " ('homemade', 22),\n",
       " ('by', 22),\n",
       " ('he', 22),\n",
       " ('expensive', 22),\n",
       " ('honest', 22),\n",
       " ('guess', 22),\n",
       " ('supermarket', 22),\n",
       " ('continue', 22),\n",
       " ('topping', 22),\n",
       " ('create', 22),\n",
       " ('ended', 22),\n",
       " ('unlike', 22),\n",
       " ('everywhere', 22),\n",
       " ('future', 22),\n",
       " ('save', 22),\n",
       " ('pick', 22),\n",
       " ('allergy', 22),\n",
       " ('gooey', 22),\n",
       " ('spicy', 22),\n",
       " ('black', 21),\n",
       " ('expected', 21),\n",
       " ('became', 21),\n",
       " ('order', 21),\n",
       " ('kept', 21),\n",
       " ('fine', 21),\n",
       " ('icy', 21),\n",
       " ('15', 21),\n",
       " ('house', 21),\n",
       " ('needed', 21),\n",
       " ('can', 21),\n",
       " ('larger', 21),\n",
       " ('chubby', 21),\n",
       " ('stronger', 21),\n",
       " ('were', 21),\n",
       " ('leche', 21),\n",
       " ('n', 21),\n",
       " ('break', 21),\n",
       " ('dinner', 21),\n",
       " ('youll', 21),\n",
       " ('particular', 21),\n",
       " ('number', 21),\n",
       " ('brown', 21),\n",
       " ('mediterranean', 21),\n",
       " ('near', 21),\n",
       " ('trio', 21),\n",
       " ('sicilian', 21),\n",
       " ('youve', 20),\n",
       " ('alternative', 20),\n",
       " ('most', 20),\n",
       " ('decade', 20),\n",
       " ('content', 20),\n",
       " ('lately', 20),\n",
       " ('finish', 20),\n",
       " ('email', 20),\n",
       " ('mini', 20),\n",
       " ('perhaps', 20),\n",
       " ('middle', 20),\n",
       " ('reminds', 20),\n",
       " ('touch', 20),\n",
       " ('gram', 20),\n",
       " ('30', 20),\n",
       " ('appreciate', 20),\n",
       " ('picture', 20),\n",
       " ('yesterday', 20),\n",
       " ('certainly', 20),\n",
       " ('boyfriend', 20),\n",
       " ('possible', 20),\n",
       " ('toffee', 20),\n",
       " ('ha', 20),\n",
       " ('beat', 20),\n",
       " ('holiday', 20),\n",
       " ('whenever', 20),\n",
       " ('vegetable', 19),\n",
       " ('immediately', 19),\n",
       " ('upset', 19),\n",
       " ('personally', 19),\n",
       " ('portion', 19),\n",
       " ('shame', 19),\n",
       " ('team', 19),\n",
       " ('100', 19),\n",
       " ('gotten', 19),\n",
       " ('sauce', 19),\n",
       " ('water', 19),\n",
       " ('wife', 19),\n",
       " ('ratio', 19),\n",
       " ('swirled', 19),\n",
       " ('period', 19),\n",
       " ('theyre', 19),\n",
       " ('contains', 19),\n",
       " ('alcohol', 19),\n",
       " ('waste', 19),\n",
       " ('contact', 19),\n",
       " ('shopping', 19),\n",
       " ('dig', 19),\n",
       " ('twice', 19),\n",
       " ('describe', 19),\n",
       " ('mostly', 19),\n",
       " ('thin', 19),\n",
       " ('chocolatey', 19),\n",
       " ('searching', 19),\n",
       " ('normal', 19),\n",
       " ('blackberry', 19),\n",
       " ('chemical', 18),\n",
       " ('lower', 18),\n",
       " ('basically', 18),\n",
       " ('alone', 18),\n",
       " ('sick', 18),\n",
       " ('turn', 18),\n",
       " ('choose', 18),\n",
       " ('okay', 18),\n",
       " ('ton', 18),\n",
       " ('mild', 18),\n",
       " ('saying', 18),\n",
       " ('delightful', 18),\n",
       " ('crispy', 18),\n",
       " ('waffle', 18),\n",
       " ('fabulous', 18),\n",
       " ('sea', 18),\n",
       " ('wouldnt', 18),\n",
       " ('halo', 18),\n",
       " ('paired', 18),\n",
       " ('ask', 18),\n",
       " ('later', 18),\n",
       " ('deal', 18),\n",
       " ('large', 18),\n",
       " ('heart', 18),\n",
       " ('honey', 18),\n",
       " ('addictive', 18),\n",
       " ('berry', 18),\n",
       " ('spirit', 18),\n",
       " ('lost', 17),\n",
       " ('stand', 17),\n",
       " ('adding', 17),\n",
       " ('whats', 17),\n",
       " ('imagine', 17),\n",
       " ('cheap', 17),\n",
       " ('our', 17),\n",
       " ('cut', 17),\n",
       " ('fish', 17),\n",
       " ('too', 17),\n",
       " ('variety', 17),\n",
       " ('etc', 17),\n",
       " ('packaging', 17),\n",
       " ('understand', 17),\n",
       " ('weight', 17),\n",
       " ('recent', 17),\n",
       " ('favourite', 17),\n",
       " ('color', 17),\n",
       " ('eye', 17),\n",
       " ('recommended', 17),\n",
       " ('where', 17),\n",
       " ('bland', 17),\n",
       " ('edition', 17),\n",
       " ('straight', 17),\n",
       " ('8', 17),\n",
       " ('seemed', 17),\n",
       " ('fun', 17),\n",
       " ('silky', 17),\n",
       " ('desert', 17),\n",
       " ('deliciousness', 17),\n",
       " ('espresso', 17),\n",
       " ('lid', 17),\n",
       " ('party', 17),\n",
       " ('pleasure', 17),\n",
       " ('dry', 17),\n",
       " ('skeptical', 17),\n",
       " ('york', 17),\n",
       " ('bryers', 16),\n",
       " ('package', 16),\n",
       " ('your', 16),\n",
       " ('sit', 16),\n",
       " ('reading', 16),\n",
       " ('taking', 16),\n",
       " ('offer', 16),\n",
       " ('rating', 16),\n",
       " ('late', 16),\n",
       " ('total', 16),\n",
       " ('pleasantly', 16),\n",
       " ('sound', 16),\n",
       " ('g', 16),\n",
       " ('rock', 16),\n",
       " ('carrying', 16),\n",
       " ('selling', 16),\n",
       " ('protein', 16),\n",
       " ('return', 16),\n",
       " ('italy', 16),\n",
       " ('once', 16),\n",
       " ('crazy', 16),\n",
       " ('keto', 16),\n",
       " ('blended', 16),\n",
       " ('d', 16),\n",
       " ('multiple', 16),\n",
       " ('loaded', 16),\n",
       " ('layered', 16),\n",
       " ('trip', 16),\n",
       " ('crumb', 16),\n",
       " ('soy', 16),\n",
       " ('incredibly', 16),\n",
       " ('minty', 16),\n",
       " ('spice', 16),\n",
       " ('ruby', 16),\n",
       " ('component', 15),\n",
       " ('leaf', 15),\n",
       " ('hill', 15),\n",
       " ('road', 15),\n",
       " ('unique', 15),\n",
       " ('grocer', 15),\n",
       " ('on', 15),\n",
       " ('of', 15),\n",
       " ('quickly', 15),\n",
       " ('strange', 15),\n",
       " ('child', 15),\n",
       " ('fall', 15),\n",
       " ('section', 15),\n",
       " ('guilty', 15),\n",
       " ('typically', 15),\n",
       " ('purpose', 15),\n",
       " ('drive', 15),\n",
       " ('gritty', 15),\n",
       " ('snicker', 15),\n",
       " ('egg', 15),\n",
       " ('substitute', 15),\n",
       " ('dense', 15),\n",
       " ('choc', 15),\n",
       " ('pleased', 15),\n",
       " ('oat', 15),\n",
       " ('generous', 15),\n",
       " ('greatest', 15),\n",
       " ('brew', 15),\n",
       " ('created', 15),\n",
       " ('cool', 15),\n",
       " ('cause', 15),\n",
       " ('birthday', 15),\n",
       " ('winner', 15),\n",
       " ('season', 15),\n",
       " ('notice', 14),\n",
       " ('heard', 14),\n",
       " ('do', 14),\n",
       " ('previous', 14),\n",
       " ('tongue', 14),\n",
       " ('cow', 14),\n",
       " ('unless', 14),\n",
       " ('planet', 14),\n",
       " ('rocky', 14),\n",
       " ('allergic', 14),\n",
       " ('terrible', 14),\n",
       " ('fake', 14),\n",
       " ('mess', 14),\n",
       " ('major', 14),\n",
       " ('sent', 14),\n",
       " ('seeing', 14),\n",
       " ('wanting', 14),\n",
       " ('luck', 14),\n",
       " ('bitter', 14),\n",
       " ('pregnant', 14),\n",
       " ('within', 14),\n",
       " ('tooth', 14),\n",
       " ('otherwise', 14),\n",
       " ('healthy', 14),\n",
       " ('creation', 14),\n",
       " ('gross', 14),\n",
       " ('publix', 14),\n",
       " ('worst', 14),\n",
       " ('impossible', 14),\n",
       " ('doubt', 14),\n",
       " ('expectation', 14),\n",
       " ('short', 14),\n",
       " ('richness', 14),\n",
       " ('god', 14),\n",
       " ('sour', 14),\n",
       " ('admit', 14),\n",
       " ('oil', 14),\n",
       " ('chocolaty', 14),\n",
       " ('bummed', 14),\n",
       " ('usual', 14),\n",
       " ('soooo', 14),\n",
       " ('seasonal', 14),\n",
       " ('bailey', 14),\n",
       " ('besides', 13),\n",
       " ('rarely', 13),\n",
       " ('mistake', 13),\n",
       " ('quart', 13),\n",
       " ('clean', 13),\n",
       " ('center', 13),\n",
       " ('taken', 13),\n",
       " ('cocoa', 13),\n",
       " ('mile', 13),\n",
       " ('joy', 13),\n",
       " ('sweeter', 13),\n",
       " ('becomes', 13),\n",
       " ...]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the 3000 most common words from the list.\n",
    "\n",
    "from nltk import FreqDist\n",
    "\n",
    "all_words = FreqDist(all_words)\n",
    "most_common_words = all_words.most_common(3000)\n",
    "\n",
    "word_features = []\n",
    "for w in most_common_words:\n",
    "    word_features.append(w[0])\n",
    "    \n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  6253 unique words total in our text dataset.\n",
      "There are  3000 unique words in the most common words list.\n"
     ]
    }
   ],
   "source": [
    "print ('There are ', len(all_words), 'unique words total in our text dataset.')\n",
    "print ('There are ', len(most_common_words), 'unique words in the most common words list.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Create Tokenized Reviews data set\n",
    "\n",
    "The export is commented out because I haven't limited the text data to the 3000 most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenized_reviews.csv\n",
    "# df_tokenize.to_csv(\"Resources/tokenized_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, interested, flavoring, component, used, i,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[boy, i, surprised, i, got, bryers, home, disc...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, havent, purchased, product, awhile, surpri...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, natural, vanilla, recipe, change, includ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>[i, issue, breyers, i, finally, found, turkey,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \n",
       "0  [i, interested, flavoring, component, used, i,...     4.1          0  \n",
       "1  [boy, i, surprised, i, got, bryers, home, disc...     4.1          0  \n",
       "2  [i, havent, purchased, product, awhile, surpri...     4.1          0  \n",
       "3  [the, natural, vanilla, recipe, change, includ...     4.1          0  \n",
       "4  [i, issue, breyers, i, finally, found, turkey,...     4.1          1  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenize.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  Vectorizing for Supervised ML algorithms\n",
    "\n",
    "We can now iterate through each review in our Tokenized Reviews dataset and create a vector of 1's and 0's for a given review depending on which words from our chosen 3000 show up in that review. However we should think ahead a little --- which ML algorithm will we use, and what format does it prefer its data in?\n",
    "\n",
    "\n",
    "Only running TFID because of scaling benefits. \n",
    "I've vectorized both the key and text features though we may not need all of this. Just wanted to get it done since we are exploring.\n",
    "\n",
    "Links to education and code syntax:\n",
    "\n",
    "https://datascience.stackexchange.com/questions/22250/what-is-the-difference-between-a-hashing-vectorizer-and-a-tfidf-vectorizer\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFID Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_breyers</th>\n",
       "      <th>0_hd</th>\n",
       "      <th>0_talenti</th>\n",
       "      <th>10_bj</th>\n",
       "      <th>10_breyers</th>\n",
       "      <th>10_talenti</th>\n",
       "      <th>11_bj</th>\n",
       "      <th>11_breyers</th>\n",
       "      <th>11_talenti</th>\n",
       "      <th>12_bj</th>\n",
       "      <th>...</th>\n",
       "      <th>6_talenti</th>\n",
       "      <th>7_bj</th>\n",
       "      <th>7_breyers</th>\n",
       "      <th>7_hd</th>\n",
       "      <th>7_talenti</th>\n",
       "      <th>8_bj</th>\n",
       "      <th>8_hd</th>\n",
       "      <th>8_talenti</th>\n",
       "      <th>9_bj</th>\n",
       "      <th>9_hd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_breyers  0_hd  0_talenti  10_bj  10_breyers  10_talenti  11_bj  \\\n",
       "0        1.0   0.0        0.0    0.0         0.0         0.0    0.0   \n",
       "1        1.0   0.0        0.0    0.0         0.0         0.0    0.0   \n",
       "2        1.0   0.0        0.0    0.0         0.0         0.0    0.0   \n",
       "3        1.0   0.0        0.0    0.0         0.0         0.0    0.0   \n",
       "4        1.0   0.0        0.0    0.0         0.0         0.0    0.0   \n",
       "\n",
       "   11_breyers  11_talenti  12_bj  ...  6_talenti  7_bj  7_breyers  7_hd  \\\n",
       "0         0.0         0.0    0.0  ...        0.0   0.0        0.0   0.0   \n",
       "1         0.0         0.0    0.0  ...        0.0   0.0        0.0   0.0   \n",
       "2         0.0         0.0    0.0  ...        0.0   0.0        0.0   0.0   \n",
       "3         0.0         0.0    0.0  ...        0.0   0.0        0.0   0.0   \n",
       "4         0.0         0.0    0.0  ...        0.0   0.0        0.0   0.0   \n",
       "\n",
       "   7_talenti  8_bj  8_hd  8_talenti  9_bj  9_hd  \n",
       "0        0.0   0.0   0.0        0.0   0.0   0.0  \n",
       "1        0.0   0.0   0.0        0.0   0.0   0.0  \n",
       "2        0.0   0.0   0.0        0.0   0.0   0.0  \n",
       "3        0.0   0.0   0.0        0.0   0.0   0.0  \n",
       "4        0.0   0.0   0.0        0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 184 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 'key' term frequencies weighted by their relative importance (IDF)\n",
    "\n",
    "df_tfidf_key = pd.DataFrame(df_tokenize)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "sparse_out_key = vectorizer.fit_transform(df_tfidf_key['key'])\n",
    "\n",
    "tfidf_key_df = pd.DataFrame(data = sparse_out_key.toarray(),\n",
    "                        columns = vectorizer.get_feature_names())\n",
    "\n",
    "tfidf_key_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3424 entries, 0 to 3423\n",
      "Columns: 184 entries, 0_breyers to 9_hd\n",
      "dtypes: float64(184)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "tfidf_key_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features :  ['0_breyers', '0_hd', '0_talenti', '10_bj', '10_breyers', '10_talenti', '11_bj', '11_breyers', '11_talenti', '12_bj', '12_breyers', '12_hd', '12_talenti', '13_bj', '13_hd', '13_talenti', '14_bj', '14_breyers', '14_hd', '14_talenti', '15_breyers', '15_hd', '15_talenti', '16_bj', '16_breyers', '16_hd', '16_talenti', '17_breyers', '17_hd', '17_talenti', '18_breyers', '18_hd', '18_talenti', '19_bj', '19_breyers', '19_hd', '19_talenti', '1_bj', '1_breyers', '1_hd', '1_talenti', '20_bj', '20_hd', '20_talenti', '21_bj', '21_breyers', '21_hd', '22_bj', '22_breyers', '22_hd', '22_talenti', '23_bj', '24_breyers', '24_hd', '24_talenti', '25_bj', '25_breyers', '25_hd', '25_talenti', '26_breyers', '26_hd', '26_talenti', '27_bj', '27_breyers', '27_hd', '27_talenti', '28_bj', '28_talenti', '29_bj', '29_hd', '29_talenti', '2_bj', '2_breyers', '2_hd', '2_talenti', '30_bj', '30_breyers', '30_hd', '30_talenti', '31_bj', '31_breyers', '31_hd', '31_talenti', '32_bj', '32_hd', '32_talenti', '33_bj', '33_breyers', '33_hd', '33_talenti', '34_bj', '34_hd', '34_talenti', '35_bj', '35_breyers', '35_hd', '35_talenti', '36_bj', '36_breyers', '36_hd', '37_bj', '37_hd', '37_talenti', '38_bj', '38_talenti', '39_bj', '39_breyers', '39_hd', '39_talenti', '3_breyers', '3_hd', '3_talenti', '40_breyers', '40_talenti', '41_bj', '41_hd', '41_talenti', '42_bj', '42_breyers', '42_hd', '43_bj', '43_hd', '44_bj', '44_hd', '44_talenti', '45_bj', '45_hd', '46_bj', '47_bj', '47_hd', '48_bj', '48_breyers', '48_hd', '49_bj', '49_hd', '4_bj', '4_breyers', '4_hd', '4_talenti', '50_breyers', '51_bj', '51_hd', '52_breyers', '53_hd', '54_bj', '55_bj', '55_breyers', '55_hd', '56_bj', '56_breyers', '56_hd', '58_breyers', '58_hd', '59_breyers', '5_bj', '5_breyers', '5_hd', '5_talenti', '60_breyers', '60_hd', '61_breyers', '61_hd', '62_hd', '63_breyers', '63_hd', '64_breyers', '64_hd', '65_breyers', '65_hd', '67_hd', '68_hd', '6_bj', '6_breyers', '6_hd', '6_talenti', '7_bj', '7_breyers', '7_hd', '7_talenti', '8_bj', '8_hd', '8_talenti', '9_bj', '9_hd']\n"
     ]
    }
   ],
   "source": [
    "print ('\\nFeatures : ', tfidf_key_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFID Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer\n",
    "df_tfidf_text = pd.DataFrame(df_tokenize)\n",
    "\n",
    "# convert text list to string and create string column\n",
    "# required for vectorizer, learned after getting error\n",
    "# https://stackoverflow.com/questions/45306988/column-of-lists-convert-list-to-string-as-a-new-column\n",
    "df_tfidf_text['text_str'] = df_tfidf_text['text'].apply(lambda x: ','.join(map(str, x)))\n",
    "\n",
    "df_tfidf_text.head()\n",
    "\n",
    "# create tokenized_reviews.csv\n",
    "df_tfidf_text.to_csv(\"Resources/tokenized_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>02</th>\n",
       "      <th>050</th>\n",
       "      <th>076840036745</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100lbs</th>\n",
       "      <th>101</th>\n",
       "      <th>...</th>\n",
       "      <th>yumtastic</th>\n",
       "      <th>yup</th>\n",
       "      <th>yuuummmyyy</th>\n",
       "      <th>zabaglione</th>\n",
       "      <th>zero</th>\n",
       "      <th>zesty</th>\n",
       "      <th>zing</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>țhe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00   02  050  076840036745   09   10  100  1000  100lbs  101  ...  \\\n",
       "0  0.0  0.0  0.0           0.0  0.0  0.0  0.0   0.0     0.0  0.0  ...   \n",
       "1  0.0  0.0  0.0           0.0  0.0  0.0  0.0   0.0     0.0  0.0  ...   \n",
       "2  0.0  0.0  0.0           0.0  0.0  0.0  0.0   0.0     0.0  0.0  ...   \n",
       "3  0.0  0.0  0.0           0.0  0.0  0.0  0.0   0.0     0.0  0.0  ...   \n",
       "4  0.0  0.0  0.0           0.0  0.0  0.0  0.0   0.0     0.0  0.0  ...   \n",
       "\n",
       "   yumtastic  yup  yuuummmyyy  zabaglione  zero  zesty  zing  zip  zone  țhe  \n",
       "0        0.0  0.0         0.0         0.0   0.0    0.0   0.0  0.0   0.0  0.0  \n",
       "1        0.0  0.0         0.0         0.0   0.0    0.0   0.0  0.0   0.0  0.0  \n",
       "2        0.0  0.0         0.0         0.0   0.0    0.0   0.0  0.0   0.0  0.0  \n",
       "3        0.0  0.0         0.0         0.0   0.0    0.0   0.0  0.0   0.0  0.0  \n",
       "4        0.0  0.0         0.0         0.0   0.0    0.0   0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 6218 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 'text' term frequencies weighted by their relative importance (IDF)\n",
    "vectorizer2 = TfidfVectorizer()\n",
    "\n",
    "sparse_out_text = vectorizer2.fit_transform(df_tfidf_text['text_str'])\n",
    "\n",
    "tfidf_text_df = pd.DataFrame(data = sparse_out_text.toarray(),\n",
    "                        columns = vectorizer2.get_feature_names())\n",
    "\n",
    "tfidf_text_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
