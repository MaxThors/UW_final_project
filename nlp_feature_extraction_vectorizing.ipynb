{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)\n",
    "## Feature Extraction & Vectorizing\n",
    "\n",
    "\n",
    "### Scope of this notebook:\n",
    "\n",
    "### 1.  Data Inspection\n",
    "### 2.  Add Sentiment Feature to data set\n",
    "### 3.  Create Product Sentiment Reviews Dataset\n",
    "### 4.  Tokenization, Normalization & Custom Stopword Filtering\n",
    "### 5.  Bag of Words - Extract the most common words\n",
    "### 6.  Create Tokenized Reviews data set\n",
    "### 7.  Term Frequency-Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  \n",
       "0  I am interested in the flavoring components us...     4.1  \n",
       "1  Boy, was I surprised when I got my Bryers home...     4.1  \n",
       "2  I havent purchased this product in awhile and ...     4.1  \n",
       "3  The Natural Vanilla recipe change to include T...     4.1  \n",
       "4  I had the same issue with breyers. I finally f...     4.1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data source\n",
    "df = pd.read_csv(\"Resources/helpful_clean_reviews_combined.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows     :  3424\n",
      "Columns  :  6\n",
      "\n",
      "Features :  ['key', 'stars', 'helpful_yes', 'helpful_no', 'text', 'rating']\n",
      "\n",
      "Missing values :   0\n",
      "\n",
      "Unique values :  \n",
      " key             184\n",
      "stars             5\n",
      "helpful_yes      66\n",
      "helpful_no       20\n",
      "text           3419\n",
      "rating           11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data overview\n",
    "print ('Rows     : ', df.shape[0])\n",
    "print ('Columns  : ', df.shape[1])\n",
    "print ('\\nFeatures : ', df.columns.tolist())\n",
    "print ('\\nMissing values :  ', df.isnull().sum().values.sum())\n",
    "print ('\\nUnique values :  \\n', df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3424 entries, 0 to 3423\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   key          3424 non-null   object \n",
      " 1   stars        3424 non-null   int64  \n",
      " 2   helpful_yes  3424 non-null   int64  \n",
      " 3   helpful_no   3424 non-null   int64  \n",
      " 4   text         3424 non-null   object \n",
      " 5   rating       3424 non-null   float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 160.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# find missing values and view data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column key has 0 null values\n",
      "Column stars has 0 null values\n",
      "Column helpful_yes has 0 null values\n",
      "Column helpful_no has 0 null values\n",
      "Column text has 0 null values\n",
      "Column rating has 0 null values\n"
     ]
    }
   ],
   "source": [
    "# Find null values\n",
    "for column in df.columns:\n",
    "    print(f\"Column {column} has {df[column].isnull().sum()} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries: 4\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate entries\n",
    "# duplicate entries are not telling us anything new  and can skew results\n",
    "print(f\"Duplicate entries: {(df.duplicated().sum()) * 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I tried the new flavor with layers and it was ...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>love this ice cream, taste fantastic!! will ne...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite cream. Where can I find th...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The best tasting ice cream out there! It is ve...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite, period. If I cant find it...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3419 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "0     0_breyers      1           11           0   \n",
       "1     0_breyers      1            7           0   \n",
       "2     0_breyers      1            8           0   \n",
       "3     0_breyers      1            4           0   \n",
       "4     0_breyers      5           21           2   \n",
       "...         ...    ...          ...         ...   \n",
       "3419       9_hd      5            1           0   \n",
       "3420       9_hd      5            1           0   \n",
       "3421       9_hd      5            1           0   \n",
       "3422       9_hd      5            1           0   \n",
       "3423       9_hd      5            1           0   \n",
       "\n",
       "                                                   text  rating  \n",
       "0     I am interested in the flavoring components us...     4.1  \n",
       "1     Boy, was I surprised when I got my Bryers home...     4.1  \n",
       "2     I havent purchased this product in awhile and ...     4.1  \n",
       "3     The Natural Vanilla recipe change to include T...     4.1  \n",
       "4     I had the same issue with breyers. I finally f...     4.1  \n",
       "...                                                 ...     ...  \n",
       "3419  I tried the new flavor with layers and it was ...     4.9  \n",
       "3420  love this ice cream, taste fantastic!! will ne...     4.9  \n",
       "3421  This is my favorite cream. Where can I find th...     4.9  \n",
       "3422  The best tasting ice cream out there! It is ve...     4.9  \n",
       "3423  This is my favorite, period. If I cant find it...     4.9  \n",
       "\n",
       "[3419 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate entries\n",
    "df.drop_duplicates(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I tried the new flavor with layers and it was ...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>love this ice cream, taste fantastic!! will ne...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite cream. Where can I find th...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The best tasting ice cream out there! It is ve...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite, period. If I cant find it...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3424 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "0     0_breyers      1           11           0   \n",
       "1     0_breyers      1            7           0   \n",
       "2     0_breyers      1            8           0   \n",
       "3     0_breyers      1            4           0   \n",
       "4     0_breyers      5           21           2   \n",
       "...         ...    ...          ...         ...   \n",
       "3419       9_hd      5            1           0   \n",
       "3420       9_hd      5            1           0   \n",
       "3421       9_hd      5            1           0   \n",
       "3422       9_hd      5            1           0   \n",
       "3423       9_hd      5            1           0   \n",
       "\n",
       "                                                   text  rating  \n",
       "0     I am interested in the flavoring components us...     4.1  \n",
       "1     Boy, was I surprised when I got my Bryers home...     4.1  \n",
       "2     I havent purchased this product in awhile and ...     4.1  \n",
       "3     The Natural Vanilla recipe change to include T...     4.1  \n",
       "4     I had the same issue with breyers. I finally f...     4.1  \n",
       "...                                                 ...     ...  \n",
       "3419  I tried the new flavor with layers and it was ...     4.9  \n",
       "3420  love this ice cream, taste fantastic!! will ne...     4.9  \n",
       "3421  This is my favorite cream. Where can I find th...     4.9  \n",
       "3422  The best tasting ice cream out there! It is ve...     4.9  \n",
       "3423  This is my favorite, period. If I cant find it...     4.9  \n",
       "\n",
       "[3424 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create data_df to hold new dataset without duplicates\n",
    "df_data = pd.DataFrame(df)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Add Sentiment Feature to data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any review with 4 or more stars gets a value of 1 to reflect positve sentiment. \n",
    "Any review with 4 or less stars gets a value of 0 to reflect negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \n",
       "0  I am interested in the flavoring components us...     4.1        NaN  \n",
       "1  Boy, was I surprised when I got my Bryers home...     4.1        NaN  \n",
       "2  I havent purchased this product in awhile and ...     4.1        NaN  \n",
       "3  The Natural Vanilla recipe change to include T...     4.1        NaN  \n",
       "4  I had the same issue with breyers. I finally f...     4.1        NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add sentiment column to df_data\n",
    "df_data['sentiment'] = pd.Series(dtype='int64')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \n",
       "0  I am interested in the flavoring components us...     4.1          0  \n",
       "1  Boy, was I surprised when I got my Bryers home...     4.1          0  \n",
       "2  I havent purchased this product in awhile and ...     4.1          0  \n",
       "3  The Natural Vanilla recipe change to include T...     4.1          0  \n",
       "4  I had the same issue with breyers. I finally f...     4.1          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign 1 for positive sentiment, 0 for negative\n",
    "# if stars 4 or higher, sentiment is positive\n",
    "\n",
    "def applyFunc(s):\n",
    "    if s >= 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# populate column        \n",
    "df_data['sentiment'] = df_data['stars'].apply(applyFunc)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>The taste of Breyers vanilla ice cream decline...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>This product no longer has specks of vanilla i...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>After trying Bryers Natural Vanilla Ice Cream ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi. My husband and I like the ice cream, but w...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I tried the new flavor with layers and it was ...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>love this ice cream, taste fantastic!! will ne...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite cream. Where can I find th...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The best tasting ice cream out there! It is ve...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite, period. If I cant find it...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2739 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "4     0_breyers      5           21           2   \n",
       "17    0_breyers      4           45           3   \n",
       "42    0_breyers      4            2           0   \n",
       "56    0_breyers      5           53          32   \n",
       "68    0_breyers      4            1           0   \n",
       "...         ...    ...          ...         ...   \n",
       "3419       9_hd      5            1           0   \n",
       "3420       9_hd      5            1           0   \n",
       "3421       9_hd      5            1           0   \n",
       "3422       9_hd      5            1           0   \n",
       "3423       9_hd      5            1           0   \n",
       "\n",
       "                                                   text  rating  sentiment  \n",
       "4     I had the same issue with breyers. I finally f...     4.1          1  \n",
       "17    The taste of Breyers vanilla ice cream decline...     4.1          1  \n",
       "42    This product no longer has specks of vanilla i...     4.1          1  \n",
       "56    After trying Bryers Natural Vanilla Ice Cream ...     4.1          1  \n",
       "68    Hi. My husband and I like the ice cream, but w...     4.1          1  \n",
       "...                                                 ...     ...        ...  \n",
       "3419  I tried the new flavor with layers and it was ...     4.9          1  \n",
       "3420  love this ice cream, taste fantastic!! will ne...     4.9          1  \n",
       "3421  This is my favorite cream. Where can I find th...     4.9          1  \n",
       "3422  The best tasting ice cream out there! It is ve...     4.9          1  \n",
       "3423  This is my favorite, period. If I cant find it...     4.9          1  \n",
       "\n",
       "[2739 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create positive sentiment dataframe\n",
    "# delete if not used in rest of notebook\n",
    "# again, seeing output may drive inspiration for new ideas or provide clarity on the direction. \n",
    "\n",
    "df_positive_sentiment = df_data[df_data['sentiment'] ==1]\n",
    "df_positive_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I rarely eat ice cream these days but bought t...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>I dont buy a lot of ice cream, gelato, or swee...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>The top layers are great. Tastes like cheeseca...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I was really excited to try this flavor but wa...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>All of your flavors are such high quality and ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tastes great except there was absolutely no ch...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>685 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "0     0_breyers      1           11           0   \n",
       "1     0_breyers      1            7           0   \n",
       "2     0_breyers      1            8           0   \n",
       "3     0_breyers      1            4           0   \n",
       "5     0_breyers      1            4           0   \n",
       "...         ...    ...          ...         ...   \n",
       "3349  8_talenti      2            3           1   \n",
       "3352  8_talenti      3            3           0   \n",
       "3358  8_talenti      3            2           1   \n",
       "3361  8_talenti      3            1           0   \n",
       "3372  8_talenti      2            1           0   \n",
       "\n",
       "                                                   text  rating  sentiment  \n",
       "0     I am interested in the flavoring components us...     4.1          0  \n",
       "1     Boy, was I surprised when I got my Bryers home...     4.1          0  \n",
       "2     I havent purchased this product in awhile and ...     4.1          0  \n",
       "3     The Natural Vanilla recipe change to include T...     4.1          0  \n",
       "5     I rarely eat ice cream these days but bought t...     4.1          0  \n",
       "...                                                 ...     ...        ...  \n",
       "3349  I dont buy a lot of ice cream, gelato, or swee...     4.3          0  \n",
       "3352  The top layers are great. Tastes like cheeseca...     4.3          0  \n",
       "3358  I was really excited to try this flavor but wa...     4.3          0  \n",
       "3361  All of your flavors are such high quality and ...     4.3          0  \n",
       "3372  Tastes great except there was absolutely no ch...     4.3          0  \n",
       "\n",
       "[685 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create negative sentiment dataframe\n",
    "# delete if not used in rest of notebook\n",
    "\n",
    "df_negative_sentiment = df_data[df_data['sentiment'] ==0]\n",
    "df_negative_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Create Product Sentiment Reviews Dataset\n",
    "\n",
    "This is the helpful_cleaned_reviews_combined.csv with duplicates removed and sentiment column added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create product_sentiment_reviews.csv\n",
    "df_data.to_csv(\"Resources/product_sentiment_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Tokenization, Normalization & Custom Stopword Filtering with NLTK\n",
    "\n",
    "Here is where all the magic of splitting the reviews into individual words, putting each word into lower case, lemmatizing each to its base form, removing punctuations and excluding stop words occurs.\n",
    "\n",
    "We perform this step with the NLTK library as it is the most popular in education and research for NLP.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer dataframe\n",
    "df_tokenize = pd.DataFrame(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Tokenizer library\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "\n",
    "# RegexpTokenizer will tokenize according to any regular expression assigned. \n",
    "# The regular expression r'\\w+' matches any pattern consisting of one or more consecutive letters.\n",
    "reTokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all the words from all the reviews into one list\n",
    "\n",
    "# initialize list to hold words\n",
    "all_words = []\n",
    "\n",
    "\n",
    "for i in range(len(df_tokenize['text'])):\n",
    "    # separate review text into a list of words\n",
    "    tokens = reTokenizer.tokenize(df_tokenize['text'][i])\n",
    "    \n",
    "    \n",
    "    df_tokenize['text'][i] = []\n",
    "    \n",
    "    # iterate through tokens\n",
    "    for word in tokens:\n",
    "        # lower the case of each word\n",
    "        word = word.lower()\n",
    "        # exclude stop words\n",
    "        if word not in stop_words:\n",
    "            \n",
    "            # Lemmatize words into a standard form and avoid counting the same word more than once\n",
    "            word = lemmatizer.lemmatize(word)\n",
    "            # add to list of words\n",
    "            all_words.append(word)\n",
    "            # append to text column of dataframe for appropriate row\n",
    "            df_tokenize['text'][i].append(word)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Bag of Words? Extract the most common words\n",
    "\n",
    "\"bag of words\" and \"most common words\" is used interchangeably throughout the rest of this notebook. We will fix it to be consistent after everyone has mastered comfort with the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cream', 3175),\n",
       " ('ice', 3018),\n",
       " ('flavor', 2681),\n",
       " ('chocolate', 1419),\n",
       " ('love', 1123),\n",
       " ('like', 987),\n",
       " ('one', 909),\n",
       " ('taste', 857),\n",
       " ('favorite', 725),\n",
       " ('good', 676),\n",
       " ('best', 645),\n",
       " ('vanilla', 566),\n",
       " ('would', 547),\n",
       " ('pint', 534),\n",
       " ('ever', 518),\n",
       " ('time', 504),\n",
       " ('get', 470),\n",
       " ('creamy', 459),\n",
       " ('cookie', 456),\n",
       " ('store', 453),\n",
       " ('find', 432),\n",
       " ('delicious', 432),\n",
       " ('please', 431),\n",
       " ('great', 398),\n",
       " ('try', 390),\n",
       " ('really', 389),\n",
       " ('im', 383),\n",
       " ('butter', 383),\n",
       " ('tried', 379),\n",
       " ('sweet', 379),\n",
       " ('gelato', 373),\n",
       " ('perfect', 370),\n",
       " ('make', 368),\n",
       " ('chip', 352),\n",
       " ('product', 351),\n",
       " ('buy', 348),\n",
       " ('texture', 346),\n",
       " ('amazing', 344),\n",
       " ('caramel', 341),\n",
       " ('breyers', 339),\n",
       " ('new', 339),\n",
       " ('eat', 338),\n",
       " ('peanut', 337),\n",
       " ('ive', 334),\n",
       " ('first', 331),\n",
       " ('year', 327),\n",
       " ('much', 314),\n",
       " ('go', 308),\n",
       " ('dairy', 308),\n",
       " ('never', 305),\n",
       " ('bought', 285),\n",
       " ('dont', 266),\n",
       " ('every', 266),\n",
       " ('chunk', 264),\n",
       " ('back', 254),\n",
       " ('always', 252),\n",
       " ('better', 246),\n",
       " ('could', 240),\n",
       " ('even', 240),\n",
       " ('coffee', 240),\n",
       " ('talenti', 231),\n",
       " ('free', 230),\n",
       " ('jerry', 229),\n",
       " ('ben', 226),\n",
       " ('cooky', 224),\n",
       " ('eating', 223),\n",
       " ('little', 218),\n",
       " ('dough', 218),\n",
       " ('cant', 211),\n",
       " ('thing', 209),\n",
       " ('swirl', 208),\n",
       " ('brand', 206),\n",
       " ('day', 204),\n",
       " ('rich', 204),\n",
       " ('also', 203),\n",
       " ('container', 203),\n",
       " ('since', 202),\n",
       " ('way', 202),\n",
       " ('fudge', 200),\n",
       " ('disappointed', 194),\n",
       " ('bit', 194),\n",
       " ('definitely', 194),\n",
       " ('mint', 193),\n",
       " ('found', 191),\n",
       " ('well', 189),\n",
       " ('smooth', 187),\n",
       " ('tasted', 185),\n",
       " ('made', 183),\n",
       " ('ingredient', 182),\n",
       " ('piece', 182),\n",
       " ('haagen', 180),\n",
       " ('thank', 179),\n",
       " ('know', 178),\n",
       " ('used', 177),\n",
       " ('say', 177),\n",
       " ('hard', 177),\n",
       " ('treat', 176),\n",
       " ('layer', 175),\n",
       " ('bite', 170),\n",
       " ('see', 169),\n",
       " ('still', 169),\n",
       " ('dazs', 168),\n",
       " ('last', 167),\n",
       " ('almond', 167),\n",
       " ('right', 166),\n",
       " ('think', 166),\n",
       " ('wish', 166),\n",
       " ('got', 164),\n",
       " ('keep', 163),\n",
       " ('need', 161),\n",
       " ('fan', 158),\n",
       " ('review', 156),\n",
       " ('come', 156),\n",
       " ('something', 156),\n",
       " ('absolutely', 152),\n",
       " ('two', 150),\n",
       " ('far', 150),\n",
       " ('milk', 148),\n",
       " ('sugar', 147),\n",
       " ('enough', 147),\n",
       " ('buying', 145),\n",
       " ('many', 141),\n",
       " ('whole', 140),\n",
       " ('non', 139),\n",
       " ('3', 137),\n",
       " ('loved', 136),\n",
       " ('stop', 136),\n",
       " ('combination', 135),\n",
       " ('thought', 134),\n",
       " ('hope', 133),\n",
       " ('real', 131),\n",
       " ('2', 129),\n",
       " ('another', 129),\n",
       " ('brownie', 129),\n",
       " ('grocery', 128),\n",
       " ('feel', 128),\n",
       " ('trying', 128),\n",
       " ('didnt', 127),\n",
       " ('lot', 127),\n",
       " ('pistachio', 126),\n",
       " ('raspberry', 125),\n",
       " ('want', 124),\n",
       " ('almost', 124),\n",
       " ('bar', 124),\n",
       " ('dessert', 123),\n",
       " ('cherry', 123),\n",
       " ('amount', 123),\n",
       " ('ago', 122),\n",
       " ('change', 120),\n",
       " ('making', 120),\n",
       " ('core', 120),\n",
       " ('sure', 119),\n",
       " ('u', 119),\n",
       " ('natural', 118),\n",
       " ('however', 118),\n",
       " ('half', 116),\n",
       " ('crunch', 116),\n",
       " ('strawberry', 114),\n",
       " ('going', 113),\n",
       " ('cheesecake', 113),\n",
       " ('frozen', 112),\n",
       " ('different', 112),\n",
       " ('though', 112),\n",
       " ('local', 112),\n",
       " ('week', 111),\n",
       " ('bad', 110),\n",
       " ('enjoy', 110),\n",
       " ('quality', 109),\n",
       " ('nice', 109),\n",
       " ('recommend', 108),\n",
       " ('freezer', 108),\n",
       " ('saw', 108),\n",
       " ('mango', 108),\n",
       " ('add', 107),\n",
       " ('big', 107),\n",
       " ('super', 106),\n",
       " ('regular', 106),\n",
       " ('actually', 105),\n",
       " ('went', 105),\n",
       " ('family', 104),\n",
       " ('marshmallow', 103),\n",
       " ('icecream', 102),\n",
       " ('away', 101),\n",
       " ('look', 101),\n",
       " ('people', 100),\n",
       " ('give', 100),\n",
       " ('5', 100),\n",
       " ('life', 99),\n",
       " ('dark', 99),\n",
       " ('nothing', 98),\n",
       " ('pie', 97),\n",
       " ('long', 97),\n",
       " ('month', 97),\n",
       " ('food', 96),\n",
       " ('available', 96),\n",
       " ('oreo', 96),\n",
       " ('mouth', 95),\n",
       " ('coconut', 95),\n",
       " ('recipe', 94),\n",
       " ('put', 93),\n",
       " ('b', 93),\n",
       " ('everything', 93),\n",
       " ('thanks', 93),\n",
       " ('top', 92),\n",
       " ('stuff', 92),\n",
       " ('happy', 92),\n",
       " ('changed', 91),\n",
       " ('take', 91),\n",
       " ('without', 91),\n",
       " ('calorie', 91),\n",
       " ('around', 90),\n",
       " ('husband', 90),\n",
       " ('doesnt', 90),\n",
       " ('j', 90),\n",
       " ('tasting', 89),\n",
       " ('looking', 88),\n",
       " ('size', 88),\n",
       " ('usually', 88),\n",
       " ('cinnamon', 88),\n",
       " ('part', 87),\n",
       " ('bean', 86),\n",
       " ('1', 86),\n",
       " ('old', 86),\n",
       " ('world', 84),\n",
       " ('came', 83),\n",
       " ('excited', 83),\n",
       " ('sad', 82),\n",
       " ('graham', 82),\n",
       " ('anything', 81),\n",
       " ('full', 81),\n",
       " ('entire', 81),\n",
       " ('wonderful', 81),\n",
       " ('huge', 80),\n",
       " ('le', 79),\n",
       " ('purchased', 79),\n",
       " ('stock', 79),\n",
       " ('home', 78),\n",
       " ('purchase', 78),\n",
       " ('maybe', 78),\n",
       " ('sitting', 78),\n",
       " ('glad', 78),\n",
       " ('4', 78),\n",
       " ('longer', 76),\n",
       " ('base', 76),\n",
       " ('balance', 76),\n",
       " ('awesome', 76),\n",
       " ('recently', 75),\n",
       " ('pecan', 75),\n",
       " ('night', 75),\n",
       " ('crunchy', 75),\n",
       " ('kind', 75),\n",
       " ('hand', 74),\n",
       " ('low', 73),\n",
       " ('literally', 73),\n",
       " ('kid', 73),\n",
       " ('salty', 73),\n",
       " ('bourbon', 73),\n",
       " ('carb', 73),\n",
       " ('star', 72),\n",
       " ('lover', 72),\n",
       " ('able', 72),\n",
       " ('truffle', 71),\n",
       " ('together', 71),\n",
       " ('cracker', 71),\n",
       " ('anymore', 70),\n",
       " ('instead', 70),\n",
       " ('10', 70),\n",
       " ('pretzel', 70),\n",
       " ('yummy', 69),\n",
       " ('friend', 68),\n",
       " ('pretty', 67),\n",
       " ('light', 67),\n",
       " ('mix', 67),\n",
       " ('oh', 67),\n",
       " ('added', 66),\n",
       " ('bring', 66),\n",
       " ('couldnt', 66),\n",
       " ('problem', 66),\n",
       " ('batch', 66),\n",
       " ('must', 65),\n",
       " ('thats', 65),\n",
       " ('cup', 65),\n",
       " ('wasnt', 65),\n",
       " ('next', 65),\n",
       " ('disappointing', 64),\n",
       " ('tell', 64),\n",
       " ('highly', 64),\n",
       " ('honestly', 64),\n",
       " ('decided', 63),\n",
       " ('ill', 63),\n",
       " ('perfectly', 63),\n",
       " ('carbs', 63),\n",
       " ('ahoy', 63),\n",
       " ('unfortunately', 62),\n",
       " ('scoop', 62),\n",
       " ('experience', 62),\n",
       " ('others', 62),\n",
       " ('target', 62),\n",
       " ('price', 61),\n",
       " ('wanted', 61),\n",
       " ('heaven', 61),\n",
       " ('bottom', 61),\n",
       " ('several', 60),\n",
       " ('let', 60),\n",
       " ('ate', 60),\n",
       " ('absolute', 60),\n",
       " ('tasty', 60),\n",
       " ('craving', 60),\n",
       " ('left', 59),\n",
       " ('gone', 59),\n",
       " ('soft', 59),\n",
       " ('reason', 59),\n",
       " ('cannot', 59),\n",
       " ('said', 59),\n",
       " ('small', 59),\n",
       " ('hit', 59),\n",
       " ('hooked', 59),\n",
       " ('received', 59),\n",
       " ('spoonful', 58),\n",
       " ('seems', 58),\n",
       " ('past', 58),\n",
       " ('believe', 58),\n",
       " ('getting', 58),\n",
       " ('flavour', 58),\n",
       " ('spoon', 58),\n",
       " ('sorbet', 58),\n",
       " ('least', 57),\n",
       " ('everyone', 57),\n",
       " ('work', 57),\n",
       " ('nut', 57),\n",
       " ('wait', 57),\n",
       " ('melt', 56),\n",
       " ('vegan', 56),\n",
       " ('sorbetto', 56),\n",
       " ('probably', 56),\n",
       " ('addicted', 56),\n",
       " ('today', 55),\n",
       " ('isnt', 55),\n",
       " ('use', 55),\n",
       " ('service', 55),\n",
       " ('worth', 55),\n",
       " ('eaten', 55),\n",
       " ('consumer', 55),\n",
       " ('omg', 55),\n",
       " ('wrong', 55),\n",
       " ('strong', 55),\n",
       " ('took', 54),\n",
       " ('may', 54),\n",
       " ('especially', 54),\n",
       " ('might', 54),\n",
       " ('banana', 54),\n",
       " ('area', 53),\n",
       " ('cone', 53),\n",
       " ('cake', 53),\n",
       " ('finally', 52),\n",
       " ('sold', 52),\n",
       " ('couple', 52),\n",
       " ('carton', 52),\n",
       " ('option', 51),\n",
       " ('flavored', 51),\n",
       " ('overall', 51),\n",
       " ('peppermint', 51),\n",
       " ('havent', 50),\n",
       " ('decadent', 50),\n",
       " ('wow', 50),\n",
       " ('lactose', 50),\n",
       " ('else', 49),\n",
       " ('shelf', 49),\n",
       " ('forward', 49),\n",
       " ('gum', 48),\n",
       " ('version', 48),\n",
       " ('noticed', 48),\n",
       " ('artificial', 48),\n",
       " ('either', 48),\n",
       " ('lol', 48),\n",
       " ('list', 47),\n",
       " ('looked', 47),\n",
       " ('original', 47),\n",
       " ('apple', 47),\n",
       " ('com', 46),\n",
       " ('totally', 46),\n",
       " ('guy', 46),\n",
       " ('id', 46),\n",
       " ('help', 46),\n",
       " ('combo', 46),\n",
       " ('limited', 46),\n",
       " ('blend', 46),\n",
       " ('issue', 45),\n",
       " ('high', 45),\n",
       " ('quite', 45),\n",
       " ('three', 45),\n",
       " ('fact', 45),\n",
       " ('throughout', 45),\n",
       " ('exactly', 45),\n",
       " ('covered', 45),\n",
       " ('pumpkin', 45),\n",
       " ('market', 44),\n",
       " ('yet', 44),\n",
       " ('sometimes', 44),\n",
       " ('seriously', 44),\n",
       " ('end', 44),\n",
       " ('special', 44),\n",
       " ('unilever', 43),\n",
       " ('plain', 43),\n",
       " ('line', 43),\n",
       " ('fresh', 43),\n",
       " ('pb', 43),\n",
       " ('yum', 43),\n",
       " ('diet', 43),\n",
       " ('enjoyed', 43),\n",
       " ('second', 42),\n",
       " ('wont', 42),\n",
       " ('cold', 42),\n",
       " ('side', 42),\n",
       " ('stopped', 42),\n",
       " ('simply', 42),\n",
       " ('tonight', 42),\n",
       " ('youre', 42),\n",
       " ('tub', 42),\n",
       " ('baked', 42),\n",
       " ('liked', 42),\n",
       " ('barely', 42),\n",
       " ('salted', 42),\n",
       " ('delight', 42),\n",
       " ('phish', 42),\n",
       " ('smores', 42),\n",
       " ('anyone', 41),\n",
       " ('choice', 41),\n",
       " ('place', 41),\n",
       " ('happened', 41),\n",
       " ('expecting', 41),\n",
       " ('rest', 41),\n",
       " ('anywhere', 41),\n",
       " ('salt', 41),\n",
       " ('finding', 41),\n",
       " ('green', 41),\n",
       " ('surprised', 40),\n",
       " ('sell', 40),\n",
       " ('truly', 40),\n",
       " ('single', 40),\n",
       " ('permanent', 40),\n",
       " ('missing', 40),\n",
       " ('obsessed', 40),\n",
       " ('discontinued', 40),\n",
       " ('box', 39),\n",
       " ('hint', 39),\n",
       " ('refreshing', 39),\n",
       " ('simple', 39),\n",
       " ('done', 39),\n",
       " ('become', 39),\n",
       " ('extremely', 39),\n",
       " ('sweetness', 39),\n",
       " ('someone', 39),\n",
       " ('easy', 39),\n",
       " ('carry', 39),\n",
       " ('completely', 38),\n",
       " ('true', 38),\n",
       " ('opened', 38),\n",
       " ('white', 38),\n",
       " ('mean', 38),\n",
       " ('walmart', 38),\n",
       " ('mixed', 38),\n",
       " ('excellent', 38),\n",
       " ('summer', 38),\n",
       " ('live', 37),\n",
       " ('gave', 37),\n",
       " ('discontinue', 37),\n",
       " ('yes', 37),\n",
       " ('lemon', 37),\n",
       " ('per', 37),\n",
       " ('perfection', 37),\n",
       " ('soon', 37),\n",
       " ('fantastic', 37),\n",
       " ('serving', 37),\n",
       " ('bigger', 37),\n",
       " ('mine', 37),\n",
       " ('oatmeal', 37),\n",
       " ('disappointment', 36),\n",
       " ('finished', 36),\n",
       " ('company', 36),\n",
       " ('consistency', 36),\n",
       " ('satisfying', 36),\n",
       " ('influenster', 36),\n",
       " ('write', 36),\n",
       " ('point', 35),\n",
       " ('thinking', 35),\n",
       " ('extra', 35),\n",
       " ('name', 35),\n",
       " ('opinion', 35),\n",
       " ('testing', 35),\n",
       " ('goodness', 35),\n",
       " ('son', 35),\n",
       " ('dream', 35),\n",
       " ('fell', 35),\n",
       " ('item', 35),\n",
       " ('already', 35),\n",
       " ('forever', 35),\n",
       " ('syrup', 34),\n",
       " ('customer', 34),\n",
       " ('read', 34)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the most common words from the list of all_words.\n",
    "\n",
    "from nltk import FreqDist\n",
    "\n",
    "# sort all of the words in the all_words list by frequency count\n",
    "all_words = FreqDist(all_words)\n",
    "# Extract the 500 most common words from the all_words list\n",
    "most_common_words = all_words.most_common(500)\n",
    "\n",
    "# create a list of most common words without the frequency count\n",
    "word_features = []\n",
    "for w in most_common_words:\n",
    "    word_features.append(w[0])\n",
    "\n",
    "#print \n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  6153 unique words total in our text dataset.\n",
      "There are  500 unique words in the most common words list.\n"
     ]
    }
   ],
   "source": [
    "print ('There are ', len(all_words), 'unique words total in our text dataset.')\n",
    "print ('There are ', len(most_common_words), 'unique words in the most common words list.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  Create \"Bag of Words\" data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Bag of Words DataFrame\n",
    "df_bagofwords = pd.DataFrame(df_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[interested, flavoring, component, used, notic...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[boy, surprised, got, bryers, home, discover, ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[havent, purchased, product, awhile, surprised...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, recipe, change, include, ta...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>[issue, breyers, finally, found, turkey, hill,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \\\n",
       "0  [interested, flavoring, component, used, notic...     4.1          0   \n",
       "1  [boy, surprised, got, bryers, home, discover, ...     4.1          0   \n",
       "2  [havent, purchased, product, awhile, surprised...     4.1          0   \n",
       "3  [natural, vanilla, recipe, change, include, ta...     4.1          0   \n",
       "4  [issue, breyers, finally, found, turkey, hill,...     4.1          1   \n",
       "\n",
       "  bag_of_words  \n",
       "0               \n",
       "1               \n",
       "2               \n",
       "3               \n",
       "4               "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create column for bag of words\n",
    "df_bagofwords['bag_of_words'] = \"\"\n",
    "df_bagofwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate dataframe to populate bag of words column\n",
    "for i in range(len(df_bagofwords['text'])):\n",
    "    # initialize empty column    \n",
    "    df_bagofwords['bag_of_words'][i] = []\n",
    "    \n",
    "    # iterate through df row by row\n",
    "    for word in df_bagofwords['text'][i]:\n",
    "        # if a word in 'text' is in the most common words\n",
    "        # note: this is simply the \"most_common_words\" without the count column\n",
    "        if word in word_features:\n",
    "            # if it is, add it to the bag of words cell\n",
    "            df_bagofwords['bag_of_words'][i].append(word)\n",
    "            \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[interested, flavoring, component, used, notic...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[used, ingredient, list, vanilla, bean, vanill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[boy, surprised, got, bryers, home, discover, ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[surprised, got, home, frozen, dairy, dessert,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[havent, purchased, product, awhile, surprised...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[havent, purchased, product, surprised, today,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, recipe, change, include, ta...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, recipe, change, gum, change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>[issue, breyers, finally, found, turkey, hill,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[issue, breyers, finally, found, natural, ice,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \\\n",
       "0  [interested, flavoring, component, used, notic...     4.1          0   \n",
       "1  [boy, surprised, got, bryers, home, discover, ...     4.1          0   \n",
       "2  [havent, purchased, product, awhile, surprised...     4.1          0   \n",
       "3  [natural, vanilla, recipe, change, include, ta...     4.1          0   \n",
       "4  [issue, breyers, finally, found, turkey, hill,...     4.1          1   \n",
       "\n",
       "                                        bag_of_words  \n",
       "0  [used, ingredient, list, vanilla, bean, vanill...  \n",
       "1  [surprised, got, home, frozen, dairy, dessert,...  \n",
       "2  [havent, purchased, product, surprised, today,...  \n",
       "3  [natural, vanilla, recipe, change, gum, change...  \n",
       "4  [issue, breyers, finally, found, natural, ice,...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bagofwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['upset', '1', '5qt', 'container', 'natural', 'vanilla', 'two', 'different', 'store', 'lacked', 'little', 'black', 'speck', 'come', 'love', 'expect']\n",
      "\n",
      "bag_of_words:  ['1', 'container', 'natural', 'vanilla', 'two', 'different', 'store', 'little', 'come', 'love']\n"
     ]
    }
   ],
   "source": [
    "# Example to compare text vs bag of words\n",
    "# set example variable equal to the review row you'd like to see\n",
    "example = 7\n",
    "\n",
    "print('text: ', df_bagofwords['text'][example])\n",
    "print('\\nbag_of_words: ',df_bagofwords['bag_of_words'][example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  Term Frequency-Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>bag_of_words</th>\n",
       "      <th>bag_of_words_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[interested, flavoring, component, used, notic...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[used, ingredient, list, vanilla, bean, vanill...</td>\n",
       "      <td>used,ingredient,list,vanilla,bean,vanilla,natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[boy, surprised, got, bryers, home, discover, ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[surprised, got, home, frozen, dairy, dessert,...</td>\n",
       "      <td>surprised,got,home,frozen,dairy,dessert,even,i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[havent, purchased, product, awhile, surprised...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[havent, purchased, product, surprised, today,...</td>\n",
       "      <td>havent,purchased,product,surprised,today,find,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, recipe, change, include, ta...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, recipe, change, gum, change...</td>\n",
       "      <td>natural,vanilla,recipe,change,gum,change,textu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>[issue, breyers, finally, found, turkey, hill,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[issue, breyers, finally, found, natural, ice,...</td>\n",
       "      <td>issue,breyers,finally,found,natural,ice,cream,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \\\n",
       "0  [interested, flavoring, component, used, notic...     4.1          0   \n",
       "1  [boy, surprised, got, bryers, home, discover, ...     4.1          0   \n",
       "2  [havent, purchased, product, awhile, surprised...     4.1          0   \n",
       "3  [natural, vanilla, recipe, change, include, ta...     4.1          0   \n",
       "4  [issue, breyers, finally, found, turkey, hill,...     4.1          1   \n",
       "\n",
       "                                        bag_of_words  \\\n",
       "0  [used, ingredient, list, vanilla, bean, vanill...   \n",
       "1  [surprised, got, home, frozen, dairy, dessert,...   \n",
       "2  [havent, purchased, product, surprised, today,...   \n",
       "3  [natural, vanilla, recipe, change, gum, change...   \n",
       "4  [issue, breyers, finally, found, natural, ice,...   \n",
       "\n",
       "                                    bag_of_words_str  \n",
       "0  used,ingredient,list,vanilla,bean,vanilla,natu...  \n",
       "1  surprised,got,home,frozen,dairy,dessert,even,i...  \n",
       "2  havent,purchased,product,surprised,today,find,...  \n",
       "3  natural,vanilla,recipe,change,gum,change,textu...  \n",
       "4  issue,breyers,finally,found,natural,ice,cream,...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dependencies\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# create new DataFrame to hold encoded values \n",
    "df_tfidf_text = pd.DataFrame(df_bagofwords)\n",
    "\n",
    "# convert text list to string and create string column\n",
    "# Required for vectorizer. Running on a list will yield an error.\n",
    "# https://stackoverflow.com/questions/45306988/column-of-lists-convert-list-to-string-as-a-new-column\n",
    "df_tfidf_text['bag_of_words_str'] = df_tfidf_text['bag_of_words'].apply(lambda x: ','.join(map(str, x)))\n",
    "\n",
    "df_tfidf_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenized_text_features.csv\n",
    "# finally in the format needed for vectorizing our features\n",
    "# the bag_of_words column as a string which is required for vectorizing\n",
    "df_tfidf_text.to_csv(\"Resources/tokenized_text_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>addicted</th>\n",
       "      <th>ago</th>\n",
       "      <th>ahoy</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>wow</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>youre</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 417 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  able  absolute  absolutely  actually  add  added  addicted  ago  ahoy  \\\n",
       "0  0.0   0.0       0.0         0.0       0.0  0.0    0.0       0.0  0.0   0.0   \n",
       "1  0.0   0.0       0.0         0.0       0.0  0.0    0.0       0.0  0.0   0.0   \n",
       "2  0.0   0.0       0.0         0.0       0.0  0.0    0.0       0.0  0.0   0.0   \n",
       "3  0.0   0.0       0.0         0.0       0.0  0.0    0.0       0.0  0.0   0.0   \n",
       "4  0.0   0.0       0.0         0.0       0.0  0.0    0.0       0.0  0.0   0.0   \n",
       "\n",
       "   ...  world  worth  wow  write  wrong  year  yes  youre  yum  yummy  \n",
       "0  ...    0.0    0.0  0.0    0.0    0.0   0.0  0.0    0.0  0.0    0.0  \n",
       "1  ...    0.0    0.0  0.0    0.0    0.0   0.0  0.0    0.0  0.0    0.0  \n",
       "2  ...    0.0    0.0  0.0    0.0    0.0   0.0  0.0    0.0  0.0    0.0  \n",
       "3  ...    0.0    0.0  0.0    0.0    0.0   0.0  0.0    0.0  0.0    0.0  \n",
       "4  ...    0.0    0.0  0.0    0.0    0.0   0.0  0.0    0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 417 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 'text' term frequencies weighted by their relative importance (IDF)\n",
    "tfidf = TfidfVectorizer(analyzer='word', stop_words = 'english')\n",
    "\n",
    "x = df_tfidf_text['bag_of_words_str']\n",
    "\n",
    "xtfidf = tfidf.fit_transform(x)\n",
    "\n",
    "tdif_bagOfWords_df = pd.DataFrame(data = xtfidf.toarray(),\n",
    "                        columns = tfidf.get_feature_names())\n",
    "\n",
    "tdif_bagOfWords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features :  ['10', 'able', 'absolute', 'absolutely', 'actually', 'add', 'added', 'addicted', 'ago', 'ahoy', 'almond', 'amazing', 'anymore', 'apple', 'area', 'artificial', 'ate', 'available', 'away', 'awesome', 'bad', 'baked', 'balance', 'banana', 'bar', 'barely', 'base', 'batch', 'bean', 'believe', 'ben', 'best', 'better', 'big', 'bigger', 'bit', 'bite', 'blend', 'bought', 'bourbon', 'box', 'brand', 'breyers', 'bring', 'brownie', 'butter', 'buy', 'buying', 'cake', 'calorie', 'came', 'caramel', 'carb', 'carbs', 'carry', 'carton', 'change', 'changed', 'cheesecake', 'cherry', 'chip', 'chocolate', 'choice', 'chunk', 'cinnamon', 'coconut', 'coffee', 'cold', 'com', 'combination', 'combo', 'come', 'company', 'completely', 'cone', 'consistency', 'consumer', 'container', 'cookie', 'cooky', 'core', 'couple', 'covered', 'cracker', 'craving', 'cream', 'creamy', 'crunch', 'crunchy', 'cup', 'customer', 'dairy', 'dark', 'day', 'dazs', 'decadent', 'decided', 'definitely', 'delicious', 'delight', 'dessert', 'didnt', 'diet', 'different', 'disappointed', 'disappointing', 'disappointment', 'discontinue', 'discontinued', 'doesnt', 'dont', 'dough', 'dream', 'easy', 'eat', 'eaten', 'eating', 'end', 'enjoy', 'enjoyed', 'entire', 'especially', 'exactly', 'excellent', 'excited', 'expecting', 'experience', 'extra', 'extremely', 'fact', 'family', 'fan', 'fantastic', 'far', 'favorite', 'feel', 'fell', 'finally', 'finding', 'finished', 'flavor', 'flavored', 'flavour', 'food', 'forever', 'forward', 'free', 'freezer', 'fresh', 'friend', 'frozen', 'fudge', 'gave', 'gelato', 'getting', 'glad', 'going', 'gone', 'good', 'goodness', 'got', 'graham', 'great', 'green', 'grocery', 'gum', 'guy', 'haagen', 'half', 'hand', 'happened', 'happy', 'hard', 'havent', 'heaven', 'help', 'high', 'highly', 'hint', 'hit', 'home', 'honestly', 'hooked', 'hope', 'huge', 'husband', 'ice', 'icecream', 'id', 'ill', 'im', 'influenster', 'ingredient', 'instead', 'isnt', 'issue', 'item', 'ive', 'jerry', 'kid', 'kind', 'know', 'lactose', 'layer', 'le', 'left', 'lemon', 'let', 'life', 'light', 'like', 'liked', 'limited', 'line', 'list', 'literally', 'little', 'live', 'local', 'lol', 'long', 'longer', 'look', 'looked', 'looking', 'lot', 'love', 'loved', 'lover', 'low', 'make', 'making', 'mango', 'market', 'marshmallow', 'maybe', 'mean', 'melt', 'milk', 'mint', 'missing', 'mix', 'mixed', 'month', 'mouth', 'natural', 'need', 'new', 'nice', 'night', 'non', 'noticed', 'nut', 'oatmeal', 'obsessed', 'oh', 'old', 'omg', 'opened', 'opinion', 'option', 'oreo', 'original', 'overall', 'past', 'pb', 'peanut', 'pecan', 'people', 'peppermint', 'perfect', 'perfection', 'perfectly', 'permanent', 'phish', 'pie', 'piece', 'pint', 'pistachio', 'place', 'plain', 'point', 'pretty', 'pretzel', 'price', 'probably', 'problem', 'product', 'pumpkin', 'purchase', 'purchased', 'quality', 'quite', 'raspberry', 'read', 'real', 'really', 'reason', 'received', 'recently', 'recipe', 'recommend', 'refreshing', 'regular', 'rest', 'review', 'rich', 'right', 'sad', 'said', 'salt', 'salted', 'salty', 'satisfying', 'saw', 'say', 'scoop', 'second', 'sell', 'seriously', 'service', 'serving', 'shelf', 'simple', 'simply', 'single', 'sitting', 'size', 'small', 'smooth', 'smores', 'soft', 'sold', 'son', 'soon', 'sorbet', 'sorbetto', 'special', 'spoon', 'spoonful', 'star', 'stock', 'stop', 'stopped', 'store', 'strawberry', 'strong', 'stuff', 'sugar', 'summer', 'super', 'sure', 'surprised', 'sweet', 'sweetness', 'swirl', 'syrup', 'talenti', 'target', 'taste', 'tasted', 'tasting', 'tasty', 'tell', 'testing', 'texture', 'thank', 'thanks', 'thats', 'thing', 'think', 'thinking', 'thought', 'time', 'today', 'tonight', 'took', 'totally', 'treat', 'tried', 'true', 'truffle', 'truly', 'try', 'trying', 'tub', 'unfortunately', 'unilever', 'use', 'used', 'usually', 'vanilla', 'vegan', 'version', 'wait', 'walmart', 'want', 'wanted', 'wasnt', 'way', 'week', 'went', 'white', 'wish', 'wonderful', 'wont', 'work', 'world', 'worth', 'wow', 'write', 'wrong', 'year', 'yes', 'youre', 'yum', 'yummy']\n"
     ]
    }
   ],
   "source": [
    "print ('\\nFeatures : ', tdif_bagOfWords_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>cream</td>\n",
       "      <td>286.489907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>ice</td>\n",
       "      <td>277.188113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>flavor</td>\n",
       "      <td>270.473062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>chocolate</td>\n",
       "      <td>176.530416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>love</td>\n",
       "      <td>169.931561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>disappointment</td>\n",
       "      <td>8.708878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>testing</td>\n",
       "      <td>8.706582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>mean</td>\n",
       "      <td>8.696728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>customer</td>\n",
       "      <td>8.578922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>syrup</td>\n",
       "      <td>8.453738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>417 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               term        rank\n",
       "85            cream  286.489907\n",
       "186             ice  277.188113\n",
       "140          flavor  270.473062\n",
       "61        chocolate  176.530416\n",
       "226            love  169.931561\n",
       "..              ...         ...\n",
       "106  disappointment    8.708878\n",
       "364         testing    8.706582\n",
       "236            mean    8.696728\n",
       "90         customer    8.578922\n",
       "356           syrup    8.453738\n",
       "\n",
       "[417 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = tfidf.get_feature_names()\n",
    "\n",
    "# sum tfidf frequency of each term through documents\n",
    "sums = xtfidf.sum(axis=0)\n",
    "\n",
    "# connecting term to its sums frequency\n",
    "data = []\n",
    "for col, term in enumerate(terms):\n",
    "    data.append( (term, sums[0,col] ))\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term','rank'])\n",
    "term_rank = ranking.sort_values('rank', ascending=False)\n",
    "\n",
    "term_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>10</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>wow</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>youre</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 423 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  rating  sentiment   10  able  \\\n",
       "0  0_breyers      1           11           0     4.1          0  0.0   0.0   \n",
       "1  0_breyers      1            7           0     4.1          0  0.0   0.0   \n",
       "2  0_breyers      1            8           0     4.1          0  0.0   0.0   \n",
       "3  0_breyers      1            4           0     4.1          0  0.0   0.0   \n",
       "4  0_breyers      5           21           2     4.1          1  0.0   0.0   \n",
       "\n",
       "   absolute  absolutely  ...  world  worth  wow  write  wrong  year  yes  \\\n",
       "0       0.0         0.0  ...    0.0    0.0  0.0    0.0    0.0   0.0  0.0   \n",
       "1       0.0         0.0  ...    0.0    0.0  0.0    0.0    0.0   0.0  0.0   \n",
       "2       0.0         0.0  ...    0.0    0.0  0.0    0.0    0.0   0.0  0.0   \n",
       "3       0.0         0.0  ...    0.0    0.0  0.0    0.0    0.0   0.0  0.0   \n",
       "4       0.0         0.0  ...    0.0    0.0  0.0    0.0    0.0   0.0  0.0   \n",
       "\n",
       "   youre  yum  yummy  \n",
       "0    0.0  0.0    0.0  \n",
       "1    0.0  0.0    0.0  \n",
       "2    0.0  0.0    0.0  \n",
       "3    0.0  0.0    0.0  \n",
       "4    0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 423 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge tfidf features and drop the originals\n",
    "\n",
    "df_tfidf_text = df_tfidf_text.merge(tdif_bagOfWords_df,left_index=True, right_index=True)\n",
    "df_tfidf_text = df_tfidf_text.drop([\"text\",\"bag_of_words\",\"bag_of_words_str\"], axis=1)\n",
    "df_tfidf_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the features from the target\n",
    "y = df_tfidf_text[\"sentiment\"]\n",
    "X = df_tfidf_text.drop([\"key\",\"stars\",\"helpful_yes\",\"helpful_no\",\"rating\",\"sentiment\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>addicted</th>\n",
       "      <th>ago</th>\n",
       "      <th>ahoy</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>wow</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>youre</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>3424.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>0.006648</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.008619</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.018397</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.005809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.049038</td>\n",
       "      <td>0.040194</td>\n",
       "      <td>0.048539</td>\n",
       "      <td>0.058675</td>\n",
       "      <td>0.040149</td>\n",
       "      <td>0.041007</td>\n",
       "      <td>0.040540</td>\n",
       "      <td>0.038915</td>\n",
       "      <td>0.050413</td>\n",
       "      <td>0.040901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050449</td>\n",
       "      <td>0.041063</td>\n",
       "      <td>0.044570</td>\n",
       "      <td>0.032104</td>\n",
       "      <td>0.035525</td>\n",
       "      <td>0.069030</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>0.030351</td>\n",
       "      <td>0.041380</td>\n",
       "      <td>0.044180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.928857</td>\n",
       "      <td>0.674291</td>\n",
       "      <td>0.887339</td>\n",
       "      <td>0.651532</td>\n",
       "      <td>0.455309</td>\n",
       "      <td>0.505587</td>\n",
       "      <td>0.748950</td>\n",
       "      <td>0.813785</td>\n",
       "      <td>0.730124</td>\n",
       "      <td>0.608328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602960</td>\n",
       "      <td>0.889288</td>\n",
       "      <td>0.816248</td>\n",
       "      <td>0.731636</td>\n",
       "      <td>0.624247</td>\n",
       "      <td>0.666159</td>\n",
       "      <td>0.785823</td>\n",
       "      <td>0.692731</td>\n",
       "      <td>0.842513</td>\n",
       "      <td>0.634024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 417 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                10         able     absolute   absolutely     actually  \\\n",
       "count  3424.000000  3424.000000  3424.000000  3424.000000  3424.000000   \n",
       "mean      0.005549     0.005273     0.005765     0.011227     0.006648   \n",
       "std       0.049038     0.040194     0.048539     0.058675     0.040149   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.928857     0.674291     0.887339     0.651532     0.455309   \n",
       "\n",
       "               add        added     addicted          ago         ahoy  ...  \\\n",
       "count  3424.000000  3424.000000  3424.000000  3424.000000  3424.000000  ...   \n",
       "mean      0.006658     0.005082     0.004520     0.008619     0.004503  ...   \n",
       "std       0.041007     0.040540     0.038915     0.050413     0.040901  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       0.505587     0.748950     0.813785     0.730124     0.608328  ...   \n",
       "\n",
       "             world        worth          wow        write        wrong  \\\n",
       "count  3424.000000  3424.000000  3424.000000  3424.000000  3424.000000   \n",
       "mean      0.007107     0.004558     0.004575     0.003007     0.004125   \n",
       "std       0.050449     0.041063     0.044570     0.032104     0.035525   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.602960     0.889288     0.816248     0.731636     0.624247   \n",
       "\n",
       "              year          yes        youre          yum        yummy  \n",
       "count  3424.000000  3424.000000  3424.000000  3424.000000  3424.000000  \n",
       "mean      0.018397     0.003074     0.003047     0.003596     0.005809  \n",
       "std       0.069030     0.032660     0.030351     0.041380     0.044180  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       0.666159     0.785823     0.692731     0.842513     0.634024  \n",
       "\n",
       "[8 rows x 417 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2739\n",
       "0     685\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2057, 0: 511})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normal train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1)\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2568, 417)\n",
      "(856, 417)\n",
      "(2568,)\n",
      "(856,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "rf_model = BalancedRandomForestClassifier(n_estimators=100, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data.\n",
    "predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Random Forest\n",
      "Accuracy Score\n",
      "0.7651869158878505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Calculating the accuracy score.\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(str('Balanced Random Forest'))\n",
    "print(str('Accuracy Score'))\n",
    "print((acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Random Forest\n",
      "Confusion Matrix\n",
      "                  Predicted High Risk  Predicted Low Risk\n",
      "Actual High Risk                  150                  24\n",
      "Actual Low Risk                   177                 505\n"
     ]
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual High Risk\", \"Actual Low Risk\"], columns=[\"Predicted High Risk\", \"Predicted Low Risk\"])\n",
    "\n",
    "cm_df\n",
    "\n",
    "print(str('Balanced Random Forest'))\n",
    "print(str('Confusion Matrix'))\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Random Forest\n",
      "Imbalanced Classification Report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.46      0.86      0.74      0.60      0.80      0.65       174\n",
      "          1       0.95      0.74      0.86      0.83      0.80      0.63       682\n",
      "\n",
      "avg / total       0.85      0.77      0.84      0.79      0.80      0.63       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(str('Balanced Random Forest'))\n",
    "print(str('Imbalanced Classification Report'))\n",
    "print(classification_report_imbalanced(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.041157708829910405, 'disappointed'),\n",
       " (0.028948902182373802, 'love'),\n",
       " (0.027405979960501783, 'best'),\n",
       " (0.022006239790729087, 'taste'),\n",
       " (0.020822530188481823, 'like'),\n",
       " (0.019960635583354813, 'vanilla'),\n",
       " (0.01719809286548308, 'used'),\n",
       " (0.016903925216234215, 'flavor'),\n",
       " (0.016359805731422605, 'perfect'),\n",
       " (0.015376806285808607, 'delicious'),\n",
       " (0.014109497719704338, 'favorite'),\n",
       " (0.013603373174743019, 'disappointing'),\n",
       " (0.01192978422129916, 'ice'),\n",
       " (0.011919247478194318, 'cream'),\n",
       " (0.011517651773841724, 'recipe'),\n",
       " (0.010403220446838243, 'amazing'),\n",
       " (0.009412197506012547, 'chocolate'),\n",
       " (0.0084239930109965, 'changed'),\n",
       " (0.008350276603617151, 'store'),\n",
       " (0.008204792784682492, 'bad'),\n",
       " (0.008064595156469198, 'creamy'),\n",
       " (0.00801383501718746, 'bought'),\n",
       " (0.007713203637104718, 'great'),\n",
       " (0.00719102277508481, 'good'),\n",
       " (0.006960863881556014, 'change'),\n",
       " (0.006707972348151277, 'product'),\n",
       " (0.0066776448343403415, 'purchased'),\n",
       " (0.0064902122711841615, 'anymore'),\n",
       " (0.006430797286997407, 'butter'),\n",
       " (0.00619968461527751, 'chip'),\n",
       " (0.006121675790006057, 'cookie'),\n",
       " (0.006048413119938824, 'bean'),\n",
       " (0.006013465994165646, 'sweet'),\n",
       " (0.005790001477758909, 'peanut'),\n",
       " (0.005580860780797436, 'dairy'),\n",
       " (0.005561924117372961, 'pint'),\n",
       " (0.005481852302031937, 'ingredient'),\n",
       " (0.005478349231241466, 'gum'),\n",
       " (0.00528967980680152, 'breyers'),\n",
       " (0.005274800358431694, 'smooth'),\n",
       " (0.005089317750509879, 'natural'),\n",
       " (0.00507696816477287, 'excited'),\n",
       " (0.0050266175179667924, 'really'),\n",
       " (0.004848761639521904, 'time'),\n",
       " (0.004786270134053401, 'way'),\n",
       " (0.004731484129854536, 'piece'),\n",
       " (0.004526713881542653, 'better'),\n",
       " (0.004373036523988628, 'unfortunately'),\n",
       " (0.0043713404757462285, 'im'),\n",
       " (0.004333104104413739, 'thank'),\n",
       " (0.004328245698211758, 'dough'),\n",
       " (0.004300759585033726, 'disappointment'),\n",
       " (0.004258861155866928, 'texture'),\n",
       " (0.004244858007605595, 'tried'),\n",
       " (0.004083130339253301, 'make'),\n",
       " (0.004043425246150025, 'oreo'),\n",
       " (0.00400145118228943, 'new'),\n",
       " (0.0039903457518608385, 'container'),\n",
       " (0.003966130185727327, 'buy'),\n",
       " (0.003954115047102497, 'bit'),\n",
       " (0.0037510232159731587, 'thing'),\n",
       " (0.0037318704831961974, 'year'),\n",
       " (0.0036996724217952296, 'barely'),\n",
       " (0.0036932633378776907, 'cooky'),\n",
       " (0.0036840919686151143, 'quality'),\n",
       " (0.003620615512000469, 'batch'),\n",
       " (0.0035919775905715935, 'rich'),\n",
       " (0.003579408071312677, 'plain'),\n",
       " (0.0035127369763231896, 'treat'),\n",
       " (0.0034691121362228298, 'gelato'),\n",
       " (0.0034616098176938745, 'didnt'),\n",
       " (0.003435496373098828, 'reason'),\n",
       " (0.003405919534589701, 'doesnt'),\n",
       " (0.0034039255231018317, 'swirl'),\n",
       " (0.003399048072482326, 'eating'),\n",
       " (0.0033344084319166037, 'tasted'),\n",
       " (0.003328613846881085, 'ive'),\n",
       " (0.0033055475726937837, 'try'),\n",
       " (0.00325546915302079, 'stop'),\n",
       " (0.0032165092314385157, 'expecting'),\n",
       " (0.0031618477540575674, 'think'),\n",
       " (0.003033596983560683, 'eat'),\n",
       " (0.003007046368135689, 'free'),\n",
       " (0.003000641778379558, 'use'),\n",
       " (0.0028837819693716196, 'wish'),\n",
       " (0.002873500160070579, 'almond'),\n",
       " (0.002856865944281902, 'dont'),\n",
       " (0.0028275818155837173, 'coffee'),\n",
       " (0.0028099433725671907, 'buying'),\n",
       " (0.002800149415151095, 'brownie'),\n",
       " (0.0027989620969099713, 'sugar'),\n",
       " (0.0027669994304467646, 'maybe'),\n",
       " (0.0027261489902389822, 'noticed'),\n",
       " (0.002673480760107641, 'little'),\n",
       " (0.002673338600457513, 'brand'),\n",
       " (0.0026726824299669106, 'wanted'),\n",
       " (0.0026540055954449413, 'come'),\n",
       " (0.0026401531982300033, 'core'),\n",
       " (0.0025774315759931514, 'caramel'),\n",
       " (0.00257135561690065, 'fan'),\n",
       " (0.0025650487900427707, 'ben'),\n",
       " (0.0025560510686105336, 'say'),\n",
       " (0.0025291561372245202, 'past'),\n",
       " (0.0025157741006159922, 'actually'),\n",
       " (0.0025036908294898317, 'real'),\n",
       " (0.002464474733768167, 'definitely'),\n",
       " (0.0024301010465835196, 'thought'),\n",
       " (0.0024195240627145767, 'happened'),\n",
       " (0.0023911834423426637, 'need'),\n",
       " (0.0023625612301699543, 'layer'),\n",
       " (0.0023205360642397773, 'talenti'),\n",
       " (0.002298842703906421, 'bar'),\n",
       " (0.0022308744311723685, 'hard'),\n",
       " (0.00218123207641164, 'looked'),\n",
       " (0.002154595536005347, 'lot'),\n",
       " (0.002147179900794806, 'half'),\n",
       " (0.0021230760976874174, 'loved'),\n",
       " (0.002118741186736769, 'bite'),\n",
       " (0.0021148135694202966, 'right'),\n",
       " (0.0020845430171067838, 'experience'),\n",
       " (0.0020785729882716445, 'grocery'),\n",
       " (0.002076731062132025, 'dazs'),\n",
       " (0.002067606227215815, 'icecream'),\n",
       " (0.002064337960828176, 'chunk'),\n",
       " (0.0020611988435077114, 'instead'),\n",
       " (0.0020281930564205464, 'available'),\n",
       " (0.0020252218863592982, 'got'),\n",
       " (0.0020209328143476384, 'combination'),\n",
       " (0.002017458229982441, 'sad'),\n",
       " (0.001973413524860323, 'super'),\n",
       " (0.001964715098725047, 'longer'),\n",
       " (0.0019220335657118076, 'purchase'),\n",
       " (0.0019167141187978456, 'old'),\n",
       " (0.001915727482463525, 'marshmallow'),\n",
       " (0.001901247603508133, 'regular'),\n",
       " (0.0018937378387068127, 'stock'),\n",
       " (0.0018905330244998776, 'tasting'),\n",
       " (0.0018758868612181298, 'original'),\n",
       " (0.0018493978081313256, 'jerry'),\n",
       " (0.0018371723848097203, 'sure'),\n",
       " (0.0018370370355436443, 'mint'),\n",
       " (0.0018184279675074204, 'fudge'),\n",
       " (0.0017883502905947446, 'syrup'),\n",
       " (0.0017596404269837392, 'looking'),\n",
       " (0.0017587865624617244, 'happy'),\n",
       " (0.001747896491296068, 'life'),\n",
       " (0.0017262013710206553, 'look'),\n",
       " (0.0016745019512690489, 'ate'),\n",
       " (0.0016700275699522646, 'review'),\n",
       " (0.0016639674258342929, 'tub'),\n",
       " (0.0016453225475059551, 'trying'),\n",
       " (0.0016427682562757376, 'know'),\n",
       " (0.0016371419181747898, 'service'),\n",
       " (0.0016279743697228666, 'making'),\n",
       " (0.0016266365837235698, 'truffle'),\n",
       " (0.0016210436587566482, 'pistachio'),\n",
       " (0.0016203687226535284, 'added'),\n",
       " (0.0016063724857944771, 'haagen'),\n",
       " (0.0016008704426443898, 'bourbon'),\n",
       " (0.0015989327741676113, 'problem'),\n",
       " (0.0015843578130782328, 'banana'),\n",
       " (0.001573450977442293, 'cherry'),\n",
       " (0.0015700261775641444, 'went'),\n",
       " (0.001548403822377203, 'heaven'),\n",
       " (0.0015437131787755466, 'pecan'),\n",
       " (0.0015381961168267056, 'kind'),\n",
       " (0.001535073909935729, 'day'),\n",
       " (0.0015249524174872375, 'overall'),\n",
       " (0.0015221941134582512, 'raspberry'),\n",
       " (0.0015080566127383104, 'enjoyed'),\n",
       " (0.001499065139539273, 'cinnamon'),\n",
       " (0.0014953490555951199, 'bring'),\n",
       " (0.0014940338623682771, 'far'),\n",
       " (0.0014804164438016309, 'add'),\n",
       " (0.0014705934722482046, 'world'),\n",
       " (0.00147042548772192, 'thats'),\n",
       " (0.0014599426666470215, 'wrong'),\n",
       " (0.0014499740448711046, 'enjoy'),\n",
       " (0.0014494195305753302, 'usually'),\n",
       " (0.0014244363414913567, 'absolutely'),\n",
       " (0.0014171202180007772, 'want'),\n",
       " (0.0014083419718369835, 'pie'),\n",
       " (0.0014073952343412396, 'wonderful'),\n",
       " (0.0014030863630828255, 'wasnt'),\n",
       " (0.0013867772171800722, 'saw'),\n",
       " (0.0013661473665011721, 'thanks'),\n",
       " (0.0013505340547974747, 'mango'),\n",
       " (0.001342714199212019, 'light'),\n",
       " (0.0013353454453403574, 'dessert'),\n",
       " (0.0013120165307239843, 'night'),\n",
       " (0.001308773521116923, 'low'),\n",
       " (0.0012867213795840944, 'hope'),\n",
       " (0.0012853124941960164, 'consistency'),\n",
       " (0.0012838732978674582, 'calorie'),\n",
       " (0.0012823657610944936, 'lemon'),\n",
       " (0.0012775595082556138, 'going'),\n",
       " (0.0012614192115788147, 'company'),\n",
       " (0.0012575439993141382, 'le'),\n",
       " (0.0012485479580416948, 'took'),\n",
       " (0.001246631227980786, 'food'),\n",
       " (0.0012446231965635623, 'big'),\n",
       " (0.0012403100907829566, 'pb'),\n",
       " (0.001234657155910373, 'second'),\n",
       " (0.0012326756099464884, 'cheesecake'),\n",
       " (0.0012216413464583545, 'omg'),\n",
       " (0.0012142069473921216, 'opened'),\n",
       " (0.0011956175523421303, 'left'),\n",
       " (0.0011949204287002402, 'crunch'),\n",
       " (0.0011942085456912918, 'mouth'),\n",
       " (0.001186022790001261, 'small'),\n",
       " (0.0011810384161522118, 'freezer'),\n",
       " (0.0011592620563142303, 'long'),\n",
       " (0.0011528647435516954, 'ahoy'),\n",
       " (0.0011487739287445863, 'coconut'),\n",
       " (0.0011432205063112435, 'honestly'),\n",
       " (0.0011364127956612856, 'month'),\n",
       " (0.0011351944755093215, 'balance'),\n",
       " (0.001122337912682979, 'non'),\n",
       " (0.0011222259248291168, 'nice'),\n",
       " (0.0011150215257592325, 'crunchy'),\n",
       " (0.001102714206788616, 'week'),\n",
       " (0.0010848941356411351, 'ago'),\n",
       " (0.0010753374862741178, 'husband'),\n",
       " (0.0010749511325853858, 'single'),\n",
       " (0.001069591206025387, 'glad'),\n",
       " (0.001065387615877054, 'hit'),\n",
       " (0.001058292849497909, 'carb'),\n",
       " (0.0010554772945299434, 'flavored'),\n",
       " (0.0010414795596408795, 'literally'),\n",
       " (0.0010410461328402276, 'salty'),\n",
       " (0.0010404778930123023, 'recommend'),\n",
       " (0.001034211064274607, 'yummy'),\n",
       " (0.001029637201052511, 'sold'),\n",
       " (0.0010260826222846218, 'sitting'),\n",
       " (0.0010211319402347828, 'entire'),\n",
       " (0.0010197896970421353, 'hooked'),\n",
       " (0.0010179277096377106, 'especially'),\n",
       " (0.0010103459330073638, 'pretzel'),\n",
       " (0.0010082857363760474, 'vegan'),\n",
       " (0.0010056383535180066, 'carton'),\n",
       " (0.0010040587755896333, 'came'),\n",
       " (0.0010007471616335674, 'green'),\n",
       " (0.0009987092057674233, 'tell'),\n",
       " (0.0009924352461852198, 'youre'),\n",
       " (0.000990000203272633, 'exactly'),\n",
       " (0.0009816338808716983, 'huge'),\n",
       " (0.000981580539240369, 'mix'),\n",
       " (0.0009811415786216205, 'dark'),\n",
       " (0.000966007774103299, 'awesome'),\n",
       " (0.000964545828966402, 'craving'),\n",
       " (0.0009632886659814042, 'cup'),\n",
       " (0.0009512450542603235, 'rest'),\n",
       " (0.0009507197302021739, 'nut'),\n",
       " (0.0009401356341826107, 'serving'),\n",
       " (0.0009292407299618928, 'said'),\n",
       " (0.000926217434421299, 'milk'),\n",
       " (0.0009256332196817139, 'area'),\n",
       " (0.0009198997957576367, 'high'),\n",
       " (0.0009191456961089884, 'pretty'),\n",
       " (0.0009163616151501492, 'different'),\n",
       " (0.0009142370920575149, 'getting'),\n",
       " (0.0009131982816996333, 'liked'),\n",
       " (0.0009117538560351275, 'version'),\n",
       " (0.000895794147957991, 'isnt'),\n",
       " (0.0008812511096811166, 'away'),\n",
       " (0.0008747564457906919, 'oh'),\n",
       " (0.0008690972249222776, 'issue'),\n",
       " (0.0008671524202770163, 'feel'),\n",
       " (0.0008591186264854595, 'stuff'),\n",
       " (0.0008478273019464788, 'wont'),\n",
       " (0.0008476308155611371, 'market'),\n",
       " (0.0008473741781080897, 'stopped'),\n",
       " (0.0008458054492099751, 'strawberry'),\n",
       " (0.0008351998936285194, 'missing'),\n",
       " (0.000833678934774215, 'cone'),\n",
       " (0.0008293257707521525, 'thinking'),\n",
       " (0.0008179934629184403, 'ill'),\n",
       " (0.0008177173981940152, 'peppermint'),\n",
       " (0.0008170340225645359, 'star'),\n",
       " (0.0008137205398093881, 'friend'),\n",
       " (0.0008054821288350412, 'local'),\n",
       " (0.000800844994008387, 'tasty'),\n",
       " (0.0008000934213863762, 'price'),\n",
       " (0.0007940845883940468, 'refreshing'),\n",
       " (0.000784689192584239, 'excellent'),\n",
       " (0.0007795695986436906, 'list'),\n",
       " (0.0007780086618158347, 'melt'),\n",
       " (0.0007606707158686226, 'today'),\n",
       " (0.0007564751101744441, '10'),\n",
       " (0.0007526417568608135, 'quite'),\n",
       " (0.000747698668014787, 'point'),\n",
       " (0.0007411161410522351, 'cake'),\n",
       " (0.0007358698182059886, 'base'),\n",
       " (0.0007271074011677233, 'graham'),\n",
       " (0.0007253167685799609, 'decadent'),\n",
       " (0.0007235393792238724, 'able'),\n",
       " (0.0007227611476732031, 'customer'),\n",
       " (0.000713370579077808, 'artificial'),\n",
       " (0.0007125489496379215, 'people'),\n",
       " (0.0007031592556969423, 'tonight'),\n",
       " (0.0006989831265427675, 'couple'),\n",
       " (0.0006950445512204195, 'live'),\n",
       " (0.0006910725604337888, 'believe'),\n",
       " (0.0006877341620972151, 'sorbet'),\n",
       " (0.0006873495595467483, 'hint'),\n",
       " (0.0006872020048092552, 'blend'),\n",
       " (0.0006781509696667596, 'probably'),\n",
       " (0.0006766608916406276, 'option'),\n",
       " (0.0006675362692251525, 'worth'),\n",
       " (0.0006608117222538564, 'baked'),\n",
       " (0.0006538672290699923, 'scoop'),\n",
       " (0.0006471051965465653, 'special'),\n",
       " (0.0006438677356178899, 'cracker'),\n",
       " (0.0006408969358443399, 'sorbetto'),\n",
       " (0.00064065338160887, 'consumer'),\n",
       " (0.0006377289790341327, 'bigger'),\n",
       " (0.0006283471286352353, 'oatmeal'),\n",
       " (0.0006256967452675044, 'size'),\n",
       " (0.0006226552140981516, 'kid'),\n",
       " (0.0006167184544538172, 'strong'),\n",
       " (0.0006132547997761366, 'spoonful'),\n",
       " (0.0006114390113560216, 'discontinued'),\n",
       " (0.0006102880073804167, 'unilever'),\n",
       " (0.0006080678757891675, 'recently'),\n",
       " (0.0006044111546346318, 'flavour'),\n",
       " (0.0006013161183754031, 'absolute'),\n",
       " (0.0005954512856150735, 'place'),\n",
       " (0.0005896361772265115, 'finally'),\n",
       " (0.0005864248778249011, 'family'),\n",
       " (0.0005740429451097878, 'completely'),\n",
       " (0.0005728277275939243, 'addicted'),\n",
       " (0.0005698680226813905, 'forever'),\n",
       " (0.000563284957712843, 'simple'),\n",
       " (0.0005575515731255575, 'read'),\n",
       " (0.0005546961868055676, 'line'),\n",
       " (0.0005524466928198033, 'salt'),\n",
       " (0.0005471018970751738, 'obsessed'),\n",
       " (0.0005469232563026438, 'wait'),\n",
       " (0.0005462554469009898, 'guy'),\n",
       " (0.0005434638146794064, 'spoon'),\n",
       " (0.0005359921920718031, 'highly'),\n",
       " (0.000532721395485085, 'seriously'),\n",
       " (0.0005312932610645642, 'let'),\n",
       " (0.0005291740901947808, 'end'),\n",
       " (0.0005220564228907428, 'frozen'),\n",
       " (0.0005215376707035616, 'finding'),\n",
       " (0.0005167300451216253, 'box'),\n",
       " (0.0005167206259008243, 'lover'),\n",
       " (0.0005155576735182541, 'permanent'),\n",
       " (0.0005129373512658119, 'received'),\n",
       " (0.0005097964004793966, 'covered'),\n",
       " (0.0005065321273903005, 'opinion'),\n",
       " (0.0004998511374612844, 'true'),\n",
       " (0.000499488548665087, 'fell'),\n",
       " (0.0004947500343368128, 'target'),\n",
       " (0.0004845028382552592, 'lactose'),\n",
       " (0.0004832088284857034, 'work'),\n",
       " (0.00047323643187066616, 'smores'),\n",
       " (0.0004715363478446756, 'salted'),\n",
       " (0.0004650123069438427, 'decided'),\n",
       " (0.0004525413793294601, 'hand'),\n",
       " (0.0004467570862457022, 'choice'),\n",
       " (0.00044603870710243823, 'fresh'),\n",
       " (0.00044474352086520486, 'id'),\n",
       " (0.00044409829784726153, 'eaten'),\n",
       " (0.0004336414796115051, 'truly'),\n",
       " (0.0004317798016808653, 'shelf'),\n",
       " (0.0004306022414028806, 'perfectly'),\n",
       " (0.0004227549906604093, 'gone'),\n",
       " (0.00040950971046411897, 'write'),\n",
       " (0.0004083912015678607, 'home'),\n",
       " (0.0004023889721123104, 'sell'),\n",
       " (0.0003909150085348281, 'carbs'),\n",
       " (0.0003888686839739842, 'testing'),\n",
       " (0.00038872786968005703, 'yum'),\n",
       " (0.00038757933077454505, 'com'),\n",
       " (0.00038737945391990495, 'cold'),\n",
       " (0.0003859184893387644, 'surprised'),\n",
       " (0.00038334748754806017, 'goodness'),\n",
       " (0.00038188979725125086, 'satisfying'),\n",
       " (0.00038056413782982216, 'forward'),\n",
       " (0.0003686958927853185, 'extremely'),\n",
       " (0.00036831558744037794, 'dream'),\n",
       " (0.0003673847689334364, 'havent'),\n",
       " (0.00036115111106751807, 'apple'),\n",
       " (0.00035955010046109185, 'limited'),\n",
       " (0.0003463061238559052, 'influenster'),\n",
       " (0.0003381919348939409, 'mixed'),\n",
       " (0.0003349194516061223, 'simply'),\n",
       " (0.0003137170594315942, 'soft'),\n",
       " (0.00030981387249397603, 'perfection'),\n",
       " (0.00029639985080361265, 'item'),\n",
       " (0.00029579218145104106, 'wow'),\n",
       " (0.00029375426504901, 'walmart'),\n",
       " (0.00028890147644730727, 'fact'),\n",
       " (0.0002758226896639692, 'help'),\n",
       " (0.0002737849049912703, 'finished'),\n",
       " (0.0002702835084459631, 'discontinue'),\n",
       " (0.00025712207339762964, 'extra'),\n",
       " (0.0002550785533959647, 'pumpkin'),\n",
       " (0.0002530002721401976, 'son'),\n",
       " (0.0002460155330336512, 'summer'),\n",
       " (0.0002391002418365918, 'lol'),\n",
       " (0.00022937729682720036, 'combo'),\n",
       " (0.00022109458344163213, 'totally'),\n",
       " (0.0002054513472925479, 'fantastic'),\n",
       " (0.0002052607366024728, 'sweetness'),\n",
       " (0.00020500936659693, 'carry'),\n",
       " (0.00020353315371878989, 'easy'),\n",
       " (0.00018314169432117572, 'mean'),\n",
       " (0.0001788477506493664, 'yes'),\n",
       " (0.00016193950998495774, 'delight'),\n",
       " (0.00016132759892550138, 'gave'),\n",
       " (0.00016023749234125466, 'diet'),\n",
       " (0.00010528680472881623, 'soon'),\n",
       " (0.00010069299427110465, 'white'),\n",
       " (8.669624762423025e-05, 'phish')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importance = sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features\n",
      "Ranked by Importance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.041157708829910405, 'disappointed'),\n",
       " (0.028948902182373802, 'love'),\n",
       " (0.027405979960501783, 'best'),\n",
       " (0.022006239790729087, 'taste'),\n",
       " (0.020822530188481823, 'like'),\n",
       " (0.019960635583354813, 'vanilla'),\n",
       " (0.01719809286548308, 'used'),\n",
       " (0.016903925216234215, 'flavor'),\n",
       " (0.016359805731422605, 'perfect'),\n",
       " (0.015376806285808607, 'delicious')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(str('Top 10 Features'))\n",
    "print(str('Ranked by Importance'))\n",
    "display(feature_importance[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 10 Features\n",
      "Ranked by Importance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.00020500936659693, 'carry'),\n",
       " (0.00020353315371878989, 'easy'),\n",
       " (0.00018314169432117572, 'mean'),\n",
       " (0.0001788477506493664, 'yes'),\n",
       " (0.00016193950998495774, 'delight'),\n",
       " (0.00016132759892550138, 'gave'),\n",
       " (0.00016023749234125466, 'diet'),\n",
       " (0.00010528680472881623, 'soon'),\n",
       " (0.00010069299427110465, 'white'),\n",
       " (8.669624762423025e-05, 'phish')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(str('Bottom 10 Features'))\n",
    "print(str('Ranked by Importance'))\n",
    "display(feature_importance[-10:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
