{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)\n",
    "## Feature Extraction & Vectorizing\n",
    "\n",
    "The primary goal of this notebook is to get the data compatible with supervised machine learning algorithms. \n",
    "Essentially, this notebook serves as the pre-processing for supervised NLP ML models. \n",
    "\n",
    "At this stage in the project, it is beneficial to decision making to see as much of the output as possible to ensure the code\n",
    "is working as intended and adjust/improve where possible.  The markdowns here are meant to be a guide to walk through what the\n",
    "code is doing and why.\n",
    "\n",
    "\n",
    "## Scope of this notebook:\n",
    "\n",
    "### 1.  Data Inspection\n",
    "### 2.  Add Sentiment Feature to data set\n",
    "### 3.  Create Product Sentiment Reviews Dataset\n",
    "### 4.  Tokenize \"text\" words\n",
    "### 5.  Bag of Words - Extract the most common words\n",
    "### 6.  Create Tokenized Reviews data set\n",
    "### 7.  TFID Vectorizing for Supervised  ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are starting with a review dataset that has been filtered down to ice cream products that have achieved an amazon rating of 4 stars or higher joined on the key feature with consumer reviews that have been filtered down those that received more helpful_yes votes than helpful_no votes.\n",
    "\n",
    "(insert why we chose to filter and clean the dataset this way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  \n",
       "0  I am interested in the flavoring components us...     4.1  \n",
       "1  Boy, was I surprised when I got my Bryers home...     4.1  \n",
       "2  I havent purchased this product in awhile and ...     4.1  \n",
       "3  The Natural Vanilla recipe change to include T...     4.1  \n",
       "4  I had the same issue with breyers. I finally f...     4.1  "
      ]
     },
     "execution_count": 894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data source\n",
    "df = pd.read_csv(\"Resources/helpful_clean_reviews_combined.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the data is key to ensuring its compatible with any functions or methods required for the code to perform.\n",
    "We know, off the cusp, that unsupervised ML doesn't like strings or null values so lets identify any of those. Also, we will remove any duplicate data as it doesn't tell us anything new and may skew results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows     :  3424\n",
      "Columns  :  6\n",
      "\n",
      "Features :  ['key', 'stars', 'helpful_yes', 'helpful_no', 'text', 'rating']\n",
      "\n",
      "Missing values :   0\n",
      "\n",
      "Unique values :  \n",
      " key             184\n",
      "stars             5\n",
      "helpful_yes      66\n",
      "helpful_no       20\n",
      "text           3419\n",
      "rating           11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data overview\n",
    "print ('Rows     : ', df.shape[0])\n",
    "print ('Columns  : ', df.shape[1])\n",
    "print ('\\nFeatures : ', df.columns.tolist())\n",
    "print ('\\nMissing values :  ', df.isnull().sum().values.sum())\n",
    "print ('\\nUnique values :  \\n', df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3424 entries, 0 to 3423\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   key          3424 non-null   object \n",
      " 1   stars        3424 non-null   int64  \n",
      " 2   helpful_yes  3424 non-null   int64  \n",
      " 3   helpful_no   3424 non-null   int64  \n",
      " 4   text         3424 non-null   object \n",
      " 5   rating       3424 non-null   float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 160.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# find missing values and view data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column key has 0 null values\n",
      "Column stars has 0 null values\n",
      "Column helpful_yes has 0 null values\n",
      "Column helpful_no has 0 null values\n",
      "Column text has 0 null values\n",
      "Column rating has 0 null values\n"
     ]
    }
   ],
   "source": [
    "# Find null values\n",
    "for column in df.columns:\n",
    "    print(f\"Column {column} has {df[column].isnull().sum()} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries: 4\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate entries\n",
    "# duplicate entries are not telling us anything new  and can skew results\n",
    "print(f\"Duplicate entries: {(df.duplicated().sum()) * 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I tried the new flavor with layers and it was ...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>love this ice cream, taste fantastic!! will ne...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite cream. Where can I find th...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The best tasting ice cream out there! It is ve...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite, period. If I cant find it...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3419 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "0     0_breyers      1           11           0   \n",
       "1     0_breyers      1            7           0   \n",
       "2     0_breyers      1            8           0   \n",
       "3     0_breyers      1            4           0   \n",
       "4     0_breyers      5           21           2   \n",
       "...         ...    ...          ...         ...   \n",
       "3419       9_hd      5            1           0   \n",
       "3420       9_hd      5            1           0   \n",
       "3421       9_hd      5            1           0   \n",
       "3422       9_hd      5            1           0   \n",
       "3423       9_hd      5            1           0   \n",
       "\n",
       "                                                   text  rating  \n",
       "0     I am interested in the flavoring components us...     4.1  \n",
       "1     Boy, was I surprised when I got my Bryers home...     4.1  \n",
       "2     I havent purchased this product in awhile and ...     4.1  \n",
       "3     The Natural Vanilla recipe change to include T...     4.1  \n",
       "4     I had the same issue with breyers. I finally f...     4.1  \n",
       "...                                                 ...     ...  \n",
       "3419  I tried the new flavor with layers and it was ...     4.9  \n",
       "3420  love this ice cream, taste fantastic!! will ne...     4.9  \n",
       "3421  This is my favorite cream. Where can I find th...     4.9  \n",
       "3422  The best tasting ice cream out there! It is ve...     4.9  \n",
       "3423  This is my favorite, period. If I cant find it...     4.9  \n",
       "\n",
       "[3419 rows x 6 columns]"
      ]
     },
     "execution_count": 899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate entries\n",
    "df.drop_duplicates(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I tried the new flavor with layers and it was ...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>love this ice cream, taste fantastic!! will ne...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite cream. Where can I find th...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The best tasting ice cream out there! It is ve...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite, period. If I cant find it...</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3424 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "0     0_breyers      1           11           0   \n",
       "1     0_breyers      1            7           0   \n",
       "2     0_breyers      1            8           0   \n",
       "3     0_breyers      1            4           0   \n",
       "4     0_breyers      5           21           2   \n",
       "...         ...    ...          ...         ...   \n",
       "3419       9_hd      5            1           0   \n",
       "3420       9_hd      5            1           0   \n",
       "3421       9_hd      5            1           0   \n",
       "3422       9_hd      5            1           0   \n",
       "3423       9_hd      5            1           0   \n",
       "\n",
       "                                                   text  rating  \n",
       "0     I am interested in the flavoring components us...     4.1  \n",
       "1     Boy, was I surprised when I got my Bryers home...     4.1  \n",
       "2     I havent purchased this product in awhile and ...     4.1  \n",
       "3     The Natural Vanilla recipe change to include T...     4.1  \n",
       "4     I had the same issue with breyers. I finally f...     4.1  \n",
       "...                                                 ...     ...  \n",
       "3419  I tried the new flavor with layers and it was ...     4.9  \n",
       "3420  love this ice cream, taste fantastic!! will ne...     4.9  \n",
       "3421  This is my favorite cream. Where can I find th...     4.9  \n",
       "3422  The best tasting ice cream out there! It is ve...     4.9  \n",
       "3423  This is my favorite, period. If I cant find it...     4.9  \n",
       "\n",
       "[3424 rows x 6 columns]"
      ]
     },
     "execution_count": 900,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create data_df to hold new dataset without duplicates\n",
    "df_data = pd.DataFrame(df)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Add Sentiment Feature to data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include a sentiment in case we run a sentiment analysis, which is very popular with NLP modeling. \n",
    "Here we will assign a value of 1 to reflect positive sentiment. This consists of star rating greater than or equal to 5. \n",
    "Any review with a star rating less than 5 gets a value of 0 to reflect negative sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \n",
       "0  I am interested in the flavoring components us...     4.1        NaN  \n",
       "1  Boy, was I surprised when I got my Bryers home...     4.1        NaN  \n",
       "2  I havent purchased this product in awhile and ...     4.1        NaN  \n",
       "3  The Natural Vanilla recipe change to include T...     4.1        NaN  \n",
       "4  I had the same issue with breyers. I finally f...     4.1        NaN  "
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add sentiment column to df_data\n",
    "df_data['sentiment'] = pd.Series(dtype='int64')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \n",
       "0  I am interested in the flavoring components us...     4.1          0  \n",
       "1  Boy, was I surprised when I got my Bryers home...     4.1          0  \n",
       "2  I havent purchased this product in awhile and ...     4.1          0  \n",
       "3  The Natural Vanilla recipe change to include T...     4.1          0  \n",
       "4  I had the same issue with breyers. I finally f...     4.1          1  "
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign 1 for positive sentiment, 0 for negative\n",
    "# I'm bad with functions, this link helped me get it right. \n",
    "# https://stackoverflow.com/questions/30953299/pandas-if-row-in-column-a-contains-x-write-y-to-row-in-column-b\n",
    "def applyFunc(s):\n",
    "    if s >= 5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# populate column        \n",
    "df_data['sentiment'] = df_data['stars'].apply(applyFunc)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>I had the same issue with breyers. I finally f...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>After trying Bryers Natural Vanilla Ice Cream ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>if this flavor is ever retired, i swear -- my ...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>I am an ice cream addict and this flavour has ...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>This flavor is sloop good, I eat about 2 a day...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I tried the new flavor with layers and it was ...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>love this ice cream, taste fantastic!! will ne...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite cream. Where can I find th...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The best tasting ice cream out there! It is ve...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>9_hd</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite, period. If I cant find it...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2530 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "4     0_breyers      5           21           2   \n",
       "56    0_breyers      5           53          32   \n",
       "74         0_hd      5           27           0   \n",
       "75         0_hd      5           10           0   \n",
       "76         0_hd      5            4           0   \n",
       "...         ...    ...          ...         ...   \n",
       "3419       9_hd      5            1           0   \n",
       "3420       9_hd      5            1           0   \n",
       "3421       9_hd      5            1           0   \n",
       "3422       9_hd      5            1           0   \n",
       "3423       9_hd      5            1           0   \n",
       "\n",
       "                                                   text  rating  sentiment  \n",
       "4     I had the same issue with breyers. I finally f...     4.1          1  \n",
       "56    After trying Bryers Natural Vanilla Ice Cream ...     4.1          1  \n",
       "74    if this flavor is ever retired, i swear -- my ...     4.9          1  \n",
       "75    I am an ice cream addict and this flavour has ...     4.9          1  \n",
       "76    This flavor is sloop good, I eat about 2 a day...     4.9          1  \n",
       "...                                                 ...     ...        ...  \n",
       "3419  I tried the new flavor with layers and it was ...     4.9          1  \n",
       "3420  love this ice cream, taste fantastic!! will ne...     4.9          1  \n",
       "3421  This is my favorite cream. Where can I find th...     4.9          1  \n",
       "3422  The best tasting ice cream out there! It is ve...     4.9          1  \n",
       "3423  This is my favorite, period. If I cant find it...     4.9          1  \n",
       "\n",
       "[2530 rows x 7 columns]"
      ]
     },
     "execution_count": 903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create positive sentiment dataframe\n",
    "# delete if not used in rest of notebook\n",
    "# again, seeing output may drive inspiration for new ideas or provide clarity on the direction. \n",
    "\n",
    "df_positive_sentiment = df_data[df_data['sentiment'] ==1]\n",
    "df_positive_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>I am interested in the flavoring components us...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boy, was I surprised when I got my Bryers home...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>I havent purchased this product in awhile and ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>The Natural Vanilla recipe change to include T...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I rarely eat ice cream these days but bought t...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>I dont buy a lot of ice cream, gelato, or swee...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>The top layers are great. Tastes like cheeseca...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I was really excited to try this flavor but wa...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>All of your flavors are such high quality and ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>8_talenti</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tastes great except there was absolutely no ch...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>894 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key  stars  helpful_yes  helpful_no  \\\n",
       "0     0_breyers      1           11           0   \n",
       "1     0_breyers      1            7           0   \n",
       "2     0_breyers      1            8           0   \n",
       "3     0_breyers      1            4           0   \n",
       "5     0_breyers      1            4           0   \n",
       "...         ...    ...          ...         ...   \n",
       "3349  8_talenti      2            3           1   \n",
       "3352  8_talenti      3            3           0   \n",
       "3358  8_talenti      3            2           1   \n",
       "3361  8_talenti      3            1           0   \n",
       "3372  8_talenti      2            1           0   \n",
       "\n",
       "                                                   text  rating  sentiment  \n",
       "0     I am interested in the flavoring components us...     4.1          0  \n",
       "1     Boy, was I surprised when I got my Bryers home...     4.1          0  \n",
       "2     I havent purchased this product in awhile and ...     4.1          0  \n",
       "3     The Natural Vanilla recipe change to include T...     4.1          0  \n",
       "5     I rarely eat ice cream these days but bought t...     4.1          0  \n",
       "...                                                 ...     ...        ...  \n",
       "3349  I dont buy a lot of ice cream, gelato, or swee...     4.3          0  \n",
       "3352  The top layers are great. Tastes like cheeseca...     4.3          0  \n",
       "3358  I was really excited to try this flavor but wa...     4.3          0  \n",
       "3361  All of your flavors are such high quality and ...     4.3          0  \n",
       "3372  Tastes great except there was absolutely no ch...     4.3          0  \n",
       "\n",
       "[894 rows x 7 columns]"
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create negative sentiment dataframe\n",
    "# delete if not used in rest of notebook\n",
    "\n",
    "df_negative_sentiment = df_data[df_data['sentiment'] ==0]\n",
    "df_negative_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Create Product Sentiment Reviews Dataset\n",
    "\n",
    "This is the helpful_cleaned_reviews_combined.csv with duplicates removed and sentiment column added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create product_sentiment_reviews.csv\n",
    "df_data.to_csv(\"Resources/product_sentiment_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Tokenize \"text\" words\n",
    "\n",
    "We are working with text data we have to count the number of words in the text, as well as, identify the number of times a particular word is present. We Tokenize the text data to do just that.\n",
    "\n",
    "Here is where all the magic of splitting the reviews into single words, putting each word into lower case, lemmatizing each to its base form, removing punctuations and excluding stop words occurs. We still have more work to do to clean this up, but hey, the code is there. \n",
    "\n",
    "While there are plenty of library and program options, we've tokenized with NLTK as this is the best way to see whats happening step by step.  \n",
    "\n",
    "As we do more research, we may change our minds and adopt libraries and programs that offer \"cleaner\" coding opportunities and better performance now that we have a clearer vision of what the code is doing function by function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer dataframe\n",
    "df_tokenize = pd.DataFrame(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Tokenizer library\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "\n",
    "# RegexpTokenizer will tokenize according to any regular expression assigned. \n",
    "# The regular expression r'\\w+' matches any pattern consisting of one or more consecutive letters.\n",
    "reTokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all the words from all the reviews into one list\n",
    "\n",
    "# initialize list to hold words\n",
    "all_words = []\n",
    "\n",
    "\n",
    "for i in range(len(df_tokenize['text'])):\n",
    "    # separate review text into a list of words\n",
    "    tokens = reTokenizer.tokenize(df_tokenize['text'][i])\n",
    "    \n",
    "    \n",
    "    df_tokenize['text'][i] = []\n",
    "    \n",
    "    # iterate through tokens\n",
    "    for word in tokens:\n",
    "        # lower the case of each word\n",
    "        word = word.lower()\n",
    "        # exclude stop words\n",
    "        if word not in stop_words:\n",
    "            \n",
    "            # Lemmatize words into a standard form and avoid counting the same word more than once\n",
    "            word = lemmatizer.lemmatize(word)\n",
    "            # add to list of words\n",
    "            all_words.append(word)\n",
    "            df_tokenize['text'][i].append(word)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Bag of Words? Extract the most common words\n",
    "\n",
    "\"bag of words\" and \"most common words\" is used interchangeably throughout the rest of this notebook. We will fix it to be consistent after everyone has mastered comfort with the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cream', 3175),\n",
       " ('ice', 3018),\n",
       " ('flavor', 2681),\n",
       " ('chocolate', 1419),\n",
       " ('love', 1123),\n",
       " ('like', 987),\n",
       " ('one', 909),\n",
       " ('taste', 857),\n",
       " ('favorite', 725),\n",
       " ('good', 676),\n",
       " ('best', 645),\n",
       " ('vanilla', 566),\n",
       " ('would', 547),\n",
       " ('pint', 534),\n",
       " ('ever', 518),\n",
       " ('time', 504),\n",
       " ('get', 470),\n",
       " ('creamy', 459),\n",
       " ('cookie', 456),\n",
       " ('store', 453),\n",
       " ('find', 432),\n",
       " ('delicious', 432),\n",
       " ('please', 431),\n",
       " ('great', 398),\n",
       " ('try', 390),\n",
       " ('really', 389),\n",
       " ('im', 383),\n",
       " ('butter', 383),\n",
       " ('tried', 379),\n",
       " ('sweet', 379),\n",
       " ('gelato', 373),\n",
       " ('perfect', 370),\n",
       " ('make', 368),\n",
       " ('chip', 352),\n",
       " ('product', 351),\n",
       " ('buy', 348),\n",
       " ('texture', 346),\n",
       " ('amazing', 344),\n",
       " ('caramel', 341),\n",
       " ('breyers', 339),\n",
       " ('new', 339),\n",
       " ('eat', 338),\n",
       " ('peanut', 337),\n",
       " ('ive', 334),\n",
       " ('first', 331),\n",
       " ('year', 327),\n",
       " ('much', 314),\n",
       " ('go', 308),\n",
       " ('dairy', 308),\n",
       " ('never', 305),\n",
       " ('bought', 285),\n",
       " ('dont', 266),\n",
       " ('every', 266),\n",
       " ('chunk', 264),\n",
       " ('back', 254),\n",
       " ('always', 252),\n",
       " ('better', 246),\n",
       " ('could', 240),\n",
       " ('even', 240),\n",
       " ('coffee', 240),\n",
       " ('talenti', 231),\n",
       " ('free', 230),\n",
       " ('jerry', 229),\n",
       " ('ben', 226),\n",
       " ('cooky', 224),\n",
       " ('eating', 223),\n",
       " ('little', 218),\n",
       " ('dough', 218),\n",
       " ('cant', 211),\n",
       " ('thing', 209),\n",
       " ('swirl', 208),\n",
       " ('brand', 206),\n",
       " ('day', 204),\n",
       " ('rich', 204),\n",
       " ('also', 203),\n",
       " ('container', 203),\n",
       " ('since', 202),\n",
       " ('way', 202),\n",
       " ('fudge', 200),\n",
       " ('disappointed', 194),\n",
       " ('bit', 194),\n",
       " ('definitely', 194),\n",
       " ('mint', 193),\n",
       " ('found', 191),\n",
       " ('well', 189),\n",
       " ('smooth', 187),\n",
       " ('tasted', 185),\n",
       " ('made', 183),\n",
       " ('ingredient', 182),\n",
       " ('piece', 182),\n",
       " ('haagen', 180),\n",
       " ('thank', 179),\n",
       " ('know', 178),\n",
       " ('used', 177),\n",
       " ('say', 177),\n",
       " ('hard', 177),\n",
       " ('treat', 176),\n",
       " ('layer', 175),\n",
       " ('bite', 170),\n",
       " ('see', 169),\n",
       " ('still', 169),\n",
       " ('dazs', 168),\n",
       " ('last', 167),\n",
       " ('almond', 167),\n",
       " ('right', 166),\n",
       " ('think', 166),\n",
       " ('wish', 166),\n",
       " ('got', 164),\n",
       " ('keep', 163),\n",
       " ('need', 161),\n",
       " ('fan', 158),\n",
       " ('review', 156),\n",
       " ('come', 156),\n",
       " ('something', 156),\n",
       " ('absolutely', 152),\n",
       " ('two', 150),\n",
       " ('far', 150),\n",
       " ('milk', 148),\n",
       " ('sugar', 147),\n",
       " ('enough', 147),\n",
       " ('buying', 145),\n",
       " ('many', 141),\n",
       " ('whole', 140),\n",
       " ('non', 139),\n",
       " ('3', 137),\n",
       " ('loved', 136),\n",
       " ('stop', 136),\n",
       " ('combination', 135),\n",
       " ('thought', 134),\n",
       " ('hope', 133),\n",
       " ('real', 131),\n",
       " ('2', 129),\n",
       " ('another', 129),\n",
       " ('brownie', 129),\n",
       " ('grocery', 128),\n",
       " ('feel', 128),\n",
       " ('trying', 128),\n",
       " ('didnt', 127),\n",
       " ('lot', 127),\n",
       " ('pistachio', 126),\n",
       " ('raspberry', 125),\n",
       " ('want', 124),\n",
       " ('almost', 124),\n",
       " ('bar', 124),\n",
       " ('dessert', 123),\n",
       " ('cherry', 123),\n",
       " ('amount', 123),\n",
       " ('ago', 122),\n",
       " ('change', 120),\n",
       " ('making', 120),\n",
       " ('core', 120),\n",
       " ('sure', 119),\n",
       " ('u', 119),\n",
       " ('natural', 118),\n",
       " ('however', 118),\n",
       " ('half', 116),\n",
       " ('crunch', 116),\n",
       " ('strawberry', 114),\n",
       " ('going', 113),\n",
       " ('cheesecake', 113),\n",
       " ('frozen', 112),\n",
       " ('different', 112),\n",
       " ('though', 112),\n",
       " ('local', 112),\n",
       " ('week', 111),\n",
       " ('bad', 110),\n",
       " ('enjoy', 110),\n",
       " ('quality', 109),\n",
       " ('nice', 109),\n",
       " ('recommend', 108),\n",
       " ('freezer', 108),\n",
       " ('saw', 108),\n",
       " ('mango', 108),\n",
       " ('add', 107),\n",
       " ('big', 107),\n",
       " ('super', 106),\n",
       " ('regular', 106),\n",
       " ('actually', 105),\n",
       " ('went', 105),\n",
       " ('family', 104),\n",
       " ('marshmallow', 103),\n",
       " ('icecream', 102),\n",
       " ('away', 101),\n",
       " ('look', 101),\n",
       " ('people', 100),\n",
       " ('give', 100),\n",
       " ('5', 100),\n",
       " ('life', 99),\n",
       " ('dark', 99),\n",
       " ('nothing', 98),\n",
       " ('pie', 97),\n",
       " ('long', 97),\n",
       " ('month', 97),\n",
       " ('food', 96),\n",
       " ('available', 96),\n",
       " ('oreo', 96),\n",
       " ('mouth', 95),\n",
       " ('coconut', 95),\n",
       " ('recipe', 94),\n",
       " ('put', 93),\n",
       " ('b', 93),\n",
       " ('everything', 93),\n",
       " ('thanks', 93),\n",
       " ('top', 92),\n",
       " ('stuff', 92),\n",
       " ('happy', 92),\n",
       " ('changed', 91),\n",
       " ('take', 91),\n",
       " ('without', 91),\n",
       " ('calorie', 91),\n",
       " ('around', 90),\n",
       " ('husband', 90),\n",
       " ('doesnt', 90),\n",
       " ('j', 90),\n",
       " ('tasting', 89),\n",
       " ('looking', 88),\n",
       " ('size', 88),\n",
       " ('usually', 88),\n",
       " ('cinnamon', 88),\n",
       " ('part', 87),\n",
       " ('bean', 86),\n",
       " ('1', 86),\n",
       " ('old', 86),\n",
       " ('world', 84),\n",
       " ('came', 83),\n",
       " ('excited', 83),\n",
       " ('sad', 82),\n",
       " ('graham', 82),\n",
       " ('anything', 81),\n",
       " ('full', 81),\n",
       " ('entire', 81),\n",
       " ('wonderful', 81),\n",
       " ('huge', 80),\n",
       " ('le', 79),\n",
       " ('purchased', 79),\n",
       " ('stock', 79),\n",
       " ('home', 78),\n",
       " ('purchase', 78),\n",
       " ('maybe', 78),\n",
       " ('sitting', 78),\n",
       " ('glad', 78),\n",
       " ('4', 78),\n",
       " ('longer', 76),\n",
       " ('base', 76),\n",
       " ('balance', 76),\n",
       " ('awesome', 76),\n",
       " ('recently', 75),\n",
       " ('pecan', 75),\n",
       " ('night', 75),\n",
       " ('crunchy', 75),\n",
       " ('kind', 75),\n",
       " ('hand', 74),\n",
       " ('low', 73),\n",
       " ('literally', 73),\n",
       " ('kid', 73),\n",
       " ('salty', 73),\n",
       " ('bourbon', 73),\n",
       " ('carb', 73),\n",
       " ('star', 72),\n",
       " ('lover', 72),\n",
       " ('able', 72),\n",
       " ('truffle', 71),\n",
       " ('together', 71),\n",
       " ('cracker', 71),\n",
       " ('anymore', 70),\n",
       " ('instead', 70),\n",
       " ('10', 70),\n",
       " ('pretzel', 70),\n",
       " ('yummy', 69),\n",
       " ('friend', 68),\n",
       " ('pretty', 67),\n",
       " ('light', 67),\n",
       " ('mix', 67),\n",
       " ('oh', 67),\n",
       " ('added', 66),\n",
       " ('bring', 66),\n",
       " ('couldnt', 66),\n",
       " ('problem', 66),\n",
       " ('batch', 66),\n",
       " ('must', 65),\n",
       " ('thats', 65),\n",
       " ('cup', 65),\n",
       " ('wasnt', 65),\n",
       " ('next', 65),\n",
       " ('disappointing', 64),\n",
       " ('tell', 64),\n",
       " ('highly', 64),\n",
       " ('honestly', 64),\n",
       " ('decided', 63),\n",
       " ('ill', 63),\n",
       " ('perfectly', 63),\n",
       " ('carbs', 63),\n",
       " ('ahoy', 63),\n",
       " ('unfortunately', 62),\n",
       " ('scoop', 62),\n",
       " ('experience', 62),\n",
       " ('others', 62),\n",
       " ('target', 62),\n",
       " ('price', 61),\n",
       " ('wanted', 61),\n",
       " ('heaven', 61),\n",
       " ('bottom', 61),\n",
       " ('several', 60),\n",
       " ('let', 60),\n",
       " ('ate', 60),\n",
       " ('absolute', 60),\n",
       " ('tasty', 60),\n",
       " ('craving', 60),\n",
       " ('left', 59),\n",
       " ('gone', 59),\n",
       " ('soft', 59),\n",
       " ('reason', 59),\n",
       " ('cannot', 59),\n",
       " ('said', 59),\n",
       " ('small', 59),\n",
       " ('hit', 59),\n",
       " ('hooked', 59),\n",
       " ('received', 59),\n",
       " ('spoonful', 58),\n",
       " ('seems', 58),\n",
       " ('past', 58),\n",
       " ('believe', 58),\n",
       " ('getting', 58),\n",
       " ('flavour', 58),\n",
       " ('spoon', 58),\n",
       " ('sorbet', 58),\n",
       " ('least', 57),\n",
       " ('everyone', 57),\n",
       " ('work', 57),\n",
       " ('nut', 57),\n",
       " ('wait', 57),\n",
       " ('melt', 56),\n",
       " ('vegan', 56),\n",
       " ('sorbetto', 56),\n",
       " ('probably', 56),\n",
       " ('addicted', 56),\n",
       " ('today', 55),\n",
       " ('isnt', 55),\n",
       " ('use', 55),\n",
       " ('service', 55),\n",
       " ('worth', 55),\n",
       " ('eaten', 55),\n",
       " ('consumer', 55),\n",
       " ('omg', 55),\n",
       " ('wrong', 55),\n",
       " ('strong', 55),\n",
       " ('took', 54),\n",
       " ('may', 54),\n",
       " ('especially', 54),\n",
       " ('might', 54),\n",
       " ('banana', 54),\n",
       " ('area', 53),\n",
       " ('cone', 53),\n",
       " ('cake', 53),\n",
       " ('finally', 52),\n",
       " ('sold', 52),\n",
       " ('couple', 52),\n",
       " ('carton', 52),\n",
       " ('option', 51),\n",
       " ('flavored', 51),\n",
       " ('overall', 51),\n",
       " ('peppermint', 51),\n",
       " ('havent', 50),\n",
       " ('decadent', 50),\n",
       " ('wow', 50),\n",
       " ('lactose', 50),\n",
       " ('else', 49),\n",
       " ('shelf', 49),\n",
       " ('forward', 49),\n",
       " ('gum', 48),\n",
       " ('version', 48),\n",
       " ('noticed', 48),\n",
       " ('artificial', 48),\n",
       " ('either', 48),\n",
       " ('lol', 48),\n",
       " ('list', 47),\n",
       " ('looked', 47),\n",
       " ('original', 47),\n",
       " ('apple', 47),\n",
       " ('com', 46),\n",
       " ('totally', 46),\n",
       " ('guy', 46),\n",
       " ('id', 46),\n",
       " ('help', 46),\n",
       " ('combo', 46),\n",
       " ('limited', 46),\n",
       " ('blend', 46),\n",
       " ('issue', 45),\n",
       " ('high', 45),\n",
       " ('quite', 45),\n",
       " ('three', 45),\n",
       " ('fact', 45),\n",
       " ('throughout', 45),\n",
       " ('exactly', 45),\n",
       " ('covered', 45),\n",
       " ('pumpkin', 45),\n",
       " ('market', 44),\n",
       " ('yet', 44),\n",
       " ('sometimes', 44),\n",
       " ('seriously', 44),\n",
       " ('end', 44),\n",
       " ('special', 44),\n",
       " ('unilever', 43),\n",
       " ('plain', 43),\n",
       " ('line', 43),\n",
       " ('fresh', 43),\n",
       " ('pb', 43),\n",
       " ('yum', 43),\n",
       " ('diet', 43),\n",
       " ('enjoyed', 43),\n",
       " ('second', 42),\n",
       " ('wont', 42),\n",
       " ('cold', 42),\n",
       " ('side', 42),\n",
       " ('stopped', 42),\n",
       " ('simply', 42),\n",
       " ('tonight', 42),\n",
       " ('youre', 42),\n",
       " ('tub', 42),\n",
       " ('baked', 42),\n",
       " ('liked', 42),\n",
       " ('barely', 42),\n",
       " ('salted', 42),\n",
       " ('delight', 42),\n",
       " ('phish', 42),\n",
       " ('smores', 42),\n",
       " ('anyone', 41),\n",
       " ('choice', 41),\n",
       " ('place', 41),\n",
       " ('happened', 41),\n",
       " ('expecting', 41),\n",
       " ('rest', 41),\n",
       " ('anywhere', 41),\n",
       " ('salt', 41),\n",
       " ('finding', 41),\n",
       " ('green', 41),\n",
       " ('surprised', 40),\n",
       " ('sell', 40),\n",
       " ('truly', 40),\n",
       " ('single', 40),\n",
       " ('permanent', 40),\n",
       " ('missing', 40),\n",
       " ('obsessed', 40),\n",
       " ('discontinued', 40),\n",
       " ('box', 39),\n",
       " ('hint', 39),\n",
       " ('refreshing', 39),\n",
       " ('simple', 39),\n",
       " ('done', 39),\n",
       " ('become', 39),\n",
       " ('extremely', 39),\n",
       " ('sweetness', 39),\n",
       " ('someone', 39),\n",
       " ('easy', 39),\n",
       " ('carry', 39),\n",
       " ('completely', 38),\n",
       " ('true', 38),\n",
       " ('opened', 38),\n",
       " ('white', 38),\n",
       " ('mean', 38),\n",
       " ('walmart', 38),\n",
       " ('mixed', 38),\n",
       " ('excellent', 38),\n",
       " ('summer', 38),\n",
       " ('live', 37),\n",
       " ('gave', 37),\n",
       " ('discontinue', 37),\n",
       " ('yes', 37),\n",
       " ('lemon', 37),\n",
       " ('per', 37),\n",
       " ('perfection', 37),\n",
       " ('soon', 37),\n",
       " ('fantastic', 37),\n",
       " ('serving', 37),\n",
       " ('bigger', 37),\n",
       " ('mine', 37),\n",
       " ('oatmeal', 37),\n",
       " ('disappointment', 36),\n",
       " ('finished', 36),\n",
       " ('company', 36),\n",
       " ('consistency', 36),\n",
       " ('satisfying', 36),\n",
       " ('influenster', 36),\n",
       " ('write', 36),\n",
       " ('point', 35),\n",
       " ('thinking', 35),\n",
       " ('extra', 35),\n",
       " ('name', 35),\n",
       " ('opinion', 35),\n",
       " ('testing', 35),\n",
       " ('goodness', 35),\n",
       " ('son', 35),\n",
       " ('dream', 35),\n",
       " ('fell', 35),\n",
       " ('item', 35),\n",
       " ('already', 35),\n",
       " ('forever', 35),\n",
       " ('syrup', 34),\n",
       " ('customer', 34),\n",
       " ('read', 34)]"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the most common words from the list.\n",
    "\n",
    "from nltk import FreqDist\n",
    "\n",
    "all_words = FreqDist(all_words)\n",
    "most_common_words = all_words.most_common(500)\n",
    "\n",
    "# create a list of most common words without the frequency count\n",
    "word_features = []\n",
    "for w in most_common_words:\n",
    "    word_features.append(w[0])\n",
    "    \n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  6153 unique words total in our text dataset.\n",
      "There are  500 unique words in the most common words list.\n"
     ]
    }
   ],
   "source": [
    "print ('There are ', len(all_words), 'unique words total in our text dataset.')\n",
    "print ('There are ', len(most_common_words), 'unique words in the most common words list.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Create Tokenized Reviews data set\n",
    "\n",
    "The export is commented out because I haven't limited the text dataset to the most_common_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[interested, flavoring, component, used, notic...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[boy, surprised, got, bryers, home, discover, ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[havent, purchased, product, awhile, surprised...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, recipe, change, include, ta...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>[issue, breyers, finally, found, turkey, hill,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \\\n",
       "0  [interested, flavoring, component, used, notic...     4.1          0   \n",
       "1  [boy, surprised, got, bryers, home, discover, ...     4.1          0   \n",
       "2  [havent, purchased, product, awhile, surprised...     4.1          0   \n",
       "3  [natural, vanilla, recipe, change, include, ta...     4.1          0   \n",
       "4  [issue, breyers, finally, found, turkey, hill,...     4.1          1   \n",
       "\n",
       "  bag_of_words  \n",
       "0               \n",
       "1               \n",
       "2               \n",
       "3               \n",
       "4               "
      ]
     },
     "execution_count": 912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create column for bag of words, otherwise loop in next cell won't work.\n",
    "# can drop columns that are unnecessary to keep it clean once we're wrapping up the project\n",
    "df_tokenize['bag_of_words'] = \"\"\n",
    "df_tokenize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate dataframe to populate bag of words column\n",
    "for i in range(len(df_tokenize['text'])):\n",
    "    # initialize empty column    \n",
    "    df_tokenize['bag_of_words'][i] = []\n",
    "    \n",
    "    # iterate through df row by row\n",
    "    for word in df_tokenize['text'][i]:\n",
    "        # if a word in 'text' is in the most common words\n",
    "        # this is simply the \"most_common_words\" without the count column otherwise it would append the word AND count\n",
    "        if word in word_features:\n",
    "            # if it is, add it to the bag of words cell\n",
    "            df_tokenize['bag_of_words'][i].append(word)\n",
    "            word_count.append(word)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[interested, flavoring, component, used, notic...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[used, ingredient, list, vanilla, bean, vanill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[boy, surprised, got, bryers, home, discover, ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[surprised, got, home, frozen, dairy, dessert,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[havent, purchased, product, awhile, surprised...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[havent, purchased, product, surprised, today,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, recipe, change, include, ta...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, recipe, change, gum, change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>[issue, breyers, finally, found, turkey, hill,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[issue, breyers, finally, found, natural, ice,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \\\n",
       "0  [interested, flavoring, component, used, notic...     4.1          0   \n",
       "1  [boy, surprised, got, bryers, home, discover, ...     4.1          0   \n",
       "2  [havent, purchased, product, awhile, surprised...     4.1          0   \n",
       "3  [natural, vanilla, recipe, change, include, ta...     4.1          0   \n",
       "4  [issue, breyers, finally, found, turkey, hill,...     4.1          1   \n",
       "\n",
       "                                        bag_of_words  \n",
       "0  [used, ingredient, list, vanilla, bean, vanill...  \n",
       "1  [surprised, got, home, frozen, dairy, dessert,...  \n",
       "2  [havent, purchased, product, surprised, today,...  \n",
       "3  [natural, vanilla, recipe, change, gum, change...  \n",
       "4  [issue, breyers, finally, found, natural, ice,...  "
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['upset', '1', '5qt', 'container', 'natural', 'vanilla', 'two', 'different', 'store', 'lacked', 'little', 'black', 'speck', 'come', 'love', 'expect']\n",
      "\n",
      "bag_of_words:  ['1', 'container', 'natural', 'vanilla', 'two', 'different', 'store', 'little', 'come', 'love']\n"
     ]
    }
   ],
   "source": [
    "# Example to Compare text vs bag of words\n",
    "# set example variable equal to the review row you'd like to see\n",
    "example = 7\n",
    "\n",
    "print('text: ', df_tokenize['text'][example])\n",
    "print('\\nbag_of_words: ',df_tokenize['bag_of_words'][example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  Vectorizing for Supervised ML algorithms\n",
    "\n",
    "We can now iterate through each review in our Tokenized Reviews dataset and create a vector of 1's and 0's for a given review depending on which words from our most common words show up in that review. However we should think ahead a little --- which ML algorithm will we use, and what format does it prefer its data in?\n",
    "\n",
    "\n",
    "Only running TFID because of scaling benefits. \n",
    "I've vectorized both the key and text features though we may not need all of this. Just wanted to get it done since we are exploring.\n",
    "\n",
    "Links to education and code syntax:\n",
    "\n",
    "https://datascience.stackexchange.com/questions/22250/what-is-the-difference-between-a-hashing-vectorizer-and-a-tfidf-vectorizer\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFID Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_breyers</th>\n",
       "      <th>0_hd</th>\n",
       "      <th>0_talenti</th>\n",
       "      <th>10_bj</th>\n",
       "      <th>10_breyers</th>\n",
       "      <th>10_talenti</th>\n",
       "      <th>11_bj</th>\n",
       "      <th>11_breyers</th>\n",
       "      <th>11_talenti</th>\n",
       "      <th>12_bj</th>\n",
       "      <th>...</th>\n",
       "      <th>6_talenti</th>\n",
       "      <th>7_bj</th>\n",
       "      <th>7_breyers</th>\n",
       "      <th>7_hd</th>\n",
       "      <th>7_talenti</th>\n",
       "      <th>8_bj</th>\n",
       "      <th>8_hd</th>\n",
       "      <th>8_talenti</th>\n",
       "      <th>9_bj</th>\n",
       "      <th>9_hd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_breyers  0_hd  0_talenti  10_bj  10_breyers  10_talenti  11_bj  \\\n",
       "0        1.0   0.0        0.0    0.0         0.0         0.0    0.0   \n",
       "1        1.0   0.0        0.0    0.0         0.0         0.0    0.0   \n",
       "2        1.0   0.0        0.0    0.0         0.0         0.0    0.0   \n",
       "3        1.0   0.0        0.0    0.0         0.0         0.0    0.0   \n",
       "4        1.0   0.0        0.0    0.0         0.0         0.0    0.0   \n",
       "\n",
       "   11_breyers  11_talenti  12_bj  ...  6_talenti  7_bj  7_breyers  7_hd  \\\n",
       "0         0.0         0.0    0.0  ...        0.0   0.0        0.0   0.0   \n",
       "1         0.0         0.0    0.0  ...        0.0   0.0        0.0   0.0   \n",
       "2         0.0         0.0    0.0  ...        0.0   0.0        0.0   0.0   \n",
       "3         0.0         0.0    0.0  ...        0.0   0.0        0.0   0.0   \n",
       "4         0.0         0.0    0.0  ...        0.0   0.0        0.0   0.0   \n",
       "\n",
       "   7_talenti  8_bj  8_hd  8_talenti  9_bj  9_hd  \n",
       "0        0.0   0.0   0.0        0.0   0.0   0.0  \n",
       "1        0.0   0.0   0.0        0.0   0.0   0.0  \n",
       "2        0.0   0.0   0.0        0.0   0.0   0.0  \n",
       "3        0.0   0.0   0.0        0.0   0.0   0.0  \n",
       "4        0.0   0.0   0.0        0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 184 columns]"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 'key' term frequencies weighted by their relative importance (IDF)\n",
    "\n",
    "df_tfidf_key = pd.DataFrame(df_tokenize)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "sparse_out_key = vectorizer.fit_transform(df_tfidf_key['key'])\n",
    "\n",
    "tfidf_key_df = pd.DataFrame(data = sparse_out_key.toarray(),\n",
    "                        columns = vectorizer.get_feature_names())\n",
    "\n",
    "tfidf_key_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3424 entries, 0 to 3423\n",
      "Columns: 184 entries, 0_breyers to 9_hd\n",
      "dtypes: float64(184)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "tfidf_key_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features :  ['0_breyers', '0_hd', '0_talenti', '10_bj', '10_breyers', '10_talenti', '11_bj', '11_breyers', '11_talenti', '12_bj', '12_breyers', '12_hd', '12_talenti', '13_bj', '13_hd', '13_talenti', '14_bj', '14_breyers', '14_hd', '14_talenti', '15_breyers', '15_hd', '15_talenti', '16_bj', '16_breyers', '16_hd', '16_talenti', '17_breyers', '17_hd', '17_talenti', '18_breyers', '18_hd', '18_talenti', '19_bj', '19_breyers', '19_hd', '19_talenti', '1_bj', '1_breyers', '1_hd', '1_talenti', '20_bj', '20_hd', '20_talenti', '21_bj', '21_breyers', '21_hd', '22_bj', '22_breyers', '22_hd', '22_talenti', '23_bj', '24_breyers', '24_hd', '24_talenti', '25_bj', '25_breyers', '25_hd', '25_talenti', '26_breyers', '26_hd', '26_talenti', '27_bj', '27_breyers', '27_hd', '27_talenti', '28_bj', '28_talenti', '29_bj', '29_hd', '29_talenti', '2_bj', '2_breyers', '2_hd', '2_talenti', '30_bj', '30_breyers', '30_hd', '30_talenti', '31_bj', '31_breyers', '31_hd', '31_talenti', '32_bj', '32_hd', '32_talenti', '33_bj', '33_breyers', '33_hd', '33_talenti', '34_bj', '34_hd', '34_talenti', '35_bj', '35_breyers', '35_hd', '35_talenti', '36_bj', '36_breyers', '36_hd', '37_bj', '37_hd', '37_talenti', '38_bj', '38_talenti', '39_bj', '39_breyers', '39_hd', '39_talenti', '3_breyers', '3_hd', '3_talenti', '40_breyers', '40_talenti', '41_bj', '41_hd', '41_talenti', '42_bj', '42_breyers', '42_hd', '43_bj', '43_hd', '44_bj', '44_hd', '44_talenti', '45_bj', '45_hd', '46_bj', '47_bj', '47_hd', '48_bj', '48_breyers', '48_hd', '49_bj', '49_hd', '4_bj', '4_breyers', '4_hd', '4_talenti', '50_breyers', '51_bj', '51_hd', '52_breyers', '53_hd', '54_bj', '55_bj', '55_breyers', '55_hd', '56_bj', '56_breyers', '56_hd', '58_breyers', '58_hd', '59_breyers', '5_bj', '5_breyers', '5_hd', '5_talenti', '60_breyers', '60_hd', '61_breyers', '61_hd', '62_hd', '63_breyers', '63_hd', '64_breyers', '64_hd', '65_breyers', '65_hd', '67_hd', '68_hd', '6_bj', '6_breyers', '6_hd', '6_talenti', '7_bj', '7_breyers', '7_hd', '7_talenti', '8_bj', '8_hd', '8_talenti', '9_bj', '9_hd']\n"
     ]
    }
   ],
   "source": [
    "print ('\\nFeatures : ', tfidf_key_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFID Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>stars</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>bag_of_words</th>\n",
       "      <th>bag_of_words_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[interested, flavoring, component, used, notic...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[used, ingredient, list, vanilla, bean, vanill...</td>\n",
       "      <td>used,ingredient,list,vanilla,bean,vanilla,natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[boy, surprised, got, bryers, home, discover, ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[surprised, got, home, frozen, dairy, dessert,...</td>\n",
       "      <td>surprised,got,home,frozen,dairy,dessert,even,i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[havent, purchased, product, awhile, surprised...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[havent, purchased, product, surprised, today,...</td>\n",
       "      <td>havent,purchased,product,surprised,today,find,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, recipe, change, include, ta...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, vanilla, recipe, change, gum, change...</td>\n",
       "      <td>natural,vanilla,recipe,change,gum,change,textu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_breyers</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>[issue, breyers, finally, found, turkey, hill,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[issue, breyers, finally, found, natural, ice,...</td>\n",
       "      <td>issue,breyers,finally,found,natural,ice,cream,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  stars  helpful_yes  helpful_no  \\\n",
       "0  0_breyers      1           11           0   \n",
       "1  0_breyers      1            7           0   \n",
       "2  0_breyers      1            8           0   \n",
       "3  0_breyers      1            4           0   \n",
       "4  0_breyers      5           21           2   \n",
       "\n",
       "                                                text  rating  sentiment  \\\n",
       "0  [interested, flavoring, component, used, notic...     4.1          0   \n",
       "1  [boy, surprised, got, bryers, home, discover, ...     4.1          0   \n",
       "2  [havent, purchased, product, awhile, surprised...     4.1          0   \n",
       "3  [natural, vanilla, recipe, change, include, ta...     4.1          0   \n",
       "4  [issue, breyers, finally, found, turkey, hill,...     4.1          1   \n",
       "\n",
       "                                        bag_of_words  \\\n",
       "0  [used, ingredient, list, vanilla, bean, vanill...   \n",
       "1  [surprised, got, home, frozen, dairy, dessert,...   \n",
       "2  [havent, purchased, product, surprised, today,...   \n",
       "3  [natural, vanilla, recipe, change, gum, change...   \n",
       "4  [issue, breyers, finally, found, natural, ice,...   \n",
       "\n",
       "                                    bag_of_words_str  \n",
       "0  used,ingredient,list,vanilla,bean,vanilla,natu...  \n",
       "1  surprised,got,home,frozen,dairy,dessert,even,i...  \n",
       "2  havent,purchased,product,surprised,today,find,...  \n",
       "3  natural,vanilla,recipe,change,gum,change,textu...  \n",
       "4  issue,breyers,finally,found,natural,ice,cream,...  "
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer\n",
    "df_tfidf_text = pd.DataFrame(df_tokenize)\n",
    "\n",
    "# convert text list to string and create string column\n",
    "# required for vectorizer, learned after getting error\n",
    "# https://stackoverflow.com/questions/45306988/column-of-lists-convert-list-to-string-as-a-new-column\n",
    "df_tfidf_text['bag_of_words_str'] = df_tfidf_text['bag_of_words'].apply(lambda x: ','.join(map(str, x)))\n",
    "\n",
    "df_tfidf_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenized_text_features.csv\n",
    "# finally in the format needed for vectorizing our features\n",
    "# the bag_of_words column as a string which is required for vectorizing\n",
    "df_tfidf_text.to_csv(\"Resources/tokenized_text_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>addicted</th>\n",
       "      <th>ago</th>\n",
       "      <th>ahoy</th>\n",
       "      <th>...</th>\n",
       "      <th>would</th>\n",
       "      <th>wow</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>youre</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 492 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  able  absolute  absolutely  actually  add  added  addicted  ago  ahoy  \\\n",
       "0  0.0   0.0       0.0         0.0       0.0  0.0    0.0       0.0  0.0   0.0   \n",
       "1  0.0   0.0       0.0         0.0       0.0  0.0    0.0       0.0  0.0   0.0   \n",
       "2  0.0   0.0       0.0         0.0       0.0  0.0    0.0       0.0  0.0   0.0   \n",
       "3  0.0   0.0       0.0         0.0       0.0  0.0    0.0       0.0  0.0   0.0   \n",
       "4  0.0   0.0       0.0         0.0       0.0  0.0    0.0       0.0  0.0   0.0   \n",
       "\n",
       "   ...  would  wow  write  wrong  year  yes  yet  youre  yum  yummy  \n",
       "0  ...    0.0  0.0    0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0  \n",
       "1  ...    0.0  0.0    0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0  \n",
       "2  ...    0.0  0.0    0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0  \n",
       "3  ...    0.0  0.0    0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0  \n",
       "4  ...    0.0  0.0    0.0    0.0   0.0  0.0  0.0    0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 492 columns]"
      ]
     },
     "execution_count": 922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 'text' term frequencies weighted by their relative importance (IDF)\n",
    "vectorizer2 = TfidfVectorizer()\n",
    "\n",
    "sparse_out_text = vectorizer2.fit_transform(df_tfidf_text['bag_of_words_str'])\n",
    "\n",
    "tdif_bagOfWords_df = pd.DataFrame(data = sparse_out_text.toarray(),\n",
    "                        columns = vectorizer2.get_feature_names())\n",
    "\n",
    "tdif_bagOfWords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3424 entries, 0 to 3423\n",
      "Columns: 492 entries, 10 to yummy\n",
      "dtypes: float64(492)\n",
      "memory usage: 12.9 MB\n"
     ]
    }
   ],
   "source": [
    "# I was expecting 500 columns since features are filtered to 500 most common words....\n",
    "tdif_bagOfWords_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features :  ['10', 'able', 'absolute', 'absolutely', 'actually', 'add', 'added', 'addicted', 'ago', 'ahoy', 'almond', 'almost', 'already', 'also', 'always', 'amazing', 'amount', 'another', 'anymore', 'anyone', 'anything', 'anywhere', 'apple', 'area', 'around', 'artificial', 'ate', 'available', 'away', 'awesome', 'back', 'bad', 'baked', 'balance', 'banana', 'bar', 'barely', 'base', 'batch', 'bean', 'become', 'believe', 'ben', 'best', 'better', 'big', 'bigger', 'bit', 'bite', 'blend', 'bottom', 'bought', 'bourbon', 'box', 'brand', 'breyers', 'bring', 'brownie', 'butter', 'buy', 'buying', 'cake', 'calorie', 'came', 'cannot', 'cant', 'caramel', 'carb', 'carbs', 'carry', 'carton', 'change', 'changed', 'cheesecake', 'cherry', 'chip', 'chocolate', 'choice', 'chunk', 'cinnamon', 'coconut', 'coffee', 'cold', 'com', 'combination', 'combo', 'come', 'company', 'completely', 'cone', 'consistency', 'consumer', 'container', 'cookie', 'cooky', 'core', 'could', 'couldnt', 'couple', 'covered', 'cracker', 'craving', 'cream', 'creamy', 'crunch', 'crunchy', 'cup', 'customer', 'dairy', 'dark', 'day', 'dazs', 'decadent', 'decided', 'definitely', 'delicious', 'delight', 'dessert', 'didnt', 'diet', 'different', 'disappointed', 'disappointing', 'disappointment', 'discontinue', 'discontinued', 'doesnt', 'done', 'dont', 'dough', 'dream', 'easy', 'eat', 'eaten', 'eating', 'either', 'else', 'end', 'enjoy', 'enjoyed', 'enough', 'entire', 'especially', 'even', 'ever', 'every', 'everyone', 'everything', 'exactly', 'excellent', 'excited', 'expecting', 'experience', 'extra', 'extremely', 'fact', 'family', 'fan', 'fantastic', 'far', 'favorite', 'feel', 'fell', 'finally', 'find', 'finding', 'finished', 'first', 'flavor', 'flavored', 'flavour', 'food', 'forever', 'forward', 'found', 'free', 'freezer', 'fresh', 'friend', 'frozen', 'fudge', 'full', 'gave', 'gelato', 'get', 'getting', 'give', 'glad', 'go', 'going', 'gone', 'good', 'goodness', 'got', 'graham', 'great', 'green', 'grocery', 'gum', 'guy', 'haagen', 'half', 'hand', 'happened', 'happy', 'hard', 'havent', 'heaven', 'help', 'high', 'highly', 'hint', 'hit', 'home', 'honestly', 'hooked', 'hope', 'however', 'huge', 'husband', 'ice', 'icecream', 'id', 'ill', 'im', 'influenster', 'ingredient', 'instead', 'isnt', 'issue', 'item', 'ive', 'jerry', 'keep', 'kid', 'kind', 'know', 'lactose', 'last', 'layer', 'le', 'least', 'left', 'lemon', 'let', 'life', 'light', 'like', 'liked', 'limited', 'line', 'list', 'literally', 'little', 'live', 'local', 'lol', 'long', 'longer', 'look', 'looked', 'looking', 'lot', 'love', 'loved', 'lover', 'low', 'made', 'make', 'making', 'mango', 'many', 'market', 'marshmallow', 'may', 'maybe', 'mean', 'melt', 'might', 'milk', 'mine', 'mint', 'missing', 'mix', 'mixed', 'month', 'mouth', 'much', 'must', 'name', 'natural', 'need', 'never', 'new', 'next', 'nice', 'night', 'non', 'nothing', 'noticed', 'nut', 'oatmeal', 'obsessed', 'oh', 'old', 'omg', 'one', 'opened', 'opinion', 'option', 'oreo', 'original', 'others', 'overall', 'part', 'past', 'pb', 'peanut', 'pecan', 'people', 'peppermint', 'per', 'perfect', 'perfection', 'perfectly', 'permanent', 'phish', 'pie', 'piece', 'pint', 'pistachio', 'place', 'plain', 'please', 'point', 'pretty', 'pretzel', 'price', 'probably', 'problem', 'product', 'pumpkin', 'purchase', 'purchased', 'put', 'quality', 'quite', 'raspberry', 'read', 'real', 'really', 'reason', 'received', 'recently', 'recipe', 'recommend', 'refreshing', 'regular', 'rest', 'review', 'rich', 'right', 'sad', 'said', 'salt', 'salted', 'salty', 'satisfying', 'saw', 'say', 'scoop', 'second', 'see', 'seems', 'sell', 'seriously', 'service', 'serving', 'several', 'shelf', 'side', 'simple', 'simply', 'since', 'single', 'sitting', 'size', 'small', 'smooth', 'smores', 'soft', 'sold', 'someone', 'something', 'sometimes', 'son', 'soon', 'sorbet', 'sorbetto', 'special', 'spoon', 'spoonful', 'star', 'still', 'stock', 'stop', 'stopped', 'store', 'strawberry', 'strong', 'stuff', 'sugar', 'summer', 'super', 'sure', 'surprised', 'sweet', 'sweetness', 'swirl', 'syrup', 'take', 'talenti', 'target', 'taste', 'tasted', 'tasting', 'tasty', 'tell', 'testing', 'texture', 'thank', 'thanks', 'thats', 'thing', 'think', 'thinking', 'though', 'thought', 'three', 'throughout', 'time', 'today', 'together', 'tonight', 'took', 'top', 'totally', 'treat', 'tried', 'true', 'truffle', 'truly', 'try', 'trying', 'tub', 'two', 'unfortunately', 'unilever', 'use', 'used', 'usually', 'vanilla', 'vegan', 'version', 'wait', 'walmart', 'want', 'wanted', 'wasnt', 'way', 'week', 'well', 'went', 'white', 'whole', 'wish', 'without', 'wonderful', 'wont', 'work', 'world', 'worth', 'would', 'wow', 'write', 'wrong', 'year', 'yes', 'yet', 'youre', 'yum', 'yummy']\n"
     ]
    }
   ],
   "source": [
    "print ('\\nFeatures : ', tdif_bagOfWords_df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
